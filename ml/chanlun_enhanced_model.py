"""ç¼ è®ºå¢å¼ºçš„LightGBMæ¨¡å‹

åœ¨éº’éºŸç°æœ‰LightGBMåŸºç¡€ä¸Šï¼Œæ·±åº¦é›†æˆç¼ è®ºå› å­å’ŒAlphaå› å­

ç‰¹ç‚¹:
1. ç»§æ‰¿Qlib LGBModel
2. è‡ªåŠ¨æ³¨å†Œå¹¶åŠ è½½16ä¸ªåŸºç¡€ç¼ è®ºå› å­
3. è‡ªåŠ¨ç”Ÿæˆå¹¶åŠ è½½10ä¸ªAlphaå› å­
4. ä¸éº’éºŸAlpha191/æŠ€æœ¯æŒ‡æ ‡å› å­èåˆ
5. ç‰¹å¾é‡è¦æ€§åˆ†æå’Œå¯è§†åŒ–
6. åŒæ¨¡å¼å¤ç”¨æ”¯æŒ

ä½œè€…: Warp AI Assistant
æ—¥æœŸ: 2025-01
é¡¹ç›®: éº’éºŸé‡åŒ–ç³»ç»Ÿ - Phase 4.2
"""

import sys
from pathlib import Path
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from qlib.contrib.model.gbdt import LGBModel
from qlib.data.dataset import DatasetH
from qlib_enhanced.chanlun.register_factors import register_chanlun_factors, get_factor_names
from qlib_enhanced.chanlun.chanlun_alpha import ChanLunAlphaFactors
import pandas as pd
import numpy as np
import logging
from typing import Optional, Dict, List
import matplotlib.pyplot as plt

logger = logging.getLogger(__name__)


class ChanLunEnhancedLGBModel(LGBModel):
    """ç¼ è®ºå¢å¼ºçš„LightGBMæ¨¡å‹
    
    åœ¨éº’éºŸç°æœ‰LGBModelåŸºç¡€ä¸Šå¢å¼º:
    - è‡ªåŠ¨åŠ è½½16ä¸ªåŸºç¡€ç¼ è®ºå› å­
    - è‡ªåŠ¨ç”Ÿæˆ10ä¸ªAlphaå› å­
    - ç‰¹å¾é‡è¦æ€§åˆ†æ
    - ç¼ è®ºå› å­è´¡çŒ®åº¦ç»Ÿè®¡
    
    ä½¿ç”¨æ–¹å¼:
    ```python
    model = ChanLunEnhancedLGBModel(
        use_chanlun=True,
        chanlun_weight=0.3,
        use_alpha=True,
        **lightgbm_params
    )
    ```
    
    å¤ç”¨æ€§:
    - Qlibç³»ç»Ÿ: ä½œä¸ºä¸»æ¨¡å‹ï¼Œå®Œæ•´MLæµç¨‹
    - ç‹¬ç«‹ç³»ç»Ÿ: å¯¼å‡ºç‰¹å¾é‡è¦æ€§ï¼ŒæŒ‡å¯¼è¯„åˆ†æƒé‡
    """
    
    def __init__(self,
                 use_chanlun: bool = True,
                 chanlun_weight: float = 0.3,
                 use_alpha: bool = True,
                 alpha_only_top5: bool = False,
                 enable_feature_analysis: bool = True,
                 **kwargs):
        """åˆå§‹åŒ–ç¼ è®ºå¢å¼ºLightGBMæ¨¡å‹
        
        Args:
            use_chanlun: æ˜¯å¦ä½¿ç”¨ç¼ è®ºå› å­
            chanlun_weight: ç¼ è®ºå› å­å»ºè®®æƒé‡ (0-1)
            use_alpha: æ˜¯å¦ä½¿ç”¨Alphaå› å­
            alpha_only_top5: ä»…ä½¿ç”¨Top5 Alphaå› å­
            enable_feature_analysis: æ˜¯å¦å¯ç”¨ç‰¹å¾é‡è¦æ€§åˆ†æ
            **kwargs: LightGBMå‚æ•°
        """
        super().__init__(**kwargs)
        
        self.use_chanlun = use_chanlun
        self.chanlun_weight = chanlun_weight
        self.use_alpha = use_alpha
        self.alpha_only_top5 = alpha_only_top5
        self.enable_feature_analysis = enable_feature_analysis
        
        # æ³¨å†Œç¼ è®ºå› å­
        if use_chanlun:
            register_chanlun_factors()
            logger.info("âœ… ç¼ è®ºå› å­å·²æ³¨å†Œåˆ°æ¨¡å‹")
        
        # ç‰¹å¾é‡è¦æ€§å­˜å‚¨
        self.feature_importance_df = None
        self.chanlun_importance_df = None
        self.alpha_importance_df = None
    
    def fit(self, dataset: DatasetH, **kwargs):
        """è®­ç»ƒæ¨¡å‹
        
        Args:
            dataset: Qlibæ ‡å‡†æ•°æ®é›†
            **kwargs: å…¶ä»–å‚æ•°
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹è®­ç»ƒç¼ è®ºå¢å¼ºLightGBMæ¨¡å‹")
        logger.info("=" * 60)
        
        # 1. æ•°æ®é›†å¢å¼ºï¼ˆæ·»åŠ Alphaå› å­ï¼‰
        if self.use_chanlun and self.use_alpha:
            logger.info("ğŸ“Š å¢å¼ºæ•°æ®é›†ï¼šæ·»åŠ Alphaå› å­...")
            dataset = self._enhance_dataset_with_alpha(dataset)
        
        # 2. è°ƒç”¨çˆ¶ç±»è®­ç»ƒ
        logger.info("ğŸ¯ å¼€å§‹LightGBMè®­ç»ƒ...")
        super().fit(dataset, **kwargs)
        
        # 3. ç‰¹å¾é‡è¦æ€§åˆ†æ
        if self.enable_feature_analysis and hasattr(self, 'model'):
            logger.info("ğŸ“ˆ åˆ†æç‰¹å¾é‡è¦æ€§...")
            self._analyze_feature_importance()
        
        logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    def _enhance_dataset_with_alpha(self, dataset: DatasetH) -> DatasetH:
        """å¢å¼ºæ•°æ®é›†ï¼šæ·»åŠ Alphaå› å­
        
        Args:
            dataset: åŸå§‹æ•°æ®é›†
            
        Returns:
            å¢å¼ºåçš„æ•°æ®é›†
        """
        try:
            # è·å–è®­ç»ƒå’ŒéªŒè¯æ•°æ®
            df_train, df_valid = dataset.prepare(
                ["train", "valid"],
                col_set=["feature", "label"],
                data_key="infer"
            )
            
            # ä¸ºæ¯ä¸ªè‚¡ç¥¨ç”ŸæˆAlphaå› å­
            logger.info(f"   å¤„ç†è®­ç»ƒé›†: {len(df_train.index.get_level_values(0).unique())} åªè‚¡ç¥¨")
            df_train = self._add_alpha_to_dataframe(df_train)
            
            logger.info(f"   å¤„ç†éªŒè¯é›†: {len(df_valid.index.get_level_values(0).unique())} åªè‚¡ç¥¨")
            df_valid = self._add_alpha_to_dataframe(df_valid)
            
            logger.info(f"   âœ… Alphaå› å­æ·»åŠ å®Œæˆ")
            logger.info(f"      è®­ç»ƒé›†ç»´åº¦: {df_train.shape}")
            logger.info(f"      éªŒè¯é›†ç»´åº¦: {df_valid.shape}")
            
        except Exception as e:
            logger.error(f"   âŒ æ•°æ®é›†å¢å¼ºå¤±è´¥: {e}")
            logger.info("   ç»§ç»­ä½¿ç”¨åŸå§‹æ•°æ®é›†")
        
        return dataset
    
    def _add_alpha_to_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """ä¸ºDataFrameæ·»åŠ Alphaå› å­
        
        Args:
            df: åŸå§‹DataFrame (MultiIndex: instrument, datetime)
            
        Returns:
            æ·»åŠ Alphaå› å­åçš„DataFrame
        """
        result = df.copy()
        
        # ç¡®å®šä½¿ç”¨å“ªäº›Alphaå› å­
        if self.alpha_only_top5:
            alpha_features = ChanLunAlphaFactors.select_important_features(5)
        else:
            alpha_features = ChanLunAlphaFactors.get_alpha_feature_names()
        
        # æŒ‰è‚¡ç¥¨åˆ†ç»„å¤„ç†
        for instrument in df.index.get_level_values(0).unique():
            try:
                inst_df = df.loc[instrument].reset_index()
                
                # ç”ŸæˆAlphaå› å­
                alpha_df = ChanLunAlphaFactors.generate_alpha_factors(
                    inst_df, 
                    code=instrument
                )
                
                # åˆå¹¶Alphaå› å­åˆ°ç»“æœ
                for col in alpha_features:
                    if col in alpha_df.columns:
                        result.loc[instrument, col] = alpha_df[col].values
                
            except Exception as e:
                logger.warning(f"   è‚¡ç¥¨ {instrument} Alphaå› å­ç”Ÿæˆå¤±è´¥: {e}")
                # å¡«å……0
                for col in alpha_features:
                    if col not in result.columns:
                        result.loc[instrument, col] = 0
        
        return result
    
    def _analyze_feature_importance(self):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        if not hasattr(self, 'model') or not hasattr(self.model, 'feature_importance_'):
            logger.warning("   æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
            return
        
        try:
            # è·å–ç‰¹å¾é‡è¦æ€§
            importance = self.model.feature_importance_
            feature_names = self.model.feature_name_
            
            # åˆ›å»ºDataFrame
            self.feature_importance_df = pd.DataFrame({
                'feature': feature_names,
                'importance': importance
            }).sort_values('importance', ascending=False)
            
            # ç­›é€‰ç¼ è®ºç›¸å…³ç‰¹å¾
            chanlun_pattern = r'(\$fx_mark|\$bi_|\$bsp_|\$seg_|\$in_|zs_|alpha_)'
            self.chanlun_importance_df = self.feature_importance_df[
                self.feature_importance_df['feature'].str.contains(chanlun_pattern, na=False)
            ]
            
            # ç­›é€‰Alphaå› å­
            self.alpha_importance_df = self.feature_importance_df[
                self.feature_importance_df['feature'].str.contains('alpha_', na=False)
            ]
            
            # ç»Ÿè®¡
            total_importance = self.feature_importance_df['importance'].sum()
            chanlun_importance = self.chanlun_importance_df['importance'].sum()
            alpha_importance = self.alpha_importance_df['importance'].sum()
            
            chanlun_contribution = chanlun_importance / total_importance * 100
            alpha_contribution = alpha_importance / total_importance * 100
            
            logger.info("")
            logger.info("=" * 60)
            logger.info("ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ")
            logger.info("=" * 60)
            logger.info(f"æ€»ç‰¹å¾æ•°: {len(self.feature_importance_df)}")
            logger.info(f"ç¼ è®ºç›¸å…³ç‰¹å¾æ•°: {len(self.chanlun_importance_df)}")
            logger.info(f"Alphaå› å­æ•°: {len(self.alpha_importance_df)}")
            logger.info("")
            logger.info(f"ç¼ è®ºå› å­æ€»è´¡çŒ®åº¦: {chanlun_contribution:.2f}%")
            logger.info(f"Alphaå› å­æ€»è´¡çŒ®åº¦: {alpha_contribution:.2f}%")
            logger.info("")
            logger.info("Top10 ç¼ è®ºç‰¹å¾:")
            for idx, row in self.chanlun_importance_df.head(10).iterrows():
                logger.info(f"   {row['feature']:30s}: {row['importance']:8.1f}")
            
            logger.info("")
            logger.info("Top5 Alphaå› å­:")
            for idx, row in self.alpha_importance_df.head(5).iterrows():
                logger.info(f"   {row['feature']:30s}: {row['importance']:8.1f}")
            
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"ç‰¹å¾é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
    
    def get_chanlun_feature_importance(self) -> Optional[pd.DataFrame]:
        """è·å–ç¼ è®ºç‰¹å¾é‡è¦æ€§
        
        Returns:
            DataFrameåŒ…å«ç¼ è®ºç‰¹å¾åŠå…¶é‡è¦æ€§
        """
        return self.chanlun_importance_df
    
    def get_alpha_feature_importance(self) -> Optional[pd.DataFrame]:
        """è·å–Alphaå› å­é‡è¦æ€§
        
        Returns:
            DataFrameåŒ…å«Alphaå› å­åŠå…¶é‡è¦æ€§
        """
        return self.alpha_importance_df
    
    def plot_importance(self, save_path: Optional[str] = None, top_n: int = 20):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾
        
        Args:
            save_path: ä¿å­˜è·¯å¾„ï¼ŒNoneåˆ™æ˜¾ç¤º
            top_n: æ˜¾ç¤ºå‰Nä¸ªç‰¹å¾
        """
        if self.feature_importance_df is None:
            logger.warning("æœªæ‰¾åˆ°ç‰¹å¾é‡è¦æ€§æ•°æ®")
            return
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(1, 2, figsize=(16, 8))
        
        # å›¾1: Top N æ‰€æœ‰ç‰¹å¾
        top_features = self.feature_importance_df.head(top_n)
        axes[0].barh(top_features['feature'], top_features['importance'])
        axes[0].set_xlabel('Importance')
        axes[0].set_title(f'Top {top_n} Features')
        axes[0].invert_yaxis()
        
        # å›¾2: ç¼ è®ºç‰¹å¾
        if self.chanlun_importance_df is not None and len(self.chanlun_importance_df) > 0:
            top_chanlun = self.chanlun_importance_df.head(top_n)
            axes[1].barh(top_chanlun['feature'], top_chanlun['importance'], color='orange')
            axes[1].set_xlabel('Importance')
            axes[1].set_title(f'Top {top_n} ç¼ è®ºç‰¹å¾')
            axes[1].invert_yaxis()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=100, bbox_inches='tight')
            logger.info(f"ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜: {save_path}")
        else:
            plt.show()
    
    def export_importance_report(self, output_path: str):
        """å¯¼å‡ºç‰¹å¾é‡è¦æ€§æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if self.feature_importance_df is None:
            logger.warning("æœªæ‰¾åˆ°ç‰¹å¾é‡è¦æ€§æ•°æ®")
            return
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("# ç¼ è®ºå¢å¼ºLightGBMæ¨¡å‹ - ç‰¹å¾é‡è¦æ€§æŠ¥å‘Š\n\n")
                
                # æ€»ä½“ç»Ÿè®¡
                f.write("## æ€»ä½“ç»Ÿè®¡\n\n")
                f.write(f"- æ€»ç‰¹å¾æ•°: {len(self.feature_importance_df)}\n")
                f.write(f"- ç¼ è®ºç‰¹å¾æ•°: {len(self.chanlun_importance_df)}\n")
                f.write(f"- Alphaå› å­æ•°: {len(self.alpha_importance_df)}\n\n")
                
                # è´¡çŒ®åº¦
                total = self.feature_importance_df['importance'].sum()
                chanlun = self.chanlun_importance_df['importance'].sum()
                alpha = self.alpha_importance_df['importance'].sum()
                
                f.write("## è´¡çŒ®åº¦\n\n")
                f.write(f"- ç¼ è®ºå› å­æ€»è´¡çŒ®: {chanlun/total*100:.2f}%\n")
                f.write(f"- Alphaå› å­æ€»è´¡çŒ®: {alpha/total*100:.2f}%\n\n")
                
                # Topç‰¹å¾
                f.write("## Top20 å…¨éƒ¨ç‰¹å¾\n\n")
                f.write("| æ’å | ç‰¹å¾ | é‡è¦æ€§ |\n")
                f.write("|-----|------|--------|\n")
                for idx, (_, row) in enumerate(self.feature_importance_df.head(20).iterrows(), 1):
                    f.write(f"| {idx} | {row['feature']} | {row['importance']:.1f} |\n")
                
                f.write("\n## Top10 ç¼ è®ºç‰¹å¾\n\n")
                f.write("| æ’å | ç‰¹å¾ | é‡è¦æ€§ |\n")
                f.write("|-----|------|--------|\n")
                for idx, (_, row) in enumerate(self.chanlun_importance_df.head(10).iterrows(), 1):
                    f.write(f"| {idx} | {row['feature']} | {row['importance']:.1f} |\n")
                
                f.write("\n## Alphaå› å­é‡è¦æ€§\n\n")
                f.write("| æ’å | å› å­ | é‡è¦æ€§ |\n")
                f.write("|-----|------|--------|\n")
                for idx, (_, row) in enumerate(self.alpha_importance_df.iterrows(), 1):
                    f.write(f"| {idx} | {row['feature']} | {row['importance']:.1f} |\n")
            
            logger.info(f"ç‰¹å¾é‡è¦æ€§æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")


if __name__ == '__main__':
    """æµ‹è¯•ç¼ è®ºå¢å¼ºLightGBMæ¨¡å‹"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("=" * 70)
    print("ç¼ è®ºå¢å¼ºLightGBMæ¨¡å‹æµ‹è¯•")
    print("=" * 70)
    
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("\n1. æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        model = ChanLunEnhancedLGBModel(
            use_chanlun=True,
            chanlun_weight=0.3,
            use_alpha=True,
            alpha_only_top5=False,
            enable_feature_analysis=True,
            # LightGBMå‚æ•°
            loss='mse',
            num_boost_round=100,
            learning_rate=0.05,
            max_depth=6,
            num_leaves=32,
        )
        
        print(f"   âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   ä½¿ç”¨ç¼ è®ºå› å­: {model.use_chanlun}")
        print(f"   ä½¿ç”¨Alphaå› å­: {model.use_alpha}")
        print(f"   ç¼ è®ºæƒé‡å»ºè®®: {model.chanlun_weight}")
        
    except Exception as e:
        print(f"   âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•Alphaå› å­ç”Ÿæˆ
    print("\n2. æµ‹è¯•Alphaå› å­ç”Ÿæˆ...")
    
    try:
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        np.random.seed(42)
        n = 50
        
        test_df = pd.DataFrame({
            'datetime': pd.date_range('2023-01-01', periods=n, freq='D'),
            'close': 10 + np.random.randn(n).cumsum() * 0.1,
            '$fx_mark': np.random.choice([-1, 0, 1], n, p=[0.1, 0.8, 0.1]),
            '$bi_direction': np.random.choice([-1, 1], n),
            '$bi_power': np.abs(np.random.randn(n) * 0.05),
            '$bi_position': np.random.rand(n),
            '$is_buy_point': np.random.choice([0, 1], n, p=[0.9, 0.1]),
            '$is_sell_point': np.random.choice([0, 1], n, p=[0.9, 0.1]),
            '$seg_direction': np.random.choice([-1, 1], n),
            '$in_chanpy_zs': np.random.choice([0, 1], n, p=[0.7, 0.3]),
            '$zs_low_chanpy': 9.5 + np.random.rand(n) * 0.3,
            '$zs_high_chanpy': 10.2 + np.random.rand(n) * 0.3,
        })
        
        # ç”ŸæˆAlphaå› å­
        result_df = ChanLunAlphaFactors.generate_alpha_factors(test_df)
        
        alpha_cols = [c for c in result_df.columns if c.startswith('alpha_')]
        print(f"   âœ… Alphaå› å­ç”ŸæˆæˆåŠŸ")
        print(f"   åŸå§‹åˆ—æ•°: {len(test_df.columns)}")
        print(f"   Alphaå› å­æ•°: {len(alpha_cols)}")
        print(f"   æ€»åˆ—æ•°: {len(result_df.columns)}")
        
    except Exception as e:
        print(f"   âŒ Alphaå› å­ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\n" + "=" * 70)
    print("âœ… ç¼ è®ºå¢å¼ºLightGBMæ¨¡å‹æµ‹è¯•å®Œæˆ!")
    print("=" * 70)
    print("\nğŸ“ è¯´æ˜:")
    print("   - å®Œæ•´æµ‹è¯•éœ€è¦Qlibæ•°æ®é›†ï¼Œå¯é€šè¿‡qlib_runè¿è¡Œ")
    print("   - æœ¬æµ‹è¯•éªŒè¯äº†æ¨¡å‹åˆ›å»ºå’ŒAlphaå› å­ç”ŸæˆåŠŸèƒ½")
    print("   - ç‰¹å¾é‡è¦æ€§åˆ†æéœ€è¦åœ¨fit()åæŸ¥çœ‹")
