"""
ç­–ç•¥ä¼˜åŒ–é—­ç¯ç³»ç»Ÿ - Qilin Stack æ ¸å¿ƒç‰¹è‰²
===========================================

å®Œæ•´æµç¨‹:
1. AIå› å­æŒ–æ˜ (RD-Agent) â†’ ç”Ÿæˆå› å­å’Œç­–ç•¥
2. å›æµ‹éªŒè¯ (Qlib) â†’ è¯„ä¼°ç­–ç•¥è¡¨ç°
3. æ¨¡æ‹Ÿäº¤æ˜“ (Live Trading) â†’ å®ç›˜å‰æµ‹è¯•
4. æ€§èƒ½åé¦ˆ â†’ å›ä¼ ç»™AIä¼˜åŒ–
5. è¿­ä»£ä¼˜åŒ– â†’ æŒç»­æ”¹è¿›

è¿™æ˜¯ Qilin Stack çš„æ ¸å¿ƒåˆ›æ–°:
- Qlib: æä¾›å›æµ‹å¼•æ“
- RD-Agent: æä¾›AIç­–ç•¥ç”Ÿæˆ
- Qilin Stack: å»ºç«‹å®Œæ•´é—­ç¯è¿æ¥

Author: Qilin Stack Team
Date: 2024-11-08
"""

import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import pandas as pd
import numpy as np
import json
from pathlib import Path

# å¯¼å…¥Qilin Stackæ ¸å¿ƒæ¨¡å—
from rd_agent.compat_wrapper import RDAgentWrapper
from rd_agent.logging_integration import QilinRDAgentLogger
from app.core.backtest_engine import BacktestEngine, Order, OrderSide, OrderType
from trading.live_trading_system import create_live_trading_system

logger = logging.getLogger(__name__)


@dataclass
class StrategyPerformance:
    """ç­–ç•¥æ€§èƒ½æŒ‡æ ‡"""
    strategy_id: str
    strategy_name: str
    
    # å›æµ‹æŒ‡æ ‡
    annual_return: float = 0.0
    sharpe_ratio: float = 0.0
    max_drawdown: float = 0.0
    win_rate: float = 0.0
    total_trades: int = 0
    
    # å› å­æŒ‡æ ‡
    ic_mean: float = 0.0
    icir: float = 0.0
    turnover: float = 0.0
    
    # å®ç›˜æŒ‡æ ‡ (æ¨¡æ‹Ÿäº¤æ˜“)
    live_pnl: float = 0.0
    live_sharpe: float = 0.0
    live_days: int = 0
    
    # ç»¼åˆè¯„åˆ†
    overall_score: float = 0.0
    
    # å…ƒæ•°æ®
    created_at: datetime = field(default_factory=datetime.now)
    last_updated: datetime = field(default_factory=datetime.now)
    iteration: int = 0


@dataclass
class FeedbackSignal:
    """åé¦ˆä¿¡å· - ç”¨äºAIä¼˜åŒ–"""
    signal_type: str  # 'positive', 'negative', 'neutral'
    aspect: str  # 'return', 'risk', 'stability', 'ic'
    message: str
    value: float
    suggestion: str  # ç»™AIçš„ä¼˜åŒ–å»ºè®®


class StrategyFeedbackLoop:
    """
    ç­–ç•¥ä¼˜åŒ–é—­ç¯ç³»ç»Ÿ
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. ä½¿ç”¨RD-Agentç”Ÿæˆç­–ç•¥
    2. å›æµ‹éªŒè¯ç­–ç•¥
    3. æ¨¡æ‹Ÿäº¤æ˜“æµ‹è¯•
    4. æ”¶é›†åé¦ˆä¿¡å·
    5. ä¼˜åŒ–è¿­ä»£
    """
    
    def __init__(self, 
                 rd_agent_config: Dict[str, Any],
                 backtest_config: Dict[str, Any],
                 live_config: Optional[Dict[str, Any]] = None,
                 workspace_path: str = "./strategy_loop"):
        """
        åˆå§‹åŒ–é—­ç¯ç³»ç»Ÿ
        
        Args:
            rd_agent_config: RD-Agenté…ç½®
            backtest_config: å›æµ‹é…ç½®
            live_config: å®ç›˜/æ¨¡æ‹Ÿç›˜é…ç½®
            workspace_path: å·¥ä½œç›®å½•
        """
        self.workspace_path = Path(workspace_path)
        self.workspace_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–å„ç»„ä»¶
        self.rd_agent = RDAgentWrapper(rd_agent_config)
        self.logger = QilinRDAgentLogger(str(self.workspace_path / 'logs'))
        self.backtest_engine = BacktestEngine(**backtest_config)
        
        # æ¨¡æ‹Ÿäº¤æ˜“ç³»ç»Ÿ (å¯é€‰)
        self.live_system = None
        if live_config:
            self.live_system = create_live_trading_system(live_config)
        
        # æ€§èƒ½è·Ÿè¸ª
        self.performance_history: List[StrategyPerformance] = []
        self.feedback_history: List[FeedbackSignal] = []
        self.current_iteration = 0
        
        logger.info("âœ… ç­–ç•¥ä¼˜åŒ–é—­ç¯ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    async def run_full_loop(self,
                           research_topic: str,
                           data: pd.DataFrame,
                           max_iterations: int = 5,
                           performance_threshold: float = 0.15) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–é—­ç¯
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            data: å†å²æ•°æ®
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            performance_threshold: æ€§èƒ½é˜ˆå€¼ (å¹´åŒ–æ”¶ç›Š>15%)
        
        Returns:
            æœ€ä¼˜ç­–ç•¥å’Œæ€§èƒ½æŠ¥å‘Š
        """
        logger.info(f"ğŸš€ å¼€å§‹ç­–ç•¥ä¼˜åŒ–é—­ç¯: {research_topic}")
        logger.info(f"   æœ€å¤§è¿­ä»£: {max_iterations}æ¬¡")
        logger.info(f"   ç›®æ ‡æ”¶ç›Š: >{performance_threshold*100}%")
        
        best_strategy = None
        best_performance = None
        
        for iteration in range(max_iterations):
            self.current_iteration = iteration + 1
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ”„ ç¬¬ {self.current_iteration}/{max_iterations} è½®è¿­ä»£")
            logger.info(f"{'='*60}")
            
            # ========== é˜¶æ®µ1: AIå› å­æŒ–æ˜ ==========
            logger.info("ğŸ¤– é˜¶æ®µ1: AIå› å­æŒ–æ˜...")
            
            # æ„å»ºåŒ…å«åé¦ˆçš„ç ”ç©¶ä¸»é¢˜
            enhanced_topic = self._enhance_topic_with_feedback(
                research_topic, 
                self.feedback_history
            )
            
            factors_result = await self.rd_agent.research_pipeline(
                research_topic=enhanced_topic,
                data=data,
                max_iterations=3
            )
            
            if not factors_result.get('factors'):
                logger.warning("âš ï¸ æœªå‘ç°æœ‰æ•ˆå› å­,è·³è¿‡æ­¤è½®")
                continue
            
            logger.info(f"âœ… å‘ç° {len(factors_result['factors'])} ä¸ªå› å­")
            
            # ========== é˜¶æ®µ2: ç­–ç•¥æ„å»º ==========
            logger.info("ğŸ“Š é˜¶æ®µ2: æ„å»ºäº¤æ˜“ç­–ç•¥...")
            
            strategy = self._build_strategy_from_factors(
                factors_result['factors']
            )
            
            # ========== é˜¶æ®µ3: å›æµ‹éªŒè¯ ==========
            logger.info("âš¡ é˜¶æ®µ3: å›æµ‹éªŒè¯...")
            
            backtest_result = await self._run_backtest(strategy, data)
            
            # ========== é˜¶æ®µ4: æ¨¡æ‹Ÿäº¤æ˜“ (å¯é€‰) ==========
            live_result = None
            if self.live_system:
                logger.info("ğŸ’¼ é˜¶æ®µ4: æ¨¡æ‹Ÿäº¤æ˜“æµ‹è¯•...")
                live_result = await self._run_live_test(strategy, data)
            
            # ========== é˜¶æ®µ5: æ€§èƒ½è¯„ä¼° ==========
            logger.info("ğŸ“ˆ é˜¶æ®µ5: æ€§èƒ½è¯„ä¼°...")
            
            performance = self._calculate_performance(
                strategy,
                factors_result,
                backtest_result,
                live_result
            )
            
            self.performance_history.append(performance)
            
            # è®°å½•åˆ°æ—¥å¿—
            self.logger.log_experiment(
                {
                    'iteration': iteration,
                    'strategy': strategy,
                    'performance': performance.__dict__
                },
                tag=f'loop.{research_topic}'
            )
            
            logger.info(f"\n{'='*60}")
            logger.info("ğŸ“Š æœ¬è½®æ€§èƒ½:")
            logger.info(f"   å¹´åŒ–æ”¶ç›Š: {performance.annual_return*100:.2f}%")
            logger.info(f"   å¤æ™®æ¯”ç‡: {performance.sharpe_ratio:.2f}")
            logger.info(f"   æœ€å¤§å›æ’¤: {performance.max_drawdown*100:.2f}%")
            logger.info(f"   ICå‡å€¼: {performance.ic_mean:.4f}")
            logger.info(f"   ç»¼åˆå¾—åˆ†: {performance.overall_score:.2f}/100")
            logger.info(f"{'='*60}\n")
            
            # ========== é˜¶æ®µ6: ç”Ÿæˆåé¦ˆ ==========
            logger.info("ğŸ” é˜¶æ®µ6: ç”Ÿæˆä¼˜åŒ–åé¦ˆ...")
            
            feedback_signals = self._generate_feedback(
                performance,
                backtest_result
            )
            
            self.feedback_history.extend(feedback_signals)
            
            for signal in feedback_signals:
                logger.info(f"   [{signal.signal_type.upper()}] {signal.aspect}: {signal.message}")
            
            # ========== é˜¶æ®µ7: åˆ¤æ–­æ˜¯å¦è¾¾æ ‡ ==========
            if performance.annual_return > performance_threshold:
                if best_performance is None or \
                   performance.overall_score > best_performance.overall_score:
                    best_strategy = strategy
                    best_performance = performance
                    
                    logger.info(f"âœ… å‘ç°æ›´ä¼˜ç­–ç•¥! ç»¼åˆå¾—åˆ†: {performance.overall_score:.2f}")
                    
                    # å¦‚æœè¶³å¤Ÿå¥½,å¯ä»¥æå‰ç»“æŸ
                    if performance.overall_score > 85:
                        logger.info("ğŸ‰ å‘ç°ä¼˜ç§€ç­–ç•¥,æå‰ç»“æŸä¼˜åŒ–")
                        break
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            self._save_checkpoint(iteration, strategy, performance)
        
        # ========== ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š ==========
        final_report = self._generate_final_report(
            best_strategy,
            best_performance,
            research_topic
        )
        
        logger.info(f"\n{'='*60}")
        logger.info("ğŸŠ ä¼˜åŒ–é—­ç¯å®Œæˆ!")
        logger.info(f"   æ€»è¿­ä»£æ¬¡æ•°: {self.current_iteration}")
        logger.info(f"   æœ€ä¼˜å¹´åŒ–æ”¶ç›Š: {best_performance.annual_return*100:.2f}%")
        logger.info(f"   æœ€ä¼˜å¤æ™®: {best_performance.sharpe_ratio:.2f}")
        logger.info(f"   æœ€ä¼˜å¾—åˆ†: {best_performance.overall_score:.2f}/100")
        logger.info(f"{'='*60}\n")
        
        return final_report
    
    def _enhance_topic_with_feedback(self,
                                     topic: str,
                                     feedback: List[FeedbackSignal]) -> str:
        """
        ä½¿ç”¨åé¦ˆä¿¡å·å¢å¼ºç ”ç©¶ä¸»é¢˜
        
        è¿™æ˜¯é—­ç¯çš„å…³é”®: å°†ä¸Šä¸€è½®çš„é—®é¢˜å‘Šè¯‰AI
        """
        if not feedback:
            return topic
        
        # è·å–æœ€è¿‘çš„åé¦ˆ
        recent_feedback = feedback[-5:]  # æœ€è¿‘5æ¡
        
        suggestions = []
        for signal in recent_feedback:
            if signal.signal_type == 'negative':
                suggestions.append(signal.suggestion)
        
        if suggestions:
            enhanced = f"{topic}\n\nä¼˜åŒ–å»ºè®®:\n"
            enhanced += "\n".join(f"- {s}" for s in suggestions)
            return enhanced
        
        return topic
    
    def _build_strategy_from_factors(self, factors: List) -> Dict[str, Any]:
        """
        ä»å› å­æ„å»ºäº¤æ˜“ç­–ç•¥
        
        ç­–ç•¥åŒ…å«:
        - å› å­ç»„åˆ
        - æƒé‡åˆ†é…
        - äº¤æ˜“è§„åˆ™
        """
        strategy = {
            'name': f'AI_Strategy_{self.current_iteration}',
            'factors': [],
            'weights': [],
            'rules': {
                'rebalance_frequency': 'weekly',  # æ¯å‘¨è°ƒä»“
                'top_k': 30,  # ä¹°å…¥å‰30åª
                'position_limit': 0.1,  # å•åªè‚¡ç¥¨æœ€å¤š10%
                'stop_loss': -0.05,  # æ­¢æŸ5%
                'take_profit': 0.15  # æ­¢ç›ˆ15%
            }
        }
        
        # æå–å› å­
        for factor in factors:
            strategy['factors'].append({
                'name': factor.name,
                'expression': factor.expression,
                'ic': factor.performance.get('ic', 0)
            })
            
            # æ ¹æ®ICåˆ†é…æƒé‡
            ic = abs(factor.performance.get('ic', 0))
            strategy['weights'].append(ic)
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(strategy['weights'])
        if total_weight > 0:
            strategy['weights'] = [w/total_weight for w in strategy['weights']]
        else:
            # å‡åˆ†æƒé‡
            n = len(strategy['factors'])
            strategy['weights'] = [1.0/n] * n
        
        return strategy
    
    async def _run_backtest(self,
                           strategy: Dict[str, Any],
                           data: pd.DataFrame) -> Dict[str, Any]:
        """
        è¿è¡Œå›æµ‹
        
        Returns:
            å›æµ‹ç»“æœ (æ”¶ç›Šæ›²çº¿, äº¤æ˜“è®°å½•ç­‰)
        """
        # è®¾ç½®æ•°æ®
        self.backtest_engine.set_data(data)
        
        # è®¡ç®—å› å­ä¿¡å·
        signals = self._calculate_factor_signals(strategy, data)
        
        # æ¨¡æ‹Ÿäº¤æ˜“
        for date, signal_data in signals.iterrows():
            self.backtest_engine.current_timestamp = date
            
            # è§£å†»æŒä»“ (T+1)
            self.backtest_engine.portfolio.unfreeze_positions(date)
            
            # æ ¹æ®ä¿¡å·ç”Ÿæˆè®¢å•
            top_stocks = signal_data.nlargest(strategy['rules']['top_k'])
            
            for symbol, score in top_stocks.items():
                if score > 0:
                    # ä¹°å…¥ä¿¡å·
                    # è®¡ç®—ä¹°å…¥æ•°é‡ (ç­‰æƒé‡)
                    target_value = (
                        self.backtest_engine.portfolio.get_total_value() * 
                        strategy['rules']['position_limit']
                    )
                    
                    current_price = self._get_price(data, symbol, date)
                    if current_price > 0:
                        quantity = int(target_value / current_price / 100) * 100  # 100è‚¡æ•´æ•°å€
                        
                        if quantity > 0:
                            order = Order(
                                symbol=symbol,
                                side=OrderSide.BUY,
                                order_type=OrderType.MARKET,
                                quantity=quantity
                            )
                            self.backtest_engine.place_order(order)
            
            # æ­¢æŸ/æ­¢ç›ˆæ£€æŸ¥
            for symbol, position in list(self.backtest_engine.portfolio.positions.items()):
                pnl_pct = position.unrealized_pnl / position.cost_basis
                
                # æ­¢æŸ
                if pnl_pct < strategy['rules']['stop_loss']:
                    if position.available_quantity > 0:
                        order = Order(
                            symbol=symbol,
                            side=OrderSide.SELL,
                            order_type=OrderType.MARKET,
                            quantity=position.available_quantity
                        )
                        self.backtest_engine.place_order(order)
                
                # æ­¢ç›ˆ
                elif pnl_pct > strategy['rules']['take_profit']:
                    if position.available_quantity > 0:
                        order = Order(
                            symbol=symbol,
                            side=OrderSide.SELL,
                            order_type=OrderType.MARKET,
                            quantity=position.available_quantity
                        )
                        self.backtest_engine.place_order(order)
        
        # è®¡ç®—å›æµ‹ç»“æœ
        result = {
            'equity_curve': self.backtest_engine.portfolio.equity_curve,
            'trades': self.backtest_engine.portfolio.trades,
            'final_value': self.backtest_engine.portfolio.get_total_value(),
            'returns': self.backtest_engine.portfolio.get_returns()
        }
        
        return result
    
    def _calculate_factor_signals(self,
                                  strategy: Dict[str, Any],
                                  data: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—å› å­ä¿¡å·
        
        Returns:
            æ¯æ—¥æ¯åªè‚¡ç¥¨çš„ç»¼åˆå¾—åˆ†
        """
        # ç®€åŒ–ç‰ˆ: ä½¿ç”¨å› å­è¡¨è¾¾å¼è®¡ç®—
        # å®é™…åº”ä½¿ç”¨Qlibçš„Alphaè¡¨è¾¾å¼å¼•æ“
        
        signals = pd.DataFrame(index=data.index)
        
        for i, factor in enumerate(strategy['factors']):
            weight = strategy['weights'][i]
            
            # è¿™é‡Œç®€åŒ–å¤„ç†,å®é™…åº”è§£æfactor['expression']
            # ç¤ºä¾‹: ä½¿ç”¨æ”¶ç›Šç‡ä½œä¸ºä¿¡å·
            factor_score = data.pct_change(20)  # 20æ—¥æ”¶ç›Šç‡
            signals[f'factor_{i}'] = factor_score * weight
        
        # ç»¼åˆå¾—åˆ†
        composite_signal = signals.sum(axis=1)
        
        return composite_signal
    
    def _get_price(self, data: pd.DataFrame, symbol: str, date: datetime) -> float:
        """è·å–æŒ‡å®šæ—¥æœŸçš„ä»·æ ¼"""
        try:
            # ç®€åŒ–ç‰ˆ: å‡è®¾dataæ˜¯å•è‚¡ç¥¨æ•°æ®
            price = data.loc[date, 'close']
            return price
        except:
            return 0.0
    
    async def _run_live_test(self,
                            strategy: Dict[str, Any],
                            data: pd.DataFrame) -> Dict[str, Any]:
        """
        è¿è¡Œæ¨¡æ‹Ÿäº¤æ˜“æµ‹è¯•
        
        ä½¿ç”¨æœ€è¿‘çš„æ•°æ®è¿›è¡Œæ¨¡æ‹Ÿ
        """
        # å®ç°æ¨¡æ‹Ÿäº¤æ˜“é€»è¾‘
        # è¿™é‡Œç®€åŒ–,å®é™…åº”è¿æ¥live_trading_system
        
        return {
            'live_pnl': 0.0,
            'live_sharpe': 0.0,
            'live_days': 0
        }
    
    def _calculate_performance(self,
                               strategy: Dict[str, Any],
                               factors_result: Dict[str, Any],
                               backtest_result: Dict[str, Any],
                               live_result: Optional[Dict[str, Any]]) -> StrategyPerformance:
        """
        è®¡ç®—ç»¼åˆæ€§èƒ½
        """
        # å›æµ‹æŒ‡æ ‡
        returns_series = pd.Series(backtest_result.get('returns', [0]))
        annual_return = returns_series.mean() * 252 if len(returns_series) > 0 else 0
        sharpe = (returns_series.mean() / returns_series.std() * np.sqrt(252)) if returns_series.std() > 0 else 0
        
        equity_curve = pd.Series([e[1] for e in backtest_result.get('equity_curve', [])])
        running_max = equity_curve.expanding().max()
        drawdown = (equity_curve - running_max) / running_max
        max_dd = abs(drawdown.min()) if len(drawdown) > 0 else 0
        
        # å› å­æŒ‡æ ‡
        factors = factors_result.get('factors', [])
        ic_values = [f.performance.get('ic', 0) for f in factors if f.performance]
        ic_mean = np.mean(ic_values) if ic_values else 0
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        score = 0
        score += min(annual_return * 100, 40)  # æ”¶ç›Š 40åˆ†
        score += min(sharpe * 10, 30)  # å¤æ™® 30åˆ†
        score += max(20 - max_dd * 100, 0)  # å›æ’¤ 20åˆ†
        score += min(abs(ic_mean) * 100, 10)  # IC 10åˆ†
        
        performance = StrategyPerformance(
            strategy_id=strategy['name'],
            strategy_name=strategy['name'],
            annual_return=annual_return,
            sharpe_ratio=sharpe,
            max_drawdown=max_dd,
            total_trades=len(backtest_result.get('trades', [])),
            ic_mean=ic_mean,
            overall_score=score,
            iteration=self.current_iteration
        )
        
        # å®ç›˜æŒ‡æ ‡
        if live_result:
            performance.live_pnl = live_result.get('live_pnl', 0)
            performance.live_sharpe = live_result.get('live_sharpe', 0)
            performance.live_days = live_result.get('live_days', 0)
        
        return performance
    
    def _generate_feedback(self,
                          performance: StrategyPerformance,
                          backtest_result: Dict[str, Any]) -> List[FeedbackSignal]:
        """
        ç”Ÿæˆåé¦ˆä¿¡å·
        
        è¿™æ˜¯é—­ç¯çš„å…³é”®: åˆ†æé—®é¢˜,ç»™å‡ºå»ºè®®
        """
        feedback = []
        
        # 1. æ”¶ç›Šåé¦ˆ
        if performance.annual_return < 0.10:
            feedback.append(FeedbackSignal(
                signal_type='negative',
                aspect='return',
                message=f'æ”¶ç›Šç‡åä½ ({performance.annual_return*100:.2f}%)',
                value=performance.annual_return,
                suggestion='å°è¯•æ›´æ¿€è¿›çš„å› å­,å¦‚åŠ¨é‡ã€åè½¬ç­‰'
            ))
        elif performance.annual_return > 0.20:
            feedback.append(FeedbackSignal(
                signal_type='positive',
                aspect='return',
                message=f'æ”¶ç›Šç‡ä¼˜ç§€ ({performance.annual_return*100:.2f}%)',
                value=performance.annual_return,
                suggestion='ä¿æŒå½“å‰å› å­æ–¹å‘'
            ))
        
        # 2. é£é™©åé¦ˆ
        if performance.sharpe_ratio < 1.0:
            feedback.append(FeedbackSignal(
                signal_type='negative',
                aspect='risk',
                message=f'å¤æ™®æ¯”ç‡åä½ ({performance.sharpe_ratio:.2f})',
                value=performance.sharpe_ratio,
                suggestion='å¢åŠ é£é™©æ§åˆ¶,è€ƒè™‘æ³¢åŠ¨ç‡å› å­'
            ))
        
        if performance.max_drawdown > 0.25:
            feedback.append(FeedbackSignal(
                signal_type='negative',
                aspect='risk',
                message=f'å›æ’¤è¿‡å¤§ ({performance.max_drawdown*100:.2f}%)',
                value=performance.max_drawdown,
                suggestion='åŠ å¼ºæ­¢æŸç­–ç•¥,é™ä½ä»“ä½'
            ))
        
        # 3. å› å­è´¨é‡åé¦ˆ
        if abs(performance.ic_mean) < 0.03:
            feedback.append(FeedbackSignal(
                signal_type='negative',
                aspect='ic',
                message=f'ICå€¼åä½ ({performance.ic_mean:.4f})',
                value=performance.ic_mean,
                suggestion='æ¢ç´¢æ–°çš„å› å­ç»´åº¦,å¦‚åŸºæœ¬é¢ã€æƒ…ç»ªç­‰'
            ))
        
        # 4. ç¨³å®šæ€§åé¦ˆ
        if len(self.performance_history) > 1:
            prev_performance = self.performance_history[-2]
            return_change = abs(performance.annual_return - prev_performance.annual_return)
            
            if return_change > 0.10:
                feedback.append(FeedbackSignal(
                    signal_type='negative',
                    aspect='stability',
                    message=f'ç­–ç•¥ä¸ç¨³å®š,æ”¶ç›Šæ³¢åŠ¨å¤§ ({return_change*100:.2f}%)',
                    value=return_change,
                    suggestion='å¯»æ‰¾æ›´ç¨³å¥çš„å› å­ç»„åˆ'
                ))
        
        return feedback
    
    def _save_checkpoint(self,
                        iteration: int,
                        strategy: Dict[str, Any],
                        performance: StrategyPerformance):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_dir = self.workspace_path / 'checkpoints'
        checkpoint_dir.mkdir(exist_ok=True)
        
        checkpoint = {
            'iteration': iteration,
            'strategy': strategy,
            'performance': performance.__dict__,
            'timestamp': datetime.now().isoformat()
        }
        
        checkpoint_file = checkpoint_dir / f'checkpoint_{iteration}.json'
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False, default=str)
        
        logger.debug(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_file}")
    
    def _generate_final_report(self,
                              best_strategy: Dict[str, Any],
                              best_performance: StrategyPerformance,
                              research_topic: str) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report = {
            'research_topic': research_topic,
            'total_iterations': self.current_iteration,
            'best_strategy': best_strategy,
            'best_performance': best_performance.__dict__,
            'performance_history': [p.__dict__ for p in self.performance_history],
            'improvement': {
                'return': (
                    best_performance.annual_return - self.performance_history[0].annual_return
                    if self.performance_history else 0
                ),
                'sharpe': (
                    best_performance.sharpe_ratio - self.performance_history[0].sharpe_ratio
                    if self.performance_history else 0
                )
            },
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.workspace_path / 'final_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    
    # 1. é…ç½®
    rd_agent_config = {
        'llm_model': 'gpt-4',
        'llm_api_key': 'your-api-key',
        'max_iterations': 5,
        'workspace_path': './logs/rdagent'
    }
    
    backtest_config = {
        'initial_capital': 1000000,
        'commission_rate': 0.0003,
        'slippage_rate': 0.0001
    }
    
    live_config = {
        'broker_name': 'mock',
        'initial_cash': 100000,
        'risk_config': {
            'max_position': 0.1,
            'stop_loss': -0.05
        }
    }
    
    # 2. åˆ›å»ºé—­ç¯ç³»ç»Ÿ
    loop_system = StrategyFeedbackLoop(
        rd_agent_config=rd_agent_config,
        backtest_config=backtest_config,
        live_config=live_config,
        workspace_path='./strategy_loop'
    )
    
    # 3. å‡†å¤‡æ•°æ®
    # è¿™é‡Œåº”è¯¥åŠ è½½çœŸå®çš„è‚¡ç¥¨æ•°æ®
    import pandas as pd
    data = pd.DataFrame({
        'date': pd.date_range('2020-01-01', '2024-01-01'),
        'close': np.random.randn(1461).cumsum() + 100,
        'volume': np.random.randint(1000000, 10000000, 1461)
    }).set_index('date')
    
    # 4. è¿è¡Œé—­ç¯ä¼˜åŒ–
    result = await loop_system.run_full_loop(
        research_topic="å¯»æ‰¾Aè‚¡çŸ­æœŸåŠ¨é‡å› å­",
        data=data,
        max_iterations=5,
        performance_threshold=0.15
    )
    
    print("\nğŸ‰ ä¼˜åŒ–å®Œæˆ!")
    print(f"æœ€ä¼˜å¹´åŒ–æ”¶ç›Š: {result['best_performance']['annual_return']*100:.2f}%")
    print(f"æœ€ä¼˜å¤æ™®æ¯”ç‡: {result['best_performance']['sharpe_ratio']:.2f}")
    print(f"æ”¶ç›Šæå‡: {result['improvement']['return']*100:.2f}%")


if __name__ == '__main__':
    import asyncio
    asyncio.run(example_usage())
