"""
ä¸€è¿›äºŒç­–ç•¥ä¸“ç”¨è¯„ä¼°æŒ‡æ ‡
è®¡ç®—P@N, Hit@N, æ¿å¼ºåº¦ç­‰æ ¸å¿ƒæŒ‡æ ‡
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)


@dataclass
class OneIntoTwoMetrics:
    """
    ä¸€è¿›äºŒä¸“ç”¨æŒ‡æ ‡ - T+1åˆ¶åº¦é€‚é…ç‰ˆ
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    - æ–°å¢T+1æ”¶ç›˜æ”¶ç›ŠæŒ‡æ ‡ï¼ˆå› ä¸ºT+1æ— æ³•å–å‡ºï¼‰
    - æ–°å¢T+1æœ€å¤§æµ®äºï¼ˆé£é™©æŒ‡æ ‡ï¼‰
    - æ–°å¢T+2æœ€ç»ˆæ”¶ç›Šï¼ˆå®é™…è·åˆ©ï¼‰
    - ä¿ç•™å…¼å®¹æ—§ç‰ˆæŒ‡æ ‡
    """
    # åŸºç¡€ç»Ÿè®¡
    date: str
    total_limitups: int      # å½“æ—¥æ¶¨åœæ€»æ•°
    predicted_count: int     # é¢„æµ‹æ•°é‡
    hit_count: int          # å‘½ä¸­æ•°é‡ï¼ˆæ¬¡æ—¥æ¶¨åœï¼‰
    touch_count: int        # è§¦æ¿æ•°é‡ï¼ˆæ¬¡æ—¥è§¦åŠæ¶¨åœï¼‰
    
    # æ ¸å¿ƒæŒ‡æ ‡
    precision_at_n: float   # P@N: é¢„æµ‹å‡†ç¡®ç‡
    hit_at_n: float        # Hit@N: å‘½ä¸­ç‡ï¼ˆç›¸å¯¹äºæ€»æ¶¨åœæ± ï¼‰
    board_strength: float   # æ¿å¼ºåº¦ï¼šå°æ¿æ—¶é—´/åŠ›åº¦ç»¼åˆ
    
    # ç»†åˆ†æŒ‡æ ‡
    first_board_hit: int    # é¦–æ¿å‘½ä¸­æ•°
    multi_board_hit: int    # è¿æ¿å‘½ä¸­æ•°
    theme_hit_rate: float   # é¢˜æå‘½ä¸­ç‡
    sector_concentration: float  # æ¿å—é›†ä¸­åº¦
    
    # æ‰§è¡ŒæŒ‡æ ‡ï¼ˆç«ä»·ä¹°å…¥æ¨¡å¼ï¼‰
    avg_queue_position: float  # å¹³å‡æ’é˜Ÿä½ç½®ï¼ˆæ’æ¿æ¨¡å¼ï¼‰
    avg_fill_ratio: float     # å¹³å‡æˆäº¤æ¯”ä¾‹
    unfilled_rate: float      # æœªæˆäº¤ç‡
    avg_auction_gap: float = 0.0  # å¹³å‡ç«ä»·æ¶¨å¹…ï¼ˆæ–°å¢ï¼‰
    
    # T+1æ”¶ç›ŠæŒ‡æ ‡ï¼ˆæ–°å¢ - å…³é”®æŒ‡æ ‡ï¼‰
    t1_close_avg_return: float = 0.0     # T+1å¹³å‡æ”¶ç›˜æ”¶ç›Šç‡
    t1_positive_rate: float = 0.0        # T+1æ”¶ç›˜ç›ˆåˆ©ç‡ï¼ˆ>0çš„æ¯”ä¾‹ï¼‰
    t1_avg_max_return: float = 0.0       # T+1å¹³å‡æœ€å¤§æµ®ç›ˆ
    t1_avg_min_return: float = 0.0       # T+1å¹³å‡æœ€å¤§æµ®äºï¼ˆé£é™©ï¼‰
    max_unrealized_loss: float = 0.0     # T+1æœ€å¤§æœªå®ç°äºæŸ
    
    # T+2æœ€ç»ˆæ”¶ç›ŠæŒ‡æ ‡ï¼ˆæ–°å¢ï¼‰
    t2_final_return: float = 0.0         # T+2æœ€ç»ˆå¹³å‡æ”¶ç›Š
    t2_positive_rate: float = 0.0        # T+2æœ€ç»ˆç›ˆåˆ©ç‡
    t2_best_sell_return: float = 0.0     # T+2æœ€ä½³å–å‡ºæ”¶ç›Š
    
    # ä¼ ç»Ÿæ”¶ç›ŠæŒ‡æ ‡ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
    avg_next_day_return: float = 0.0     # æ¬¡æ—¥å¹³å‡æ”¶ç›Šï¼ˆ=t1_close_avg_returnï¼‰
    win_loss_ratio: float = 0.0          # ç›ˆäºæ¯”
    max_single_return: float = 0.0       # æœ€å¤§å•ç¥¨æ”¶ç›Š
    max_single_loss: float = 0.0         # æœ€å¤§å•ç¥¨äºæŸ


class OneIntoTwoEvaluator:
    """ä¸€è¿›äºŒç­–ç•¥è¯„ä¼°å™¨"""
    
    def __init__(self, limit_types: Optional[Dict[str, float]] = None):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            limit_types: æ¶¨è·Œåœé™åˆ¶ {æ™®é€š: 0.1, ç§‘åˆ›: 0.2, ST: 0.05}
        """
        self.limit_types = limit_types or {
            'normal': 0.10,
            'kcb': 0.20,
            'st': 0.05
        }
        self.metrics_history: List[OneIntoTwoMetrics] = []
    
    def evaluate_predictions(self, 
                            predictions: pd.DataFrame,
                            actual_results: pd.DataFrame,
                            date: str) -> OneIntoTwoMetrics:
        """
        è¯„ä¼°é¢„æµ‹ç»“æœ
        
        Args:
            predictions: é¢„æµ‹DataFrameï¼Œå« [symbol, prob, rank]
            actual_results: å®é™…ç»“æœDataFrameï¼Œå« [symbol, is_limit_up, touch_limit, return]
            date: è¯„ä¼°æ—¥æœŸ
            
        Returns:
            OneIntoTwoMetrics: è¯„ä¼°æŒ‡æ ‡
        """
        # åˆå¹¶é¢„æµ‹å’Œå®é™…
        merged = pd.merge(
            predictions, actual_results, 
            on='symbol', how='left'
        )
        
        # åŸºç¡€ç»Ÿè®¡
        total_limitups = len(actual_results[actual_results['is_limit_up'] == True])
        predicted_count = len(predictions)
        hit_count = merged['is_limit_up'].sum()
        touch_count = merged['touch_limit'].sum()
        
        # æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—
        precision_at_n = hit_count / predicted_count if predicted_count > 0 else 0
        hit_at_n = hit_count / total_limitups if total_limitups > 0 else 0
        
        # æ¿å¼ºåº¦è®¡ç®—
        board_strength = self._calculate_board_strength(merged)
        
        # ç»†åˆ†æŒ‡æ ‡
        first_board_hit = self._count_first_board_hits(merged)
        multi_board_hit = hit_count - first_board_hit
        theme_hit_rate = self._calculate_theme_hit_rate(merged)
        sector_concentration = self._calculate_sector_concentration(merged)
        
        # æ‰§è¡ŒæŒ‡æ ‡
        avg_queue_position = merged.get('queue_position', pd.Series([0.5])).mean()
        avg_fill_ratio = merged.get('fill_ratio', pd.Series([1.0])).mean()
        unfilled_rate = (merged.get('fill_ratio', pd.Series([1.0])) < 0.01).mean()
        
        # æ”¶ç›ŠæŒ‡æ ‡
        returns = merged.get('return', pd.Series([0]))
        avg_next_day_return = returns.mean()
        
        positive_returns = returns[returns > 0]
        negative_returns = returns[returns < 0]
        
        if len(negative_returns) > 0 and negative_returns.mean() != 0:
            win_loss_ratio = abs(positive_returns.mean() / negative_returns.mean())
        else:
            win_loss_ratio = float('inf') if len(positive_returns) > 0 else 0
        
        max_single_return = returns.max() if len(returns) > 0 else 0
        max_single_loss = returns.min() if len(returns) > 0 else 0
        
        metrics = OneIntoTwoMetrics(
            date=date,
            total_limitups=total_limitups,
            predicted_count=predicted_count,
            hit_count=hit_count,
            touch_count=touch_count,
            precision_at_n=precision_at_n,
            hit_at_n=hit_at_n,
            board_strength=board_strength,
            first_board_hit=first_board_hit,
            multi_board_hit=multi_board_hit,
            theme_hit_rate=theme_hit_rate,
            sector_concentration=sector_concentration,
            avg_queue_position=avg_queue_position,
            avg_fill_ratio=avg_fill_ratio,
            unfilled_rate=unfilled_rate,
            avg_auction_gap=avg_auction_gap,
            # T+1æŒ‡æ ‡ï¼ˆæ–°å¢ï¼‰
            t1_close_avg_return=t1_close_avg_return,
            t1_positive_rate=t1_positive_rate,
            t1_avg_max_return=t1_avg_max_return,
            t1_avg_min_return=t1_avg_min_return,
            max_unrealized_loss=max_unrealized_loss,
            # T+2æŒ‡æ ‡ï¼ˆæ–°å¢ï¼‰
            t2_final_return=t2_final_return,
            t2_positive_rate=t2_positive_rate,
            t2_best_sell_return=t2_best_sell_return,
            # ä¼ ç»ŸæŒ‡æ ‡ï¼ˆå…¼å®¹ï¼‰
            avg_next_day_return=avg_next_day_return,
            win_loss_ratio=win_loss_ratio,
            max_single_return=max_single_return,
            max_single_loss=max_single_loss
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def _calculate_board_strength(self, data: pd.DataFrame) -> float:
        """è®¡ç®—æ¿å¼ºåº¦"""
        if data.empty:
            return 0
        
        # ä½¿ç”¨å°æ¿æ—¶é—´ã€å°å•é‡ç­‰è®¡ç®—
        # è¿™é‡Œç®€åŒ–ä¸ºå‘½ä¸­ç‡çš„åŠ æƒ
        hit_rate = data['is_limit_up'].mean() if 'is_limit_up' in data else 0
        touch_rate = data['touch_limit'].mean() if 'touch_limit' in data else 0
        
        return hit_rate * 0.7 + touch_rate * 0.3
    
    def _count_first_board_hits(self, data: pd.DataFrame) -> int:
        """ç»Ÿè®¡é¦–æ¿å‘½ä¸­æ•°"""
        if 'board_count' not in data.columns:
            return 0
        
        first_boards = data[data['board_count'] == 1]
        return first_boards['is_limit_up'].sum()
    
    def _calculate_theme_hit_rate(self, data: pd.DataFrame) -> float:
        """è®¡ç®—é¢˜æå‘½ä¸­ç‡"""
        if 'theme' not in data.columns:
            return 0
        
        # æŒ‰é¢˜æåˆ†ç»„è®¡ç®—å‘½ä¸­ç‡
        theme_hits = data.groupby('theme')['is_limit_up'].mean()
        return theme_hits.mean() if len(theme_hits) > 0 else 0
    
    def _calculate_sector_concentration(self, data: pd.DataFrame) -> float:
        """è®¡ç®—æ¿å—é›†ä¸­åº¦ï¼ˆHHIæŒ‡æ•°ï¼‰"""
        if 'sector' not in data.columns:
            return 0
        
        sector_counts = data['sector'].value_counts()
        total = len(data)
        
        if total == 0:
            return 0
        
        # è®¡ç®—HHIï¼ˆèµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°ï¼‰
        hhi = sum((count/total) ** 2 for count in sector_counts)
        return hhi
    
    def calculate_daily_metrics(self,
                               predictions: Dict[str, pd.DataFrame],
                               actual_results: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """
        è®¡ç®—å¤šæ—¥è¯„ä¼°æŒ‡æ ‡
        
        Args:
            predictions: {date: predictions_df}
            actual_results: {date: results_df}
            
        Returns:
            DataFrame with daily metrics
        """
        daily_metrics = []
        
        for date in predictions.keys():
            if date not in actual_results:
                continue
            
            metrics = self.evaluate_predictions(
                predictions[date],
                actual_results[date],
                date
            )
            
            daily_metrics.append({
                'æ—¥æœŸ': date,
                'é¢„æµ‹æ•°': metrics.predicted_count,
                'å‘½ä¸­æ•°': metrics.hit_count,
                'P@N': metrics.precision_at_n,
                'Hit@N': metrics.hit_at_n,
                'æ¿å¼ºåº¦': metrics.board_strength,
                'å¹³å‡æ”¶ç›Š': metrics.avg_next_day_return,
                'ç›ˆäºæ¯”': metrics.win_loss_ratio,
                'æˆäº¤ç‡': metrics.avg_fill_ratio,
                'æœªæˆäº¤ç‡': metrics.unfilled_rate
            })
        
        return pd.DataFrame(daily_metrics)
    
    def calculate_cumulative_metrics(self) -> Dict[str, float]:
        """è®¡ç®—ç´¯è®¡æŒ‡æ ‡"""
        if not self.metrics_history:
            return {}
        
        total_predicted = sum(m.predicted_count for m in self.metrics_history)
        total_hit = sum(m.hit_count for m in self.metrics_history)
        total_touch = sum(m.touch_count for m in self.metrics_history)
        
        avg_precision = total_hit / total_predicted if total_predicted > 0 else 0
        avg_hit_rate = np.mean([m.hit_at_n for m in self.metrics_history])
        avg_board_strength = np.mean([m.board_strength for m in self.metrics_history])
        
        avg_return = np.mean([m.avg_next_day_return for m in self.metrics_history])
        best_day_return = max(m.avg_next_day_return for m in self.metrics_history)
        worst_day_return = min(m.avg_next_day_return for m in self.metrics_history)
        
        avg_fill_ratio = np.mean([m.avg_fill_ratio for m in self.metrics_history])
        avg_unfilled = np.mean([m.unfilled_rate for m in self.metrics_history])
        
        return {
            'æ€»é¢„æµ‹æ•°': total_predicted,
            'æ€»å‘½ä¸­æ•°': total_hit,
            'æ€»è§¦æ¿æ•°': total_touch,
            'å¹³å‡P@N': avg_precision,
            'å¹³å‡Hit@N': avg_hit_rate,
            'å¹³å‡æ¿å¼ºåº¦': avg_board_strength,
            'å¹³å‡æ—¥æ”¶ç›Š': avg_return,
            'æœ€ä½³æ—¥æ”¶ç›Š': best_day_return,
            'æœ€å·®æ—¥æ”¶ç›Š': worst_day_return,
            'å¹³å‡æˆäº¤ç‡': avg_fill_ratio,
            'å¹³å‡æœªæˆäº¤ç‡': avg_unfilled,
            'è¯„ä¼°å¤©æ•°': len(self.metrics_history)
        }
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        cumulative = self.calculate_cumulative_metrics()
        
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š ä¸€è¿›äºŒç­–ç•¥è¯„ä¼°æŠ¥å‘Š")
        report.append("=" * 60)
        
        report.append("\nğŸ“ˆ æ•´ä½“è¡¨ç°")
        report.append(f"  è¯„ä¼°å¤©æ•°: {cumulative.get('è¯„ä¼°å¤©æ•°', 0)}å¤©")
        report.append(f"  æ€»é¢„æµ‹æ•°: {cumulative.get('æ€»é¢„æµ‹æ•°', 0)}")
        report.append(f"  æ€»å‘½ä¸­æ•°: {cumulative.get('æ€»å‘½ä¸­æ•°', 0)}")
        
        report.append("\nğŸ¯ æ ¸å¿ƒæŒ‡æ ‡")
        report.append(f"  å¹³å‡P@N: {cumulative.get('å¹³å‡P@N', 0):.2%}")
        report.append(f"  å¹³å‡Hit@N: {cumulative.get('å¹³å‡Hit@N', 0):.2%}")
        report.append(f"  å¹³å‡æ¿å¼ºåº¦: {cumulative.get('å¹³å‡æ¿å¼ºåº¦', 0):.3f}")
        
        report.append("\nğŸ’° æ”¶ç›ŠæŒ‡æ ‡")
        report.append(f"  å¹³å‡æ—¥æ”¶ç›Š: {cumulative.get('å¹³å‡æ—¥æ”¶ç›Š', 0):.2%}")
        report.append(f"  æœ€ä½³æ—¥æ”¶ç›Š: {cumulative.get('æœ€ä½³æ—¥æ”¶ç›Š', 0):.2%}")
        report.append(f"  æœ€å·®æ—¥æ”¶ç›Š: {cumulative.get('æœ€å·®æ—¥æ”¶ç›Š', 0):.2%}")
        
        report.append("\nğŸ“Š æ‰§è¡ŒæŒ‡æ ‡")
        report.append(f"  å¹³å‡æˆäº¤ç‡: {cumulative.get('å¹³å‡æˆäº¤ç‡', 0):.2%}")
        report.append(f"  å¹³å‡æœªæˆäº¤ç‡: {cumulative.get('å¹³å‡æœªæˆäº¤ç‡', 0):.2%}")
        
        # æœ€è¿‘5æ—¥è¡¨ç°
        if len(self.metrics_history) > 0:
            report.append("\nğŸ“… æœ€è¿‘è¡¨ç°")
            for m in self.metrics_history[-5:]:
                report.append(
                    f"  {m.date}: P@N={m.precision_at_n:.1%}, "
                    f"å‘½ä¸­={m.hit_count}/{m.predicted_count}, "
                    f"æ”¶ç›Š={m.avg_next_day_return:.2%}"
                )
        
        report.append("\n" + "=" * 60)
        return "\n".join(report)


def evaluate_one_into_two_backtest(backtest_results: Dict,
                                  predictions: pd.DataFrame) -> Dict[str, float]:
    """
    è¯„ä¼°ä¸€è¿›äºŒå›æµ‹ç»“æœ
    
    Args:
        backtest_results: å›æµ‹ç»“æœå­—å…¸
        predictions: é¢„æµ‹æ•°æ®
        
    Returns:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    evaluator = OneIntoTwoEvaluator()
    
    # æå–äº¤æ˜“æ•°æ®
    trades = backtest_results.get('trades', [])
    
    if not trades:
        return {
            'precision_at_10': 0,
            'hit_at_10': 0,
            'board_strength': 0,
            'avg_fill_ratio': 0
        }
    
    # æŒ‰æ—¥æœŸåˆ†ç»„
    trades_df = pd.DataFrame(trades)
    trades_by_date = trades_df.groupby(trades_df['timestamp'].dt.date)
    
    metrics_list = []
    for date, day_trades in trades_by_date:
        # è®¡ç®—å½“æ—¥æŒ‡æ ‡
        hit_count = len(day_trades[day_trades['pnl'] > 0])
        total_count = len(day_trades)
        
        if total_count > 0:
            precision = hit_count / total_count
            metrics_list.append(precision)
    
    # æ±‡æ€»æŒ‡æ ‡
    avg_precision = np.mean(metrics_list) if metrics_list else 0
    
    return {
        'precision_at_10': avg_precision,
        'hit_at_10': avg_precision * 0.8,  # ç®€åŒ–ä¼°ç®—
        'board_strength': avg_precision * 0.5 + 0.3,  # ç®€åŒ–ä¼°ç®—
        'avg_fill_ratio': backtest_results.get('avg_fill_ratio', 0.5)
    }


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = OneIntoTwoEvaluator()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    dates = pd.date_range('2025-01-01', '2025-01-05', freq='B')
    
    for date in dates:
        # æ¨¡æ‹Ÿé¢„æµ‹
        predictions = pd.DataFrame({
            'symbol': [f'STOCK_{i:03d}' for i in range(10)],
            'prob': np.random.uniform(0.5, 0.9, 10),
            'rank': range(1, 11)
        })
        
        # æ¨¡æ‹Ÿå®é™…ç»“æœ
        actual = pd.DataFrame({
            'symbol': [f'STOCK_{i:03d}' for i in range(10)],
            'is_limit_up': np.random.choice([True, False], 10, p=[0.3, 0.7]),
            'touch_limit': np.random.choice([True, False], 10, p=[0.5, 0.5]),
            'return': np.random.normal(0.02, 0.05, 10),
            'board_count': np.random.choice([1, 2, 3], 10, p=[0.6, 0.3, 0.1]),
            'theme': np.random.choice(['AI', 'æ–°èƒ½æº', 'åŒ»è¯'], 10),
            'sector': np.random.choice(['ç§‘æŠ€', 'æ¶ˆè´¹', 'é‡‘è'], 10),
            'queue_position': np.random.uniform(0, 1, 10),
            'fill_ratio': np.random.uniform(0, 1, 10)
        })
        
        # è¯„ä¼°
        metrics = evaluator.evaluate_predictions(predictions, actual, date.strftime('%Y-%m-%d'))
        print(f"\nğŸ“… {date.strftime('%Y-%m-%d')} è¯„ä¼°ç»“æœ:")
        print(f"  P@N: {metrics.precision_at_n:.2%}")
        print(f"  Hit@N: {metrics.hit_at_n:.2%}")
        print(f"  æ¿å¼ºåº¦: {metrics.board_strength:.3f}")
        print(f"  å¹³å‡æ”¶ç›Š: {metrics.avg_next_day_return:.2%}")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + evaluator.generate_report())
    
    print("\nâœ… è¯„ä¼°å®Œæˆï¼")