"""
Walk-ForwardéªŒè¯æ¡†æ¶

æ ¹æ® docs/IMPROVEMENT_ROADMAP.md é˜¶æ®µä¸€ä»»åŠ¡ 1.3
ç›®æ ‡ï¼šå®ç°ä¸¥æ ¼çš„æ ·æœ¬å¤–æµ‹è¯•ï¼Œé¿å…è¿‡æ‹Ÿåˆ

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ»šåŠ¨æ—¶é—´çª—å£å›æµ‹
2. ä¸¥æ ¼çš„æ—¶é—´åºåˆ—åˆ‡åˆ†
3. å¤šæŒ‡æ ‡æ€§èƒ½è¯„ä¼°
4. ç¨³å®šæ€§åˆ†æï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€æœ€å°å€¼ï¼‰
5. å›æµ‹ç»“æœå¯è§†åŒ–

ä½œè€…ï¼šQilin Quant Team
åˆ›å»ºï¼š2025-10-30
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Callable
from datetime import datetime, timedelta
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class WalkForwardValidator:
    """Walk-ForwardéªŒè¯å™¨"""
    
    def __init__(self, 
                 train_months: int = 12,
                 predict_months: int = 1,
                 step_months: int = 1):
        """
        åˆå§‹åŒ–Walk-ForwardéªŒè¯å™¨
        
        Args:
            train_months: è®­ç»ƒçª—å£é•¿åº¦ï¼ˆæœˆï¼‰
            predict_months: é¢„æµ‹çª—å£é•¿åº¦ï¼ˆæœˆï¼‰
            step_months: æ»šåŠ¨æ­¥é•¿ï¼ˆæœˆï¼‰
        """
        self.train_months = train_months
        self.predict_months = predict_months
        self.step_months = step_months
        
        # è¯„ä¼°æŒ‡æ ‡å†å²
        self.metrics_history = []
        
        print(f"ğŸ”„ Walk-ForwardéªŒè¯å™¨åˆå§‹åŒ–")
        print(f"  è®­ç»ƒçª—å£: {train_months}ä¸ªæœˆ")
        print(f"  é¢„æµ‹çª—å£: {predict_months}ä¸ªæœˆ")
        print(f"  æ»šåŠ¨æ­¥é•¿: {step_months}ä¸ªæœˆ")
    
    def generate_time_windows(self, 
                             start_date: str, 
                             end_date: str) -> List[Dict]:
        """
        ç”Ÿæˆæ—¶é—´çª—å£
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        
        Returns:
            List[Dict]: æ—¶é—´çª—å£åˆ—è¡¨ï¼Œæ¯ä¸ªçª—å£åŒ…å«train_start, train_end, test_start, test_end
        """
        print(f"\nç”Ÿæˆæ—¶é—´çª—å£: {start_date} -> {end_date}")
        
        start = pd.to_datetime(start_date)
        end = pd.to_datetime(end_date)
        
        windows = []
        current_start = start
        
        while True:
            # è®­ç»ƒé›†æ—¶é—´èŒƒå›´
            train_start = current_start
            train_end = train_start + pd.DateOffset(months=self.train_months)
            
            # æµ‹è¯•é›†æ—¶é—´èŒƒå›´
            test_start = train_end
            test_end = test_start + pd.DateOffset(months=self.predict_months)
            
            # å¦‚æœæµ‹è¯•é›†ç»“æŸæ—¶é—´è¶…è¿‡æ€»ç»“æŸæ—¶é—´ï¼Œåœæ­¢
            if test_end > end:
                break
            
            window = {
                'train_start': train_start.strftime('%Y-%m-%d'),
                'train_end': train_end.strftime('%Y-%m-%d'),
                'test_start': test_start.strftime('%Y-%m-%d'),
                'test_end': test_end.strftime('%Y-%m-%d'),
                'window_id': len(windows) + 1
            }
            
            windows.append(window)
            
            # å‘å‰æ»šåŠ¨
            current_start = current_start + pd.DateOffset(months=self.step_months)
        
        print(f"âœ… ç”Ÿæˆ {len(windows)} ä¸ªæ—¶é—´çª—å£")
        
        return windows
    
    def validate(self, 
                model_class,
                X: pd.DataFrame,
                y: pd.Series,
                time_col: str = 'date',
                model_params: Dict = None,
                top_k: int = 20) -> pd.DataFrame:
        """
        æ‰§è¡ŒWalk-ForwardéªŒè¯
        
        Args:
            model_class: æ¨¡å‹ç±»ï¼ˆéœ€å®ç°fitå’Œpredictæ–¹æ³•ï¼‰
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
            time_col: æ—¶é—´åˆ—å
            model_params: æ¨¡å‹å‚æ•°
            top_k: Top Kå‡†ç¡®ç‡çš„Kå€¼
        
        Returns:
            pd.DataFrame: æ¯ä¸ªçª—å£çš„æ€§èƒ½æŒ‡æ ‡
        """
        print(f"\nå¼€å§‹Walk-ForwardéªŒè¯...")
        
        if model_params is None:
            model_params = {}
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
        if time_col in X.columns:
            X = X.sort_values(time_col)
            y = y.loc[X.index]
        
        # ç”Ÿæˆæ—¶é—´çª—å£
        start_date = X[time_col].min()
        end_date = X[time_col].max()
        windows = self.generate_time_windows(start_date, end_date)
        
        results = []
        
        for window in windows:
            print(f"\nçª—å£ {window['window_id']}: "
                  f"è®­ç»ƒ {window['train_start']} ~ {window['train_end']}, "
                  f"æµ‹è¯• {window['test_start']} ~ {window['test_end']}")
            
            try:
                # åˆ‡åˆ†æ•°æ®
                train_mask = (X[time_col] >= window['train_start']) & (X[time_col] < window['train_end'])
                test_mask = (X[time_col] >= window['test_start']) & (X[time_col] < window['test_end'])
                
                X_train = X[train_mask].drop(columns=[time_col] if time_col in X.columns else [])
                y_train = y[train_mask]
                
                X_test = X[test_mask].drop(columns=[time_col] if time_col in X.columns else [])
                y_test = y[test_mask]
                
                if len(X_train) == 0 or len(X_test) == 0:
                    print(f"  âš ï¸ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ­¤çª—å£")
                    continue
                
                print(f"  è®­ç»ƒæ ·æœ¬: {len(X_train)}, æµ‹è¯•æ ·æœ¬: {len(X_test)}")
                
                # è®­ç»ƒæ¨¡å‹
                model = model_class(**model_params)
                model.fit(X_train, y_train)
                
                # é¢„æµ‹
                if hasattr(model, 'predict_proba'):
                    y_pred_proba = model.predict_proba(X_test)
                    if y_pred_proba.ndim > 1 and y_pred_proba.shape[1] > 1:
                        y_pred_proba = y_pred_proba[:, 1]
                else:
                    y_pred_proba = model.predict(X_test)
                
                y_pred = (y_pred_proba > 0.5).astype(int)
                
                # è®¡ç®—æŒ‡æ ‡
                metrics = self._calculate_metrics(
                    y_test, y_pred, y_pred_proba, top_k
                )
                
                # è®°å½•çª—å£ä¿¡æ¯
                metrics.update(window)
                results.append(metrics)
                
                print(f"  AUC: {metrics['auc']:.4f}, "
                      f"P@{top_k}: {metrics[f'precision_at_{top_k}']:.4f}, "
                      f"Hit@{top_k}: {metrics[f'hit_at_{top_k}']:.4f}")
                
            except Exception as e:
                print(f"  âŒ çª—å£ {window['window_id']} éªŒè¯å¤±è´¥: {e}")
                continue
        
        df_results = pd.DataFrame(results)
        self.metrics_history = results
        
        print(f"\nâœ… Walk-ForwardéªŒè¯å®Œæˆï¼Œå…± {len(results)} ä¸ªçª—å£")
        
        return df_results
    
    def calculate_stability_metrics(self, df_results: pd.DataFrame) -> Dict:
        """
        è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        
        Args:
            df_results: éªŒè¯ç»“æœDataFrame
        
        Returns:
            Dict: ç¨³å®šæ€§ç»Ÿè®¡
        """
        print("\nè®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡...")
        
        metrics_cols = [col for col in df_results.columns 
                       if col not in ['train_start', 'train_end', 'test_start', 'test_end', 'window_id']]
        
        stability = {}
        
        for metric in metrics_cols:
            values = df_results[metric].dropna()
            
            if len(values) == 0:
                continue
            
            stability[f'{metric}_mean'] = float(values.mean())
            stability[f'{metric}_std'] = float(values.std())
            stability[f'{metric}_min'] = float(values.min())
            stability[f'{metric}_max'] = float(values.max())
            stability[f'{metric}_median'] = float(values.median())
            
            # è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆCVï¼‰
            if values.mean() != 0:
                stability[f'{metric}_cv'] = float(values.std() / abs(values.mean()))
        
        return stability
    
    def plot_metrics_over_time(self, 
                               df_results: pd.DataFrame,
                               save_path: str = None):
        """
        ç»˜åˆ¶æŒ‡æ ‡æ—¶é—´åºåˆ—å›¾
        
        Args:
            df_results: éªŒè¯ç»“æœDataFrame
            save_path: ä¿å­˜è·¯å¾„
        """
        print("\nç»˜åˆ¶æŒ‡æ ‡æ—¶é—´åºåˆ—å›¾...")
        
        key_metrics = ['auc', 'precision', 'recall', 'f1', 'precision_at_20', 'hit_at_20']
        available_metrics = [m for m in key_metrics if m in df_results.columns]
        
        if not available_metrics:
            print("âš ï¸ æ— å¯ç”¨æŒ‡æ ‡")
            return
        
        n_metrics = len(available_metrics)
        fig, axes = plt.subplots(n_metrics, 1, figsize=(14, 4 * n_metrics))
        
        if n_metrics == 1:
            axes = [axes]
        
        # ä½¿ç”¨test_startä½œä¸ºxè½´
        x_dates = pd.to_datetime(df_results['test_start'])
        
        for idx, metric in enumerate(available_metrics):
            ax = axes[idx]
            
            values = df_results[metric].values
            
            # ç»˜åˆ¶æŠ˜çº¿å›¾
            ax.plot(x_dates, values, marker='o', linewidth=2, markersize=6, label=metric)
            
            # æ·»åŠ å‡å€¼çº¿
            mean_val = values.mean()
            ax.axhline(y=mean_val, color='red', linestyle='--', 
                      alpha=0.7, label=f'å‡å€¼: {mean_val:.4f}')
            
            # æ·»åŠ æ ‡å‡†å·®åŒºé—´
            std_val = values.std()
            ax.fill_between(x_dates, mean_val - std_val, mean_val + std_val,
                           alpha=0.2, color='gray', label=f'Â±1 std')
            
            ax.set_title(f'{metric.upper()} - æ—¶é—´åºåˆ—', fontsize=12, fontweight='bold')
            ax.set_xlabel('æµ‹è¯•æœŸå¼€å§‹æ—¥æœŸ', fontsize=10)
            ax.set_ylabel(metric.upper(), fontsize=10)
            ax.legend(loc='best', fontsize=9)
            ax.grid(True, alpha=0.3)
            
            # æ—‹è½¬xè½´æ ‡ç­¾
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"  å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def generate_report(self, 
                       df_results: pd.DataFrame,
                       stability_metrics: Dict,
                       output_path: str = None) -> str:
        """
        ç”ŸæˆéªŒè¯æŠ¥å‘Š
        
        Args:
            df_results: éªŒè¯ç»“æœDataFrame
            stability_metrics: ç¨³å®šæ€§æŒ‡æ ‡
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            str: æŠ¥å‘Šå†…å®¹
        """
        print("\nç”ŸæˆWalk-ForwardéªŒè¯æŠ¥å‘Š...")
        
        report_lines = []
        report_lines.append("# Walk-ForwardéªŒè¯æŠ¥å‘Š\n\n")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report_lines.append(f"**éªŒè¯çª—å£æ•°**: {len(df_results)}\n")
        report_lines.append(f"**è®­ç»ƒçª—å£**: {self.train_months}ä¸ªæœˆ\n")
        report_lines.append(f"**é¢„æµ‹çª—å£**: {self.predict_months}ä¸ªæœˆ\n")
        report_lines.append(f"**æ»šåŠ¨æ­¥é•¿**: {self.step_months}ä¸ªæœˆ\n\n")
        
        # æ•´ä½“æ€§èƒ½æ¦‚è§ˆ
        report_lines.append("## ğŸ“Š æ•´ä½“æ€§èƒ½æ¦‚è§ˆ\n\n")
        
        key_metrics = ['auc', 'precision', 'recall', 'f1', 'precision_at_20', 'hit_at_20']
        
        report_lines.append("| æŒ‡æ ‡ | å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | å˜å¼‚ç³»æ•° |\n")
        report_lines.append("|------|------|--------|--------|--------|----------|\n")
        
        for metric in key_metrics:
            if f'{metric}_mean' in stability_metrics:
                mean_val = stability_metrics[f'{metric}_mean']
                std_val = stability_metrics[f'{metric}_std']
                min_val = stability_metrics[f'{metric}_min']
                max_val = stability_metrics[f'{metric}_max']
                cv_val = stability_metrics.get(f'{metric}_cv', 0)
                
                report_lines.append(
                    f"| {metric.upper()} "
                    f"| {mean_val:.4f} "
                    f"| {std_val:.4f} "
                    f"| {min_val:.4f} "
                    f"| {max_val:.4f} "
                    f"| {cv_val:.4f} |\n"
                )
        
        report_lines.append("\n")
        
        # ç¨³å®šæ€§è¯„ä¼°
        report_lines.append("## ğŸ¯ ç¨³å®šæ€§è¯„ä¼°\n\n")
        
        auc_cv = stability_metrics.get('auc_cv', 0)
        
        if auc_cv < 0.05:
            stability_level = "ä¼˜ç§€ï¼ˆCV < 0.05ï¼‰"
            emoji = "ğŸŒŸ"
        elif auc_cv < 0.10:
            stability_level = "è‰¯å¥½ï¼ˆCV < 0.10ï¼‰"
            emoji = "âœ…"
        elif auc_cv < 0.15:
            stability_level = "ä¸€èˆ¬ï¼ˆCV < 0.15ï¼‰"
            emoji = "âš ï¸"
        else:
            stability_level = "è¾ƒå·®ï¼ˆCV â‰¥ 0.15ï¼‰"
            emoji = "âŒ"
        
        report_lines.append(f"{emoji} **ç¨³å®šæ€§ç­‰çº§**: {stability_level}\n\n")
        report_lines.append(f"- AUCå˜å¼‚ç³»æ•°: {auc_cv:.4f}\n")
        report_lines.append(f"- AUCæ ‡å‡†å·®: {stability_metrics.get('auc_std', 0):.4f}\n\n")
        
        # æœ€ä½³/æœ€å·®çª—å£
        report_lines.append("## ğŸ† æœ€ä½³çª—å£ vs âš ï¸ æœ€å·®çª—å£\n\n")
        
        if 'auc' in df_results.columns:
            best_idx = df_results['auc'].idxmax()
            worst_idx = df_results['auc'].idxmin()
            
            best_window = df_results.loc[best_idx]
            worst_window = df_results.loc[worst_idx]
            
            report_lines.append("### ğŸ† æœ€ä½³çª—å£\n\n")
            report_lines.append(f"- **æµ‹è¯•æœŸ**: {best_window['test_start']} ~ {best_window['test_end']}\n")
            report_lines.append(f"- **AUC**: {best_window['auc']:.4f}\n")
            report_lines.append(f"- **Precision**: {best_window.get('precision', 0):.4f}\n")
            report_lines.append(f"- **Recall**: {best_window.get('recall', 0):.4f}\n\n")
            
            report_lines.append("### âš ï¸ æœ€å·®çª—å£\n\n")
            report_lines.append(f"- **æµ‹è¯•æœŸ**: {worst_window['test_start']} ~ {worst_window['test_end']}\n")
            report_lines.append(f"- **AUC**: {worst_window['auc']:.4f}\n")
            report_lines.append(f"- **Precision**: {worst_window.get('precision', 0):.4f}\n")
            report_lines.append(f"- **Recall**: {worst_window.get('recall', 0):.4f}\n\n")
        
        # è¯¦ç»†ç»“æœè¡¨
        report_lines.append("## ğŸ“‹ è¯¦ç»†ç»“æœè¡¨\n\n")
        report_lines.append("| çª—å£ID | æµ‹è¯•æœŸ | AUC | Precision | Recall | F1 | P@20 | Hit@20 |\n")
        report_lines.append("|--------|--------|-----|-----------|--------|----|----- |--------|\n")
        
        for _, row in df_results.iterrows():
            test_period = f"{row['test_start'][:7]} ~ {row['test_end'][:7]}"
            report_lines.append(
                f"| {row['window_id']} "
                f"| {test_period} "
                f"| {row.get('auc', 0):.4f} "
                f"| {row.get('precision', 0):.4f} "
                f"| {row.get('recall', 0):.4f} "
                f"| {row.get('f1', 0):.4f} "
                f"| {row.get('precision_at_20', 0):.4f} "
                f"| {row.get('hit_at_20', 0):.4f} |\n"
            )
        
        report_content = "".join(report_lines)
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")
        
        return report_content
    
    # ==================== å†…éƒ¨æ–¹æ³• ====================
    
    def _calculate_metrics(self, 
                          y_true: np.ndarray, 
                          y_pred: np.ndarray, 
                          y_pred_proba: np.ndarray,
                          top_k: int = 20) -> Dict:
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        metrics = {}
        
        # åŸºç¡€æŒ‡æ ‡
        try:
            metrics['auc'] = roc_auc_score(y_true, y_pred_proba)
        except:
            metrics['auc'] = 0.5
        
        metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)
        metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)
        metrics['f1'] = f1_score(y_true, y_pred, zero_division=0)
        
        # Top KæŒ‡æ ‡
        if len(y_pred_proba) >= top_k:
            # é€‰æ‹©é¢„æµ‹æ¦‚ç‡æœ€é«˜çš„Top K
            top_k_idx = np.argsort(y_pred_proba)[-top_k:]
            
            # Precision@K
            precision_at_k = y_true[top_k_idx].sum() / top_k
            metrics[f'precision_at_{top_k}'] = precision_at_k
            
            # Hit@K (è‡³å°‘å‘½ä¸­ä¸€ä¸ªæ­£æ ·æœ¬)
            hit_at_k = 1.0 if y_true[top_k_idx].sum() > 0 else 0.0
            metrics[f'hit_at_{top_k}'] = hit_at_k
        else:
            metrics[f'precision_at_{top_k}'] = 0
            metrics[f'hit_at_{top_k}'] = 0
        
        return metrics


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.datasets import make_classification
    
    # åˆå§‹åŒ–éªŒè¯å™¨
    validator = WalkForwardValidator(
        train_months=12,
        predict_months=1,
        step_months=1
    )
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("\nç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    n_samples = 10000
    n_features = 50
    
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=20,
        n_redundant=10,
        random_state=42
    )
    
    # æ·»åŠ æ—¶é—´åˆ—
    start_date = pd.to_datetime('2020-01-01')
    dates = pd.date_range(start_date, periods=n_samples, freq='D')
    
    X_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])
    X_df['date'] = dates
    y_series = pd.Series(y)
    
    # æ‰§è¡ŒéªŒè¯
    df_results = validator.validate(
        model_class=RandomForestClassifier,
        X=X_df,
        y=y_series,
        time_col='date',
        model_params={'n_estimators': 100, 'max_depth': 10, 'random_state': 42}
    )
    
    # è®¡ç®—ç¨³å®šæ€§
    stability_metrics = validator.calculate_stability_metrics(df_results)
    
    print("\n" + "="*70)
    print("ğŸ“Š ç¨³å®šæ€§æŒ‡æ ‡")
    print("="*70)
    for k, v in stability_metrics.items():
        if 'mean' in k or 'std' in k or 'cv' in k:
            print(f"{k}: {v:.4f}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report_path = project_root / 'reports' / 'walk_forward_report.md'
    report_path.parent.mkdir(parents=True, exist_ok=True)
    validator.generate_report(df_results, stability_metrics, str(report_path))
    
    # ç»˜åˆ¶å›¾è¡¨
    plot_path = project_root / 'reports' / 'walk_forward_metrics.png'
    validator.plot_metrics_over_time(df_results, str(plot_path))
    
    print("\nâœ… Walk-ForwardéªŒè¯æ¼”ç¤ºå®Œæˆï¼")


if __name__ == '__main__':
    main()
