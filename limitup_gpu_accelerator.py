"""
æ¶¨åœæ¿é¢„æµ‹ç³»ç»Ÿ - GPUåŠ é€Ÿè®­ç»ƒæ¨¡å—
ä½¿ç”¨ç±»RAPIDSé£æ ¼APIï¼Œè‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§ï¼ŒCPU/GPUæ— ç¼åˆ‡æ¢
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import json
from datetime import datetime
import time

# å°è¯•å¯¼å…¥GPUåŠ é€Ÿåº“
import logging
logger = logging.getLogger(__name__)
try:
    import cudf
    import cuml
    from cuml.ensemble import RandomForestClassifier as cuRF
    GPU_AVAILABLE = True
    logger.info("âœ… GPUåŠ é€Ÿåº“å·²åŠ è½½ (cuDF + cuML)")
except ImportError:
    GPU_AVAILABLE = False
    logger.warning("âš ï¸ GPUåº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")

# CPUåå¤‡åº“
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb


class GPUAcceleratedPreprocessor:
    """GPUåŠ é€Ÿæ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self, use_gpu: bool = True):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        """
        self.use_gpu = use_gpu and GPU_AVAILABLE
        self.device = 'GPU' if self.use_gpu else 'CPU'
        
        logger.info(f"æ•°æ®å¤„ç†è®¾å¤‡: {self.device}")
    
    def to_device(self, df: pd.DataFrame):
        """å°†DataFrameè½¬æ¢åˆ°ç›®æ ‡è®¾å¤‡"""
        if self.use_gpu:
            return cudf.from_pandas(df)
        return df
    
    def to_cpu(self, df):
        """å°†æ•°æ®è½¬å›CPU"""
        if self.use_gpu and isinstance(df, cudf.DataFrame):
            return df.to_pandas()
        return df
    
    def compute_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—é«˜çº§ç‰¹å¾ï¼ˆGPUåŠ é€Ÿï¼‰
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            ç‰¹å¾æ•°æ®
        """
        logger.info(f"å¼€å§‹ç‰¹å¾è®¡ç®— (è®¾å¤‡: {self.device})...")
        start_time = time.time()
        
        # è½¬æ¢åˆ°ç›®æ ‡è®¾å¤‡
        gdf = self.to_device(df)
        
        # è®¡ç®—ç»Ÿè®¡ç‰¹å¾ï¼ˆå‘é‡åŒ–æ“ä½œï¼ŒGPUè‡ªåŠ¨åŠ é€Ÿï¼‰
        features = []
        
        # 1. ç§»åŠ¨å¹³å‡ç‰¹å¾
        for window in [5, 10, 20]:
            col_name = f'ma_{window}'
            if 'close' in gdf.columns:
                gdf[col_name] = gdf['close'].rolling(window=window).mean()
                features.append(col_name)
        
        # 2. æ³¢åŠ¨ç‡ç‰¹å¾
        for window in [5, 10, 20]:
            col_name = f'std_{window}'
            if 'close' in gdf.columns:
                gdf[col_name] = gdf['close'].rolling(window=window).std()
                features.append(col_name)
        
        # 3. åŠ¨é‡ç‰¹å¾
        for period in [1, 5, 10]:
            col_name = f'momentum_{period}'
            if 'close' in gdf.columns:
                gdf[col_name] = gdf['close'].pct_change(periods=period)
                features.append(col_name)
        
        # 4. æˆäº¤é‡ç‰¹å¾
        if 'volume' in gdf.columns:
            for window in [5, 10]:
                col_name = f'volume_ma_{window}'
                gdf[col_name] = gdf['volume'].rolling(window=window).mean()
                features.append(col_name)
        
        # è½¬å›CPU
        result = self.to_cpu(gdf)
        
        elapsed = time.time() - start_time
        logger.info(f"ç‰¹å¾è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
        logger.info(f"ç”Ÿæˆç‰¹å¾æ•°: {len(features)}")
        
        return result


class GPUAcceleratedModel:
    """GPUåŠ é€Ÿæ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model_type: str = 'xgboost',
        use_gpu: bool = True,
        **model_params
    ):
        """
        åˆå§‹åŒ–æ¨¡å‹
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('xgboost', 'lightgbm', 'random_forest')
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            **model_params: æ¨¡å‹å‚æ•°
        """
        self.model_type = model_type
        self.use_gpu = use_gpu and GPU_AVAILABLE
        self.device = 'GPU' if self.use_gpu else 'CPU'
        self.model_params = model_params
        
        self.model = None
        self.training_time = 0
        
        logger.info(f"æ¨¡å‹: {model_type}, è®¾å¤‡: {self.device}")
    
    def _create_model(self):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        
        if self.model_type == 'xgboost':
            params = {
                'tree_method': 'hist' if not self.use_gpu else 'gpu_hist',
                'device': 'cuda' if self.use_gpu else 'cpu',
                'random_state': 42,
                **self.model_params
            }
            return xgb.XGBClassifier(**params)
        
        elif self.model_type == 'lightgbm':
            params = {
                'device': 'gpu' if self.use_gpu else 'cpu',
                'gpu_platform_id': 0,
                'gpu_device_id': 0,
                'random_state': 42,
                **self.model_params
            }
            return lgb.LGBMClassifier(**params)
        
        elif self.model_type == 'random_forest':
            if self.use_gpu:
                # cuML RandomForest
                params = {
                    'n_estimators': self.model_params.get('n_estimators', 100),
                    'max_depth': self.model_params.get('max_depth', 10),
                    'random_state': 42
                }
                return cuRF(**params)
            else:
                # Sklearn RandomForest
                params = {
                    'n_estimators': self.model_params.get('n_estimators', 100),
                    'max_depth': self.model_params.get('max_depth', 10),
                    'random_state': 42,
                    'n_jobs': -1
                }
                return RandomForestClassifier(**params)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def train(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None,
        y_val: Optional[pd.Series] = None
    ):
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯æ ‡ç­¾
        """
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ (è®¾å¤‡: {self.device})...")
        print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape}")
        
        start_time = time.time()
        
        # åˆ›å»ºæ¨¡å‹
        self.model = self._create_model()
        
        # è®­ç»ƒ
        if X_val is not None and y_val is not None:
            if self.model_type in ['xgboost', 'lightgbm']:
                self.model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    verbose=False
                )
            else:
                self.model.fit(X_train, y_train)
        else:
            self.model.fit(X_train, y_train)
        
        self.training_time = time.time() - start_time
        
        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {self.training_time:.2f}ç§’")
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """é¢„æµ‹"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        predictions = self.model.predict(X)
        
        # cuMLè¿”å›cuDF Seriesï¼Œéœ€è¦è½¬æ¢
        if self.use_gpu and hasattr(predictions, 'to_numpy'):
            predictions = predictions.to_numpy()
        
        return predictions
    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """é¢„æµ‹æ¦‚ç‡"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        probas = self.model.predict_proba(X)
        
        # cuMLè¿”å›cuDF DataFrameï¼Œéœ€è¦è½¬æ¢
        if self.use_gpu and hasattr(probas, 'to_numpy'):
            probas = probas.to_numpy()
        
        return probas


class GPUAcceleratedPipeline:
    """GPUåŠ é€Ÿå®Œæ•´Pipeline"""
    
    def __init__(
        self,
        model_type: str = 'xgboost',
        use_gpu: bool = True,
        save_dir: str = './gpu_models'
    ):
        """
        åˆå§‹åŒ–Pipeline
        
        Args:
            model_type: æ¨¡å‹ç±»å‹
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        self.model_type = model_type
        self.use_gpu = use_gpu and GPU_AVAILABLE
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.preprocessor = GPUAcceleratedPreprocessor(use_gpu=use_gpu)
        self.model = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'preprocess_time': 0,
            'training_time': 0,
            'inference_time': 0,
            'speedup_ratio': 1.0
        }
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ GPUåŠ é€ŸPipelineåˆå§‹åŒ–")
        print(f"æ¨¡å‹: {model_type}")
        print(f"è®¾å¤‡: {'GPU' if self.use_gpu else 'CPU'}")
        print(f"{'='*60}\n")
    
    def fit(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None,
        y_val: Optional[pd.Series] = None,
        **model_params
    ):
        """è®­ç»ƒPipeline"""
        
        total_start = time.time()
        
        # 1. æ•°æ®é¢„å¤„ç†
        logger.info("æ•°æ®é¢„å¤„ç†...")
        preprocess_start = time.time()
        X_train_processed = self.preprocessor.compute_features(X_train)
        if X_val is not None:
            X_val_processed = self.preprocessor.compute_features(X_val)
        else:
            X_val_processed = None
        self.stats['preprocess_time'] = time.time() - preprocess_start
        
        # 2. æ¨¡å‹è®­ç»ƒ
        logger.info("æ¨¡å‹è®­ç»ƒ...")
        self.model = GPUAcceleratedModel(
            model_type=self.model_type,
            use_gpu=self.use_gpu,
            **model_params
        )
        
        self.model.train(
            X_train_processed,
            y_train,
            X_val_processed if X_val_processed is not None else None,
            y_val
        )
        self.stats['training_time'] = self.model.training_time
        
        # 3. æ€»ç»“
        total_time = time.time() - total_start
        logger.info("="*60)
        logger.info("Pipelineè®­ç»ƒå®Œæˆ!")
        logger.info("="*60)
        logger.info(f"é¢„å¤„ç†è€—æ—¶: {self.stats['preprocess_time']:.2f}ç§’")
        logger.info(f"è®­ç»ƒè€—æ—¶: {self.stats['training_time']:.2f}ç§’")
        logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info("="*60)
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """é¢„æµ‹"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        start_time = time.time()
        
        # é¢„å¤„ç†
        X_processed = self.preprocessor.compute_features(X)
        
        # é¢„æµ‹
        predictions = self.model.predict(X_processed)
        
        self.stats['inference_time'] = time.time() - start_time
        
        return predictions
    
    def benchmark(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        n_runs: int = 3
    ) -> Dict[str, float]:
        """
        æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆå¯¹æ¯”CPU vs GPUï¼‰
        
        Returns:
            æ€§èƒ½ç»Ÿè®¡å­—å…¸
        """
        logger.info("="*60)
        logger.info(f"æ€§èƒ½åŸºå‡†æµ‹è¯• (è¿è¡Œ{n_runs}æ¬¡)")
        logger.info("="*60)
        
        results = {'cpu': [], 'gpu': []}
        
        # CPUæµ‹è¯•
        if not self.use_gpu:
            print("âš ï¸ å½“å‰å·²åœ¨CPUæ¨¡å¼ï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")
            return {'cpu_time': 0, 'gpu_time': 0, 'speedup': 1.0}
        
        for device_type in ['cpu', 'gpu']:
            use_gpu = (device_type == 'gpu')
            
            logger.info("-"*40)
            logger.info(f"æµ‹è¯•è®¾å¤‡: {device_type.upper()}")
            logger.info("-"*40)
            
            for run in range(n_runs):
                logger.info(f"è¿è¡Œ {run+1}/{n_runs}...")
                
                # åˆ›å»ºPipeline
                pipeline = GPUAcceleratedPipeline(
                    model_type=self.model_type,
                    use_gpu=use_gpu,
                    save_dir=str(self.save_dir)
                )
                
                # è®­ç»ƒ
                start_time = time.time()
                pipeline.fit(X_train, y_train)
                elapsed = time.time() - start_time
                
                results[device_type].append(elapsed)
                logger.info(f"è€—æ—¶: {elapsed:.2f}ç§’")
        
        # è®¡ç®—ç»Ÿè®¡
        cpu_time = np.mean(results['cpu'])
        gpu_time = np.mean(results['gpu'])
        speedup = cpu_time / gpu_time if gpu_time > 0 else 1.0
        
        logger.info("="*60)
        logger.info("åŸºå‡†æµ‹è¯•ç»“æœæ±‡æ€»")
        logger.info("="*60)
        logger.info(f"CPUå¹³å‡è€—æ—¶: {cpu_time:.2f}ç§’")
        logger.info(f"GPUå¹³å‡è€—æ—¶: {gpu_time:.2f}ç§’")
        logger.info(f"åŠ é€Ÿæ¯”: {speedup:.2f}x")
        logger.info("="*60)
        
        self.stats['speedup_ratio'] = speedup
        
        return {
            'cpu_time': cpu_time,
            'gpu_time': gpu_time,
            'speedup': speedup
        }
    
    def save(self, filename: str):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        filepath = self.save_dir / filename
        
        # ä¿å­˜æ¨¡å‹ï¼ˆå…·ä½“å®ç°å–å†³äºæ¨¡å‹ç±»å‹ï¼‰
        if self.model_type in ['xgboost', 'lightgbm']:
            self.model.model.save_model(str(filepath))
        else:
            import joblib
            joblib.dump(self.model.model, filepath)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'model_type': self.model_type,
            'use_gpu': self.use_gpu,
            'stats': self.stats,
            'timestamp': datetime.now().isoformat()
        }
        
        metadata_file = filepath.with_suffix('.json')
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æ¨¡å‹å·²ä¿å­˜: {filepath}")


if __name__ == '__main__':
    from app.core.logging_setup import setup_logging
    setup_logging()
    logger.info("="*60)
    logger.info("æ¶¨åœæ¿é¢„æµ‹ç³»ç»Ÿ - GPUåŠ é€Ÿè®­ç»ƒæ¨¡å—")
    logger.info("="*60)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 5000
    n_features = 100
    
    X_train = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    X_train['close'] = np.random.randn(n_samples).cumsum()
    X_train['volume'] = np.random.randint(1000, 10000, n_samples)
    
    y_train = pd.Series(np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3]))
    
    logger.info(f"æ•°æ®é›†å¤§å°: {X_train.shape}")
    logger.info(f"æ¶¨åœæ¿æ ·æœ¬å æ¯”: {y_train.mean():.2%}")
    
    # æµ‹è¯•GPU Pipeline
    logger.info("="*60)
    logger.info("GPUåŠ é€ŸPipelineæµ‹è¯•")
    logger.info("="*60)
    
    pipeline = GPUAcceleratedPipeline(
        model_type='xgboost',
        use_gpu=True
    )
    
    pipeline.fit(
        X_train, y_train,
        n_estimators=100,
        max_depth=6
    )
    
    # é¢„æµ‹æµ‹è¯•
    X_test = X_train.head(100)
    predictions = pipeline.predict(X_test)
    logger.info(f"é¢„æµ‹ç»“æœç¤ºä¾‹: {predictions[:10]}")
    
    # å¦‚æœGPUå¯ç”¨ï¼Œè¿è¡ŒåŸºå‡†æµ‹è¯•
    if GPU_AVAILABLE:
        logger.info("="*60)
        logger.info("æ€§èƒ½åŸºå‡†æµ‹è¯•")
        logger.info("="*60)
        
        benchmark_results = pipeline.benchmark(
            X_train.head(1000),
            y_train.head(1000),
            n_runs=2
        )
    
    logger.info("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
