#!/usr/bin/env python
"""
ä¸€è¿›äºŒæ¶¨åœæ¿å› å­ç»„åˆä¼˜åŒ–å™¨
ç”¨äºå› å­æƒé‡ä¼˜åŒ–ã€ICè®¡ç®—ã€å› å­ç­›é€‰
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import logging
from pathlib import Path
import json

logger = logging.getLogger(__name__)


class FactorOptimizer:
    """
    å› å­ç»„åˆä¼˜åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    1. è®¡ç®—å› å­ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰
    2. å› å­æƒé‡ä¼˜åŒ–
    3. å› å­æ­£äº¤åŒ–å¤„ç†
    4. å› å­ç»„åˆè¯„åˆ†
    """
    
    def __init__(self, cache_dir: str = "./workspace/factor_optimizer_cache"):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¼˜åŒ–å†å²
        self.optimization_history: List[Dict] = []
        
        logger.info("âœ… å› å­ç»„åˆä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    def calculate_ic(
        self,
        factor_values: pd.Series,
        target_returns: pd.Series
    ) -> Dict[str, float]:
        """
        è®¡ç®—å› å­ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰
        
        Args:
            factor_values: å› å­å€¼åºåˆ—
            target_returns: ç›®æ ‡æ”¶ç›Šç‡åºåˆ—
            
        Returns:
            ICç»Ÿè®¡æŒ‡æ ‡
        """
        # åˆ é™¤ç¼ºå¤±å€¼
        valid_mask = factor_values.notna() & target_returns.notna()
        factor_clean = factor_values[valid_mask]
        returns_clean = target_returns[valid_mask]
        
        if len(factor_clean) < 10:
            logger.warning(f"æœ‰æ•ˆæ ·æœ¬è¿‡å°‘: {len(factor_clean)}")
            return {'ic': 0, 'rank_ic': 0, 'ir': 0}
        
        # è®¡ç®—Pearson IC
        ic = factor_clean.corr(returns_clean)
        
        # è®¡ç®—Spearman Rank IC
        rank_ic = factor_clean.rank().corr(returns_clean.rank())
        
        # è®¡ç®—ICçš„æ ‡å‡†å·®ï¼ˆç”¨äºIRï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç”¨æ—¶é—´åºåˆ—ICçš„æ ‡å‡†å·®
        ic_std = 0.05  # å‡è®¾å€¼
        
        # è®¡ç®—IR (Information Ratio)
        ir = ic / ic_std if ic_std > 0 else 0
        
        return {
            'ic': float(ic) if not np.isnan(ic) else 0,
            'rank_ic': float(rank_ic) if not np.isnan(rank_ic) else 0,
            'ir': float(ir) if not np.isnan(ir) else 0,
            'n_samples': len(factor_clean)
        }
    
    def optimize_factor_weights(
        self,
        factors: List[Dict[str, Any]],
        factor_matrix: pd.DataFrame,
        target_returns: pd.Series,
        method: str = 'ic_weighted'
    ) -> Dict[str, float]:
        """
        ä¼˜åŒ–å› å­æƒé‡
        
        Args:
            factors: å› å­åˆ—è¡¨
            factor_matrix: å› å­å€¼çŸ©é˜µ (æ ·æœ¬ x å› å­)
            target_returns: ç›®æ ‡æ”¶ç›Šç‡
            method: ä¼˜åŒ–æ–¹æ³• ['ic_weighted', 'equal', 'max_ic', 'ridge']
            
        Returns:
            å› å­æƒé‡å­—å…¸
        """
        logger.info(f"å¼€å§‹å› å­æƒé‡ä¼˜åŒ–ï¼Œæ–¹æ³•: {method}")
        
        weights = {}
        
        if method == 'equal':
            # ç­‰æƒé‡
            n_factors = len(factors)
            for factor in factors:
                weights[factor['name']] = 1.0 / n_factors
        
        elif method == 'ic_weighted':
            # ICåŠ æƒ
            ic_scores = {}
            total_ic = 0
            
            for factor in factors:
                factor_name = factor['name']
                if factor_name in factor_matrix.columns:
                    ic_result = self.calculate_ic(
                        factor_matrix[factor_name],
                        target_returns
                    )
                    ic_scores[factor_name] = abs(ic_result['ic'])
                    total_ic += abs(ic_result['ic'])
            
            # å½’ä¸€åŒ–
            if total_ic > 0:
                for factor_name, ic in ic_scores.items():
                    weights[factor_name] = ic / total_ic
            else:
                # é€€åŒ–åˆ°ç­‰æƒ
                for factor in factors:
                    weights[factor['name']] = 1.0 / len(factors)
        
        elif method == 'max_ic':
            # åªé€‰æ‹©ICæœ€é«˜çš„å› å­
            best_factor = None
            max_ic = -1
            
            for factor in factors:
                factor_name = factor['name']
                if factor_name in factor_matrix.columns:
                    ic_result = self.calculate_ic(
                        factor_matrix[factor_name],
                        target_returns
                    )
                    if abs(ic_result['ic']) > max_ic:
                        max_ic = abs(ic_result['ic'])
                        best_factor = factor_name
            
            if best_factor:
                weights = {best_factor: 1.0}
                for factor in factors:
                    if factor['name'] != best_factor:
                        weights[factor['name']] = 0.0
        
        elif method == 'ridge':
            # å²­å›å½’ä¼˜åŒ–ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            from sklearn.linear_model import Ridge
            
            X = factor_matrix.fillna(0)
            y = target_returns.fillna(0)
            
            model = Ridge(alpha=0.1)
            model.fit(X, y)
            
            # å½’ä¸€åŒ–ç³»æ•°ä¸ºæƒé‡
            coef_abs = np.abs(model.coef_)
            coef_sum = coef_abs.sum()
            
            if coef_sum > 0:
                for i, factor in enumerate(factors):
                    weights[factor['name']] = coef_abs[i] / coef_sum
            else:
                for factor in factors:
                    weights[factor['name']] = 1.0 / len(factors)
        
        logger.info(f"æƒé‡ä¼˜åŒ–å®Œæˆ: {weights}")
        return weights
    
    def select_best_factors(
        self,
        factors: List[Dict[str, Any]],
        factor_matrix: pd.DataFrame,
        target_returns: pd.Series,
        n_select: int = 10,
        min_ic: float = 0.05,
        max_corr: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        ç­›é€‰æœ€ä¼˜å› å­ç»„åˆ
        
        Args:
            factors: å› å­åˆ—è¡¨
            factor_matrix: å› å­å€¼çŸ©é˜µ
            target_returns: ç›®æ ‡æ”¶ç›Šç‡
            n_select: é€‰æ‹©å› å­æ•°é‡
            min_ic: æœ€å°ICé˜ˆå€¼
            max_corr: æœ€å¤§ç›¸å…³ç³»æ•°é˜ˆå€¼ï¼ˆç”¨äºå»ç›¸å…³ï¼‰
            
        Returns:
            ç­›é€‰åçš„å› å­åˆ—è¡¨
        """
        logger.info(f"å¼€å§‹å› å­ç­›é€‰ï¼Œç›®æ ‡é€‰æ‹© {n_select} ä¸ªå› å­")
        
        # 1. è®¡ç®—æ¯ä¸ªå› å­çš„IC
        factor_scores = []
        
        for factor in factors:
            factor_name = factor['name']
            if factor_name in factor_matrix.columns:
                ic_result = self.calculate_ic(
                    factor_matrix[factor_name],
                    target_returns
                )
                
                factor_scores.append({
                    'factor': factor,
                    'ic': abs(ic_result['ic']),
                    'rank_ic': abs(ic_result['rank_ic']),
                    'ir': ic_result['ir']
                })
        
        # 2. æŒ‰ICæ’åº
        factor_scores.sort(key=lambda x: x['ic'], reverse=True)
        
        # 3. å»æ‰ICè¿‡ä½çš„å› å­
        factor_scores = [f for f in factor_scores if f['ic'] >= min_ic]
        
        if not factor_scores:
            logger.warning("æ²¡æœ‰æ»¡è¶³ICé˜ˆå€¼çš„å› å­")
            return []
        
        # 4. é€æ­¥æ·»åŠ å› å­ï¼Œé¿å…é«˜ç›¸å…³
        selected_factors = []
        selected_names = []
        
        for score_info in factor_scores:
            if len(selected_factors) >= n_select:
                break
            
            factor_name = score_info['factor']['name']
            
            # æ£€æŸ¥ä¸å·²é€‰å› å­çš„ç›¸å…³æ€§
            if selected_names:
                correlations = []
                for selected_name in selected_names:
                    corr = factor_matrix[factor_name].corr(
                        factor_matrix[selected_name]
                    )
                    correlations.append(abs(corr))
                
                # å¦‚æœä¸ä»»ä½•å·²é€‰å› å­ç›¸å…³æ€§è¿‡é«˜ï¼Œè·³è¿‡
                if max(correlations) > max_corr:
                    logger.info(f"è·³è¿‡å› å­ {factor_name}ï¼Œç›¸å…³æ€§è¿‡é«˜: {max(correlations):.3f}")
                    continue
            
            # æ·»åŠ å› å­
            factor_info = score_info['factor'].copy()
            factor_info['actual_ic'] = score_info['ic']
            factor_info['actual_rank_ic'] = score_info['rank_ic']
            factor_info['ir'] = score_info['ir']
            
            selected_factors.append(factor_info)
            selected_names.append(factor_name)
            
            logger.info(f"é€‰æ‹©å› å­ {factor_name}, IC={score_info['ic']:.4f}")
        
        logger.info(f"æœ€ç»ˆé€‰æ‹© {len(selected_factors)} ä¸ªå› å­")
        return selected_factors
    
    def create_composite_score(
        self,
        factor_matrix: pd.DataFrame,
        weights: Dict[str, float],
        standardize: bool = True
    ) -> pd.Series:
        """
        åˆ›å»ºå› å­ç»„åˆè¯„åˆ†
        
        Args:
            factor_matrix: å› å­å€¼çŸ©é˜µ
            weights: å› å­æƒé‡
            standardize: æ˜¯å¦æ ‡å‡†åŒ–
            
        Returns:
            ç»¼åˆè¯„åˆ†åºåˆ—
        """
        scores = pd.Series(0.0, index=factor_matrix.index)
        
        for factor_name, weight in weights.items():
            if factor_name in factor_matrix.columns and weight > 0:
                factor_values = factor_matrix[factor_name]
                
                if standardize:
                    # æ ‡å‡†åŒ–åˆ° [0, 1]
                    factor_min = factor_values.min()
                    factor_max = factor_values.max()
                    if factor_max > factor_min:
                        factor_std = (factor_values - factor_min) / (factor_max - factor_min)
                    else:
                        factor_std = factor_values
                else:
                    factor_std = factor_values
                
                scores += weight * factor_std.fillna(0)
        
        return scores
    
    def backtest_factors(
        self,
        factors: List[Dict[str, Any]],
        factor_matrix: pd.DataFrame,
        target_returns: pd.Series,
        weights: Optional[Dict[str, float]] = None
    ) -> Dict[str, Any]:
        """
        å›æµ‹å› å­ç»„åˆ
        
        Args:
            factors: å› å­åˆ—è¡¨
            factor_matrix: å› å­å€¼çŸ©é˜µ
            target_returns: ç›®æ ‡æ”¶ç›Šç‡
            weights: å› å­æƒé‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å›æµ‹ç»“æœ
        """
        logger.info("å¼€å§‹å› å­å›æµ‹")
        
        # å¦‚æœæ²¡æœ‰æä¾›æƒé‡ï¼Œä½¿ç”¨ICåŠ æƒ
        if weights is None:
            weights = self.optimize_factor_weights(
                factors, factor_matrix, target_returns, method='ic_weighted'
            )
        
        # åˆ›å»ºç»¼åˆè¯„åˆ†
        composite_scores = self.create_composite_score(factor_matrix, weights)
        
        # æŒ‰è¯„åˆ†åˆ†ç»„ï¼ˆäº”åˆ†ä½ï¼‰
        composite_scores_clean = composite_scores.dropna()
        target_returns_clean = target_returns[composite_scores_clean.index]
        
        quintiles = pd.qcut(composite_scores_clean, 5, labels=False, duplicates='drop')
        
        # è®¡ç®—å„åˆ†ç»„æ”¶ç›Š
        group_returns = {}
        for q in range(5):
            mask = (quintiles == q)
            if mask.sum() > 0:
                group_returns[f'Q{q+1}'] = target_returns_clean[mask].mean()
        
        # å¤šç©ºæ”¶ç›Šï¼ˆæœ€é«˜åˆ†ç»„ - æœ€ä½åˆ†ç»„ï¼‰
        long_short_return = group_returns.get('Q5', 0) - group_returns.get('Q1', 0)
        
        # å•è°ƒæ€§æ£€éªŒ
        monotonicity = all(
            group_returns.get(f'Q{i}', 0) <= group_returns.get(f'Q{i+1}', 0)
            for i in range(1, 5)
        )
        
        results = {
            'group_returns': group_returns,
            'long_short_return': long_short_return,
            'monotonicity': monotonicity,
            'weights': weights,
            'n_samples': len(composite_scores_clean)
        }
        
        logger.info(f"å›æµ‹å®Œæˆï¼Œå¤šç©ºæ”¶ç›Š: {long_short_return:.4f}")
        return results
    
    def save_optimization_result(
        self,
        result: Dict[str, Any],
        filename: Optional[str] = None
    ) -> str:
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        if filename is None:
            filename = f"optimization_{datetime.now():%Y%m%d_%H%M%S}.json"
        
        filepath = self.cache_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜: {filepath}")
        return str(filepath)


# æ¼”ç¤ºä½¿ç”¨
async def demo():
    """æ¼”ç¤ºå› å­ä¼˜åŒ–"""
    print("=" * 70)
    print("å› å­ç»„åˆä¼˜åŒ–æ¼”ç¤º")
    print("=" * 70)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = FactorOptimizer()
    
    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 100
    
    # å‡è®¾æœ‰5ä¸ªå› å­
    factors = [
        {'name': 'å°æ¿å¼ºåº¦', 'expected_ic': 0.08},
        {'name': 'è¿æ¿é«˜åº¦', 'expected_ic': 0.12},
        {'name': 'é¢˜æå…±æŒ¯', 'expected_ic': 0.10},
        {'name': 'æ—©ç›˜æ¶¨åœ', 'expected_ic': 0.15},
        {'name': 'é‡èƒ½çˆ†å‘', 'expected_ic': 0.09}
    ]
    
    # ç”Ÿæˆå› å­å€¼çŸ©é˜µ
    factor_matrix = pd.DataFrame({
        'å°æ¿å¼ºåº¦': np.random.randn(n_samples),
        'è¿æ¿é«˜åº¦': np.random.randn(n_samples),
        'é¢˜æå…±æŒ¯': np.random.randn(n_samples),
        'æ—©ç›˜æ¶¨åœ': np.random.randn(n_samples),
        'é‡èƒ½çˆ†å‘': np.random.randn(n_samples)
    })
    
    # ç”Ÿæˆç›®æ ‡æ”¶ç›Šï¼ˆä¸å› å­æœ‰ç›¸å…³æ€§ï¼‰
    target_returns = (
        0.08 * factor_matrix['å°æ¿å¼ºåº¦'] +
        0.12 * factor_matrix['è¿æ¿é«˜åº¦'] +
        0.10 * factor_matrix['é¢˜æå…±æŒ¯'] +
        0.15 * factor_matrix['æ—©ç›˜æ¶¨åœ'] +
        0.09 * factor_matrix['é‡èƒ½çˆ†å‘'] +
        np.random.randn(n_samples) * 0.5
    )
    
    # 1. è®¡ç®—IC
    print("\nğŸ“Š æ­¥éª¤1: è®¡ç®—å„å› å­IC")
    for factor in factors:
        ic_result = optimizer.calculate_ic(
            factor_matrix[factor['name']],
            target_returns
        )
        print(f"  {factor['name']}: IC={ic_result['ic']:.4f}, Rank IC={ic_result['rank_ic']:.4f}")
    
    # 2. ä¼˜åŒ–æƒé‡
    print("\nâš–ï¸  æ­¥éª¤2: ä¼˜åŒ–å› å­æƒé‡")
    weights = optimizer.optimize_factor_weights(
        factors, factor_matrix, target_returns, method='ic_weighted'
    )
    for name, weight in weights.items():
        print(f"  {name}: {weight:.4f}")
    
    # 3. é€‰æ‹©æœ€ä¼˜å› å­
    print("\nğŸ” æ­¥éª¤3: ç­›é€‰æœ€ä¼˜å› å­")
    selected = optimizer.select_best_factors(
        factors, factor_matrix, target_returns,
        n_select=3, min_ic=0.05, max_corr=0.7
    )
    print(f"  é€‰æ‹©äº† {len(selected)} ä¸ªå› å­:")
    for factor in selected:
        print(f"    - {factor['name']}: IC={factor.get('actual_ic', 0):.4f}")
    
    # 4. å›æµ‹
    print("\nğŸ“ˆ æ­¥éª¤4: å›æµ‹å› å­ç»„åˆ")
    backtest_result = optimizer.backtest_factors(
        factors, factor_matrix, target_returns
    )
    print(f"  åˆ†ç»„æ”¶ç›Š: {backtest_result['group_returns']}")
    print(f"  å¤šç©ºæ”¶ç›Š: {backtest_result['long_short_return']:.4f}")
    print(f"  å•è°ƒæ€§: {backtest_result['monotonicity']}")


if __name__ == '__main__':
    import asyncio
    asyncio.run(demo())
