"""
Qlibå›æµ‹é›†æˆæ¨¡å—æµ‹è¯•
æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import sys
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "web"))


def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("=" * 60)
    print("æµ‹è¯•1: æ¨¡å—å¯¼å…¥")
    print("=" * 60)
    
    try:
        from tabs.qlib_backtest_tab import (
            render_qlib_backtest_tab,
            _ensure_qlib_initialized,
            _generate_sample_predictions,
            run_qlib_backtest
        )
        print("âœ… æ‰€æœ‰æ ¸å¿ƒå‡½æ•°å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_qlib_availability():
    """æµ‹è¯•Qlibå¯ç”¨æ€§"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: Qlibå¯ç”¨æ€§")
    print("=" * 60)
    
    try:
        import qlib
        from qlib.backtest import backtest
        from qlib.constant import REG_CN
        print("âœ… Qlibå·²å®‰è£…")
        
        # æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–
        from tabs.qlib_backtest_tab import _ensure_qlib_initialized
        if _ensure_qlib_initialized():
            print("âœ… Qlibå·²åˆå§‹åŒ–")
            return True
        else:
            print("âš ï¸ Qlibæœªåˆå§‹åŒ–ï¼ˆå¯èƒ½éœ€è¦é…ç½®æ•°æ®è·¯å¾„ï¼‰")
            return False
    except ImportError as e:
        print(f"âŒ Qlibæœªå®‰è£…: {e}")
        return False


def test_generate_sample_predictions():
    """æµ‹è¯•ç¤ºä¾‹é¢„æµ‹æ•°æ®ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: ç¤ºä¾‹é¢„æµ‹æ•°æ®ç”Ÿæˆ")
    print("=" * 60)
    
    try:
        from tabs.qlib_backtest_tab import _generate_sample_predictions
        
        pred_score = _generate_sample_predictions()
        
        print(f"âœ… ç”ŸæˆæˆåŠŸ")
        print(f"   - æ•°æ®ç±»å‹: {type(pred_score)}")
        print(f"   - æ•°æ®å½¢çŠ¶: {pred_score.shape}")
        print(f"   - ç´¢å¼•å±‚çº§: {pred_score.index.names}")
        print(f"   - æ•°å€¼èŒƒå›´: [{pred_score.min():.4f}, {pred_score.max():.4f}]")
        print(f"   - å‡å€¼: {pred_score.mean():.4f}")
        print(f"   - æ ‡å‡†å·®: {pred_score.std():.4f}")
        
        # éªŒè¯æ•°æ®æ ¼å¼
        assert isinstance(pred_score, pd.Series), "åº”è¯¥æ˜¯Seriesç±»å‹"
        assert pred_score.index.names == ['datetime', 'instrument'], "ç´¢å¼•åº”è¯¥æ˜¯datetimeå’Œinstrument"
        assert len(pred_score) > 0, "æ•°æ®ä¸åº”ä¸ºç©º"
        
        print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡")
        return pred_score
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_backtest_execution_mock():
    """æµ‹è¯•å›æµ‹æ‰§è¡Œï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: å›æµ‹æ‰§è¡Œï¼ˆæ¨¡æ‹Ÿï¼‰")
    print("=" * 60)
    
    try:
        from tabs.qlib_backtest_tab import _generate_sample_predictions
        
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        pred_score = _generate_sample_predictions()
        
        print("âœ… é¢„æµ‹æ•°æ®å‡†å¤‡å®Œæˆ")
        print(f"   - æ•°æ®é‡: {len(pred_score)}")
        
        # æ¨¡æ‹Ÿå›æµ‹å‚æ•°
        params = {
            'pred_score': pred_score,
            'start_time': '2020-01-01',
            'end_time': '2020-12-31',
            'benchmark': 'SH000300',
            'topk': 30,
            'n_drop': 5,
            'init_cash': 1000000,
            'open_cost': 0.0015,
            'close_cost': 0.0025,
            'min_cost': 5.0
        }
        
        print("âœ… å›æµ‹å‚æ•°é…ç½®å®Œæˆ")
        print(f"   - æ—¶é—´èŒƒå›´: {params['start_time']} ~ {params['end_time']}")
        print(f"   - æŒä»“æ•°é‡: {params['topk']}")
        print(f"   - åˆå§‹èµ„é‡‘: {params['init_cash']:,.0f}å…ƒ")
        
        # æ³¨æ„ï¼šå®é™…æ‰§è¡Œéœ€è¦Qlibå·²åˆå§‹åŒ–å’Œæ•°æ®å¯ç”¨
        # è¿™é‡Œä»…æµ‹è¯•å‚æ•°å‡†å¤‡
        print("â„¹ï¸ å®é™…å›æµ‹éœ€è¦Qlibå®Œå…¨åˆå§‹åŒ–ï¼ˆè·³è¿‡æ‰§è¡Œï¼‰")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_result_structure():
    """æµ‹è¯•ç»“æœæ•°æ®ç»“æ„"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5: ç»“æœæ•°æ®ç»“æ„éªŒè¯")
    print("=" * 60)
    
    try:
        # æ¨¡æ‹Ÿç»“æœæ•°æ®ç»“æ„
        dates = pd.date_range('2020-01-01', '2020-12-31', freq='D')
        
        # æ¨¡æ‹Ÿå‡€å€¼
        portfolio_value = pd.Series(
            np.cumprod(1 + np.random.randn(len(dates)) * 0.01),
            index=dates
        )
        
        # æ¨¡æ‹Ÿæ—¥æ”¶ç›Š
        daily_returns = pd.Series(
            np.random.randn(len(dates)) * 0.01,
            index=dates
        )
        
        # æ¨¡æ‹Ÿå›æ’¤
        running_max = portfolio_value.expanding().max()
        drawdown = (portfolio_value - running_max) / running_max
        
        # è®¡ç®—æŒ‡æ ‡
        annualized_return = (portfolio_value.iloc[-1] ** (365 / len(dates))) - 1
        sharpe = daily_returns.mean() / daily_returns.std() * np.sqrt(252)
        max_drawdown = drawdown.min()
        volatility = daily_returns.std() * np.sqrt(252)
        win_rate = (daily_returns > 0).sum() / len(daily_returns)
        
        metrics = {
            'annualized_return': annualized_return,
            'cumulative_return': portfolio_value.iloc[-1] - 1,
            'information_ratio': sharpe,
            'max_drawdown': max_drawdown,
            'volatility': volatility,
            'win_rate': win_rate,
        }
        
        print("âœ… ç»“æœæ•°æ®ç»“æ„åˆ›å»ºæˆåŠŸ")
        print("\nå…³é”®æŒ‡æ ‡ï¼š")
        print(f"   - å¹´åŒ–æ”¶ç›Šç‡: {metrics['annualized_return']:.2%}")
        print(f"   - å¤æ™®æ¯”ç‡: {metrics['information_ratio']:.3f}")
        print(f"   - æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}")
        print(f"   - æ³¢åŠ¨ç‡: {metrics['volatility']:.2%}")
        print(f"   - èƒœç‡: {metrics['win_rate']:.2%}")
        
        # éªŒè¯ç»“æ„
        assert 'annualized_return' in metrics
        assert 'information_ratio' in metrics
        assert 'max_drawdown' in metrics
        
        print("\nâœ… æ‰€æœ‰ç»“æ„éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸ§ª " * 20)
    print("Qlibå›æµ‹é›†æˆæ¨¡å—æµ‹è¯•å¥—ä»¶")
    print("ğŸ§ª " * 20 + "\n")
    
    results = {}
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    results['imports'] = test_imports()
    results['qlib_availability'] = test_qlib_availability()
    results['sample_predictions'] = test_generate_sample_predictions() is not None
    results['backtest_mock'] = test_backtest_execution_mock()
    results['result_structure'] = test_result_structure()
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    total = len(results)
    passed = sum(results.values())
    
    for test_name, passed_flag in results.items():
        status = "âœ… PASS" if passed_flag else "âŒ FAIL"
        print(f"{status} - {test_name}")
    
    print("\n" + "-" * 60)
    print(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)
