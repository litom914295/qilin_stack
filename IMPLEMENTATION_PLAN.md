# ğŸ“‹ Qilin Stack å®Œæ•´å®æ–½è®¡åˆ’

## æ€»ä½“ç›®æ ‡

å°†å½“å‰çš„**åŸå‹ç³»ç»Ÿ**å‡çº§ä¸º**ç”Ÿäº§å°±ç»ªç³»ç»Ÿ**ï¼Œå…·å¤‡å®Œæ•´çš„æµ‹è¯•ã€æ–‡æ¡£ã€ç›‘æ§ã€æ€§èƒ½ä¼˜åŒ–å’Œéƒ¨ç½²èƒ½åŠ›ã€‚

**æ€»å·¥æœŸ**: 25-35 ä¸ªå·¥ä½œæ—¥  
**å›¢é˜Ÿè§„æ¨¡**: 1-2 äºº  
**ä¼˜å…ˆçº§**: é«˜ â†’ ä½ï¼ˆé˜¶æ®µ1æœ€é«˜ï¼‰

---

## ğŸ“Š è¿›åº¦æ€»è§ˆ

| é˜¶æ®µ | ä»»åŠ¡æ•° | é¢„è®¡å¤©æ•° | çŠ¶æ€ | ä¼˜å…ˆçº§ |
|------|--------|----------|------|--------|
| é˜¶æ®µ1: æµ‹è¯•ä½“ç³» | 3 | 4-6å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸ”´ P0 |
| é˜¶æ®µ2: æ–‡æ¡£å®Œå–„ | 3 | 5å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸ”´ P0 |
| é˜¶æ®µ3: æ•°æ®æ¥å…¥ | 3 | 3-5å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸŸ  P1 |
| é˜¶æ®µ4: ç›‘æ§éƒ¨ç½² | 3 | 2å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸŸ  P1 |
| é˜¶æ®µ5: æ€§èƒ½ä¼˜åŒ– | 3 | 4-5å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸŸ¡ P2 |
| é˜¶æ®µ6: å›æµ‹ç³»ç»Ÿ | 2 | 5-7å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸŸ¡ P2 |
| é˜¶æ®µ7: ç”Ÿäº§éƒ¨ç½² | 1 | 2-3å¤© | ğŸ”„ å¾…å¼€å§‹ | ğŸŸ¢ P3 |

**å›¾ä¾‹**:
- ğŸ”´ P0 = å¿…é¡»å®Œæˆï¼Œç³»ç»ŸåŸºç¡€
- ğŸŸ  P1 = é‡è¦ï¼Œå½±å“å¯ç”¨æ€§
- ğŸŸ¡ P2 = æœ‰ä»·å€¼ï¼Œæå‡ä½“éªŒ
- ğŸŸ¢ P3 = å¯é€‰ï¼Œé•¿æœŸä¼˜åŒ–

---

## é˜¶æ®µ1: å®Œå–„æµ‹è¯•ä½“ç³» (4-6å¤©) ğŸ”´

### ç›®æ ‡
å»ºç«‹å®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•ä½“ç³»ï¼Œç¡®ä¿ä»£ç è´¨é‡å’Œç³»ç»Ÿç¨³å®šæ€§ã€‚

### ä»»åŠ¡æ¸…å•

#### 1.1 å•å…ƒæµ‹è¯• (2-3å¤©)
**æ–‡ä»¶ç»“æ„**:
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_decision_engine.py      # å†³ç­–å¼•æ“æµ‹è¯•
â”‚   â”œâ”€â”€ test_signal_generators.py    # ä¿¡å·ç”Ÿæˆå™¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_weight_optimizer.py     # æƒé‡ä¼˜åŒ–å™¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_market_state.py         # å¸‚åœºçŠ¶æ€æ£€æµ‹æµ‹è¯•
â”‚   â”œâ”€â”€ test_monitoring.py           # ç›‘æ§ç³»ç»Ÿæµ‹è¯•
â”‚   â”œâ”€â”€ test_data_pipeline.py        # æ•°æ®ç®¡é“æµ‹è¯•
â”‚   â””â”€â”€ test_system_bridge.py        # ç³»ç»Ÿæ¡¥æ¥æµ‹è¯•
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_end_to_end.py           # ç«¯åˆ°ç«¯æµ‹è¯•
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ sample_data.py               # æµ‹è¯•æ•°æ®
â”‚   â””â”€â”€ mock_responses.py            # Mockå“åº”
â”œâ”€â”€ conftest.py                      # pytesté…ç½®
â””â”€â”€ requirements-test.txt            # æµ‹è¯•ä¾èµ–
```

**æµ‹è¯•è¦†ç›–ç›®æ ‡**:
- æ ¸å¿ƒé€»è¾‘è¦†ç›–ç‡: **80%+**
- å…³é”®è·¯å¾„è¦†ç›–ç‡: **100%**
- è¾¹ç•Œæ¡ä»¶æµ‹è¯•: **å®Œæ•´**

**æŠ€æœ¯æ ˆ**:
- `pytest` - æµ‹è¯•æ¡†æ¶
- `pytest-asyncio` - å¼‚æ­¥æµ‹è¯•
- `pytest-cov` - è¦†ç›–ç‡æŠ¥å‘Š
- `pytest-mock` - Mockå·¥å…·
- `hypothesis` - å±æ€§æµ‹è¯•ï¼ˆå¯é€‰ï¼‰

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
```python
# tests/unit/test_decision_engine.py
import pytest
from decision_engine.core import DecisionEngine, SignalType

@pytest.mark.asyncio
async def test_decision_engine_basic():
    """æµ‹è¯•åŸºæœ¬å†³ç­–æµç¨‹"""
    engine = DecisionEngine()
    decisions = await engine.make_decisions(['000001.SZ'], '2024-06-30')
    assert len(decisions) == 1
    assert decisions[0].final_signal in SignalType
    assert 0 <= decisions[0].confidence <= 1

@pytest.mark.asyncio
async def test_decision_engine_empty_symbols():
    """æµ‹è¯•ç©ºè‚¡ç¥¨åˆ—è¡¨"""
    engine = DecisionEngine()
    decisions = await engine.make_decisions([], '2024-06-30')
    assert len(decisions) == 0

@pytest.mark.asyncio
async def test_signal_fusion_weighted():
    """æµ‹è¯•åŠ æƒä¿¡å·èåˆ"""
    from decision_engine.core import SignalFuser, Signal
    fuser = SignalFuser()
    signals = [
        Signal(SignalType.BUY, 0.8, 0.9, 'qlib'),
        Signal(SignalType.SELL, 0.6, 0.7, 'trading_agents'),
        Signal(SignalType.HOLD, 0.5, 0.6, 'rd_agent')
    ]
    result = fuser.fuse_signals(signals)
    assert result.type in SignalType
    assert 0 <= result.confidence <= 1
```

**æ‰§è¡Œæ–¹å¼**:
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# è¿è¡Œå¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=decision_engine --cov=adaptive_system --cov=monitoring --cov=data_pipeline --cov-report=html

# è¿è¡Œç‰¹å®šæ¨¡å—
pytest tests/unit/test_decision_engine.py -v
```

---

#### 1.2 é›†æˆæµ‹è¯• (1-2å¤©)
**ç›®æ ‡**: æµ‹è¯•å¤šæ¨¡å—ååŒå·¥ä½œ

**æµ‹è¯•åœºæ™¯**:
1. **å®Œæ•´å†³ç­–æµç¨‹**
   - æ•°æ®è·å– â†’ ä¿¡å·ç”Ÿæˆ â†’ ä¿¡å·èåˆ â†’ å†³ç­–è¾“å‡º â†’ ç›‘æ§è®°å½•
2. **å¸‚åœºçŠ¶æ€è‡ªé€‚åº”**
   - æ£€æµ‹ç‰›å¸‚ â†’ è°ƒæ•´å‚æ•° â†’ ç”Ÿæˆå†³ç­–
   - æ£€æµ‹ç†Šå¸‚ â†’ è°ƒæ•´å‚æ•° â†’ ç”Ÿæˆå†³ç­–
3. **æƒé‡åŠ¨æ€ä¼˜åŒ–**
   - æ€§èƒ½è¯„ä¼° â†’ æƒé‡æ›´æ–° â†’ æ–°å†³ç­–ç”Ÿæˆ
4. **é”™è¯¯å¤„ç†å’Œé™çº§**
   - æ•°æ®æºå¤±è´¥ â†’ è‡ªåŠ¨é™çº§ â†’ ç»§ç»­è¿è¡Œ
   - å•ä¸ªç³»ç»Ÿå¤±è´¥ â†’ å…¶ä»–ç³»ç»Ÿè¡¥å¿

**ç¤ºä¾‹æµ‹è¯•**:
```python
# tests/integration/test_end_to_end.py
import pytest
from decision_engine.core import get_decision_engine
from adaptive_system.market_state import AdaptiveStrategyAdjuster
from monitoring.metrics import get_monitor

@pytest.mark.asyncio
async def test_full_decision_pipeline():
    """æµ‹è¯•å®Œæ•´å†³ç­–æµç¨‹"""
    # 1. åˆå§‹åŒ–
    engine = get_decision_engine()
    adjuster = AdaptiveStrategyAdjuster()
    monitor = get_monitor()
    
    # 2. å¸‚åœºçŠ¶æ€æ£€æµ‹
    market_data = create_test_market_data()
    state = adjuster.detector.detect_state(market_data)
    assert state is not None
    
    # 3. ç”Ÿæˆå†³ç­–
    symbols = ['000001.SZ', '600000.SH']
    decisions = await engine.make_decisions(symbols, '2024-06-30')
    assert len(decisions) == 2
    
    # 4. éªŒè¯ç›‘æ§æŒ‡æ ‡
    metrics = monitor.export_metrics()
    assert 'decision_made_total' in metrics
    assert monitor.get_summary()['total_decisions'] == 2
```

---

#### 1.3 CIé…ç½® (1å¤©)
**ç›®æ ‡**: è‡ªåŠ¨åŒ–æµ‹è¯•å’Œä»£ç è´¨é‡æ£€æŸ¥

**GitHub Actions é…ç½®**:
```yaml
# .github/workflows/test.yml
name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Lint with flake8
      run: |
        pip install flake8
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --max-complexity=10 --max-line-length=120 --statistics
    
    - name: Type check with mypy
      run: |
        pip install mypy
        mypy decision_engine adaptive_system monitoring data_pipeline
    
    - name: Run tests with coverage
      run: |
        pytest tests/ --cov=. --cov-report=xml --cov-report=html
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: true

  quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install pylint black isort
    
    - name: Check code formatting
      run: |
        black --check .
        isort --check-only .
    
    - name: Lint with pylint
      run: |
        pylint decision_engine adaptive_system monitoring data_pipeline --fail-under=8.0
```

**ä»£ç è´¨é‡é…ç½®æ–‡ä»¶**:

```ini
# .flake8
[flake8]
max-line-length = 120
exclude = .git,__pycache__,build,dist,venv
ignore = E203,W503

# pyproject.toml (black + isort)
[tool.black]
line-length = 120
target-version = ['py39', 'py310', 'py311']

[tool.isort]
profile = "black"
line_length = 120

# .pylintrc
[MASTER]
max-line-length=120
disable=missing-docstring,too-few-public-methods
```

**é¢„æœŸæˆæœ**:
- âœ… æ¯æ¬¡æäº¤è‡ªåŠ¨è¿è¡Œæµ‹è¯•
- âœ… Pull Requestæ£€æŸ¥é—¨ç¦
- âœ… è¦†ç›–ç‡æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ
- âœ… ä»£ç è´¨é‡è¯„åˆ†â‰¥8.0

---

## é˜¶æ®µ2: æ–‡æ¡£å®Œå–„ (5å¤©) ğŸ”´

### ç›®æ ‡
æä¾›å®Œæ•´çš„å¼€å‘è€…æ–‡æ¡£å’Œç”¨æˆ·æ–‡æ¡£ï¼Œé™ä½ä½¿ç”¨é—¨æ§›ã€‚

### ä»»åŠ¡æ¸…å•

#### 2.1 APIæ–‡æ¡£ (2å¤©)
**ç›®æ ‡**: è‡ªåŠ¨ç”Ÿæˆä¸“ä¸šçš„APIæ–‡æ¡£

**å·¥å…·**: Sphinx + autodoc + napoleon

**æ–‡æ¡£ç»“æ„**:
```
docs/
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ conf.py                 # Sphinxé…ç½®
â”‚   â”œâ”€â”€ index.rst               # é¦–é¡µ
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ decision_engine.rst # å†³ç­–å¼•æ“API
â”‚   â”‚   â”œâ”€â”€ adaptive_system.rst # è‡ªé€‚åº”ç³»ç»ŸAPI
â”‚   â”‚   â”œâ”€â”€ monitoring.rst      # ç›‘æ§ç³»ç»ŸAPI
â”‚   â”‚   â””â”€â”€ data_pipeline.rst   # æ•°æ®ç®¡é“API
â”‚   â”œâ”€â”€ tutorials/
â”‚   â”‚   â”œâ”€â”€ quickstart.rst      # å¿«é€Ÿå¼€å§‹
â”‚   â”‚   â”œâ”€â”€ basic_usage.rst     # åŸºç¡€ä½¿ç”¨
â”‚   â”‚   â””â”€â”€ advanced.rst        # é«˜çº§ç‰¹æ€§
â”‚   â””â”€â”€ guides/
â”‚       â”œâ”€â”€ configuration.rst   # é…ç½®æŒ‡å—
â”‚       â”œâ”€â”€ deployment.rst      # éƒ¨ç½²æŒ‡å—
â”‚       â””â”€â”€ troubleshooting.rst # æ•…éšœæ’æŸ¥
â”œâ”€â”€ build/
â””â”€â”€ Makefile
```

**Docstring è§„èŒƒ** (Google Style):
```python
class DecisionEngine:
    """æ™ºèƒ½å†³ç­–å¼•æ“ï¼Œèåˆå¤šä¸ªç³»ç»Ÿçš„äº¤æ˜“ä¿¡å·ã€‚
    
    è¯¥ç±»è´Ÿè´£ä»Qlibã€TradingAgentså’ŒRD-Agentä¸‰ä¸ªç³»ç»Ÿè·å–ä¿¡å·ï¼Œ
    è¿›è¡ŒåŠ æƒèåˆï¼Œå¹¶åº”ç”¨é£é™©è¿‡æ»¤è§„åˆ™ï¼Œæœ€ç»ˆè¾“å‡ºäº¤æ˜“å†³ç­–ã€‚
    
    Attributes:
        qlib_generator (QlibSignalGenerator): Qlibä¿¡å·ç”Ÿæˆå™¨
        ta_generator (TradingAgentsSignalGenerator): TradingAgentsä¿¡å·ç”Ÿæˆå™¨
        rd_generator (RDAgentSignalGenerator): RD-Agentä¿¡å·ç”Ÿæˆå™¨
        fuser (SignalFuser): ä¿¡å·èåˆå™¨
        weights (Dict[str, float]): ç³»ç»Ÿæƒé‡é…ç½®
    
    Examples:
        åŸºæœ¬ä½¿ç”¨::
        
            >>> import asyncio
            >>> from decision_engine.core import get_decision_engine
            >>> 
            >>> async def main():
            ...     engine = get_decision_engine()
            ...     decisions = await engine.make_decisions(
            ...         symbols=['000001.SZ', '600000.SH'],
            ...         date='2024-06-30'
            ...     )
            ...     for decision in decisions:
            ...         print(f"{decision.symbol}: {decision.final_signal.value}")
            >>> 
            >>> asyncio.run(main())
    
    Note:
        - é»˜è®¤æƒé‡ä¸º Qlib:40%, TradingAgents:35%, RD-Agent:25%
        - å¯é€šè¿‡ `update_weights()` æ–¹æ³•åŠ¨æ€è°ƒæ•´
        - æ‰€æœ‰ä¿¡å·ç”Ÿæˆå‡ä¸ºå¼‚æ­¥æ“ä½œ
    """
    
    async def make_decisions(
        self,
        symbols: List[str],
        date: str,
        min_confidence: float = 0.5
    ) -> List[Decision]:
        """ç”Ÿæˆäº¤æ˜“å†³ç­–ã€‚
        
        Args:
            symbols (List[str]): è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¾‹å¦‚ ['000001.SZ', '600000.SH']
            date (str): å†³ç­–æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
            min_confidence (float, optional): æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼ã€‚é»˜è®¤ 0.5
        
        Returns:
            List[Decision]: å†³ç­–åˆ—è¡¨ï¼Œæ¯ä¸ªå†³ç­–åŒ…å«ï¼š
                - symbol: è‚¡ç¥¨ä»£ç 
                - final_signal: æœ€ç»ˆä¿¡å·ï¼ˆBUY/SELL/HOLDç­‰ï¼‰
                - confidence: ç½®ä¿¡åº¦ [0, 1]
                - strength: ä¿¡å·å¼ºåº¦ [0, 1]
                - reasoning: å†³ç­–æ¨ç†è¯´æ˜
                - source_signals: åŸå§‹ä¿¡å·åˆ—è¡¨
        
        Raises:
            ValueError: å¦‚æœ date æ ¼å¼ä¸æ­£ç¡®
            RuntimeError: å¦‚æœæ‰€æœ‰ä¿¡å·ç”Ÿæˆå™¨éƒ½å¤±è´¥
        
        Examples:
            ç”Ÿæˆå•ä¸ªè‚¡ç¥¨å†³ç­–::
            
                >>> decisions = await engine.make_decisions(
                ...     symbols=['000001.SZ'],
                ...     date='2024-06-30',
                ...     min_confidence=0.6
                ... )
                >>> print(decisions[0].final_signal)
                SignalType.BUY
            
            æ‰¹é‡ç”Ÿæˆå†³ç­–::
            
                >>> symbols = ['000001.SZ', '600000.SH', '600519.SH']
                >>> decisions = await engine.make_decisions(symbols, '2024-06-30')
                >>> high_conf = [d for d in decisions if d.confidence > 0.7]
        
        Note:
            - æ–¹æ³•ä¼šå¹¶è¡Œè°ƒç”¨ä¸‰ä¸ªä¿¡å·ç”Ÿæˆå™¨ä»¥æé«˜æ•ˆç‡
            - ä½äº min_confidence çš„ä¿¡å·ä¼šè¢«è¿‡æ»¤ä¸º HOLD
            - å»ºè®®å¤„ç†å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ
        """
        pass
```

**ç”Ÿæˆæ–‡æ¡£**:
```bash
# åˆå§‹åŒ–Sphinx
cd docs
sphinx-quickstart

# é…ç½®conf.py
# æ·»åŠ æ‰©å±•: 'sphinx.ext.autodoc', 'sphinx.ext.napoleon', 'sphinx.ext.viewcode'

# ç”ŸæˆHTMLæ–‡æ¡£
make html

# æŸ¥çœ‹æ–‡æ¡£
open build/html/index.html
```

**é¢„æœŸæˆæœ**:
- âœ… æ‰€æœ‰å…¬å…±APIæœ‰å®Œæ•´docstring
- âœ… è‡ªåŠ¨ç”Ÿæˆçš„HTMLæ–‡æ¡£
- âœ… ä»£ç ç¤ºä¾‹å¯è¿è¡Œ
- âœ… äº¤å‰å¼•ç”¨æ­£ç¡®

---

#### 2.2 ç”¨æˆ·æŒ‡å— (2å¤©)
**ç›®æ ‡**: ç¼–å†™é¢å‘æœ€ç»ˆç”¨æˆ·çš„ä½¿ç”¨æ–‡æ¡£

**å†…å®¹å¤§çº²**:

**å¿«é€Ÿå¼€å§‹ (QUICKSTART.md)**:
```markdown
# å¿«é€Ÿå¼€å§‹

## 5åˆ†é’Ÿä¸Šæ‰‹

### 1. å®‰è£…
```bash
pip install -r requirements.txt
```

### 2. é…ç½®
```yaml
# config/config.yaml
llm_provider: "openai"
llm_api_key: "your-key"
llm_api_base: "https://api.tu-zi.com"
```

### 3. è¿è¡Œç¬¬ä¸€ä¸ªå†³ç­–
```python
import asyncio
from decision_engine.core import get_decision_engine

async def main():
    engine = get_decision_engine()
    decisions = await engine.make_decisions(['000001.SZ'], '2024-06-30')
    print(decisions[0].final_signal)

asyncio.run(main())
```

## æ ¸å¿ƒæ¦‚å¿µ

### ä¿¡å·ç±»å‹
- BUY: ä¹°å…¥ä¿¡å·
- SELL: å–å‡ºä¿¡å·
- HOLD: æŒæœ‰
- STRONG_BUY: å¼ºä¹°
- STRONG_SELL: å¼ºå–

### ä¸‰å¤§ç³»ç»Ÿ
1. **Qlib**: é‡åŒ–æ¨¡å‹é¢„æµ‹
2. **TradingAgents**: å¤šæ™ºèƒ½ä½“ååŒ
3. **RD-Agent**: å› å­ç ”ç©¶å’Œå‘ç°

### ä¿¡å·èåˆ
é»˜è®¤æƒé‡: Qlib 40%, TradingAgents 35%, RD-Agent 25%
```

**é…ç½®æŒ‡å— (CONFIGURATION.md)**:
```markdown
# é…ç½®æŒ‡å—

## ç³»ç»Ÿé…ç½®

### LLMé…ç½®
```yaml
llm_provider: "openai"  # æˆ– "azure", "anthropic"
llm_model: "gpt-5-thinking-all"
llm_api_key: "${LLM_API_KEY}"  # æ”¯æŒç¯å¢ƒå˜é‡
llm_api_base: "https://api.tu-zi.com"
llm_timeout: 30
llm_max_retries: 3
```

### æ•°æ®æºé…ç½®
```yaml
data_sources:
  primary: "qlib"
  fallback: ["akshare", "tushare"]
  
qlib:
  provider_uri: "~/.qlib/qlib_data/cn_data"
  
akshare:
  cache_dir: "./cache/akshare"
  cache_ttl: 3600
```

### å†³ç­–å¼•æ“é…ç½®
```yaml
decision_engine:
  weights:
    qlib: 0.40
    trading_agents: 0.35
    rd_agent: 0.25
  
  thresholds:
    min_confidence: 0.5
    min_strength: 0.3
  
  risk_filters:
    max_position_size: 0.2
    max_single_stock: 0.1
```

## ç¯å¢ƒå˜é‡

å¿…éœ€:
- `LLM_API_KEY`: LLMæœåŠ¡å¯†é’¥
- `QLIB_DATA_PATH`: Qlibæ•°æ®è·¯å¾„

å¯é€‰:
- `AKSHARE_TOKEN`: AKShareä»¤ç‰Œ
- `TUSHARE_TOKEN`: Tushareä»¤ç‰Œ
- `PROMETHEUS_PORT`: ç›‘æ§ç«¯å£ (é»˜è®¤8000)
```

**æœ€ä½³å®è·µ (BEST_PRACTICES.md)**:
```markdown
# æœ€ä½³å®è·µ

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†
```python
# âŒ ä¸æ¨èï¼šé€ä¸ªå¤„ç†
for symbol in symbols:
    decisions = await engine.make_decisions([symbol], date)

# âœ… æ¨èï¼šæ‰¹é‡å¤„ç†
decisions = await engine.make_decisions(symbols, date)
```

### 2. ç¼“å­˜ä½¿ç”¨
```python
# å¯ç”¨ç¼“å­˜
from data_pipeline.unified_data import UnifiedDataPipeline
pipeline = UnifiedDataPipeline(cache_enabled=True, cache_ttl=3600)
```

### 3. å¹¶å‘æ§åˆ¶
```python
# é™åˆ¶å¹¶å‘æ•°
import asyncio
semaphore = asyncio.Semaphore(10)

async def process_with_limit(symbol):
    async with semaphore:
        return await engine.make_decisions([symbol], date)
```

## é”™è¯¯å¤„ç†

### å¥å£®çš„é”™è¯¯å¤„ç†
```python
from decision_engine.core import DecisionEngineError

try:
    decisions = await engine.make_decisions(symbols, date)
except DecisionEngineError as e:
    logger.error(f"å†³ç­–å¤±è´¥: {e}")
    # é™çº§ç­–ç•¥
    decisions = fallback_decisions(symbols)
except Exception as e:
    logger.critical(f"æœªçŸ¥é”™è¯¯: {e}")
    raise
```

## ç›‘æ§é›†æˆ

### è®°å½•å…³é”®æŒ‡æ ‡
```python
from monitoring.metrics import get_monitor

monitor = get_monitor()

# è®°å½•å†³ç­–
for decision in decisions:
    monitor.record_decision(
        symbol=decision.symbol,
        decision=decision.final_signal.value,
        latency=elapsed_time,
        confidence=decision.confidence
    )

# å®šæœŸå¯¼å‡º
metrics = monitor.export_metrics()
```
```

---

#### 2.3 éƒ¨ç½²æ–‡æ¡£ (1å¤©)
**DEPLOYMENT_PRODUCTION.md**:
```markdown
# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—

## ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚
- Python 3.9+
- 8GB+ RAM
- 50GB+ ç£ç›˜ç©ºé—´
- Linux (æ¨è Ubuntu 20.04+)

### ä¾èµ–å®‰è£…
```bash
# ç³»ç»Ÿä¾èµ–
sudo apt-get update
sudo apt-get install -y build-essential python3-dev

# Pythonä¾èµ–
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

## æ•°æ®åˆå§‹åŒ–

### Qlibæ•°æ®ä¸‹è½½
```bash
python -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn
```

### æ•°æ®éªŒè¯
```bash
python scripts/validate_data.py
```

## é…ç½®ä¼˜åŒ–

### ç”Ÿäº§é…ç½®æ¨¡æ¿
```yaml
# config/production.yaml
environment: "production"

logging:
  level: "INFO"
  file: "/var/log/qilin_stack/app.log"
  max_size: "100MB"
  backup_count: 10

performance:
  worker_threads: 8
  max_concurrent_requests: 100
  connection_pool_size: 20

monitoring:
  enabled: true
  port: 8000
  metrics_interval: 60
```

### å®‰å…¨é…ç½®
```bash
# ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨å¯†é’¥
export LLM_API_KEY="your-secret-key"
export AKSHARE_TOKEN="your-token"

# æˆ–ä½¿ç”¨secretsç®¡ç†å™¨
aws secretsmanager get-secret-value --secret-id qilin-stack-keys
```

## æœåŠ¡éƒ¨ç½²

### ä½¿ç”¨systemd
```ini
# /etc/systemd/system/qilin-stack.service
[Unit]
Description=Qilin Stack Decision Engine
After=network.target

[Service]
Type=simple
User=qilin
WorkingDirectory=/opt/qilin-stack
Environment="LLM_API_KEY=xxx"
ExecStart=/opt/qilin-stack/venv/bin/python main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
# å¯åŠ¨æœåŠ¡
sudo systemctl enable qilin-stack
sudo systemctl start qilin-stack
sudo systemctl status qilin-stack
```

### ä½¿ç”¨Docker
```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
CMD ["python", "main.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  qilin-stack:
    build: .
    ports:
      - "8000:8000"
    environment:
      - LLM_API_KEY=${LLM_API_KEY}
    volumes:
      - ./data:/app/data
      - ./config:/app/config
    restart: unless-stopped
  
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
```

## å¥åº·æ£€æŸ¥

### å¥åº·æ£€æŸ¥ç«¯ç‚¹
```python
# health_check.py
from fastapi import FastAPI
from monitoring.metrics import get_monitor

app = FastAPI()

@app.get("/health")
async def health():
    monitor = get_monitor()
    summary = monitor.get_summary()
    return {
        "status": "healthy" if summary['total_errors'] == 0 else "degraded",
        "uptime": summary['uptime'],
        "total_decisions": summary['total_decisions']
    }

@app.get("/ready")
async def ready():
    # æ£€æŸ¥ä¾èµ–æœåŠ¡
    from decision_engine.core import get_decision_engine
    engine = get_decision_engine()
    return {"ready": True}
```

### ç›‘æ§æ£€æŸ¥
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥æŒ‡æ ‡å¯¼å‡º
curl http://localhost:8000/metrics
```

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**Q: å†³ç­–å»¶è¿Ÿè¿‡é«˜**
```bash
# æ£€æŸ¥å¹¶å‘é…ç½®
# å¢åŠ workeræ•°é‡
# å¯ç”¨ç¼“å­˜

# ç›‘æ§CPU/å†…å­˜
htop
```

**Q: LLMè°ƒç”¨å¤±è´¥**
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl https://api.tu-zi.com

# æ£€æŸ¥APIå¯†é’¥
echo $LLM_API_KEY

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f /var/log/qilin_stack/app.log | grep ERROR
```

**Q: æ•°æ®åŠ è½½å¤±è´¥**
```bash
# éªŒè¯æ•°æ®å®Œæ•´æ€§
python scripts/validate_data.py

# é‡æ–°ä¸‹è½½æ•°æ®
python -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn
```

## æ€§èƒ½åŸºå‡†

### é¢„æœŸæ€§èƒ½æŒ‡æ ‡
- å†³ç­–å»¶è¿Ÿ: < 100ms (P95)
- ååé‡: > 1000 å†³ç­–/ç§’
- å†…å­˜ä½¿ç”¨: < 4GB
- CPUä½¿ç”¨: < 50% (8æ ¸)

### å‹æµ‹å‘½ä»¤
```bash
# ä½¿ç”¨locustè¿›è¡Œå‹æµ‹
locust -f tests/load_test.py --host=http://localhost:8000
```
```

---

## é˜¶æ®µ3: å®é™…æ•°æ®æ¥å…¥ (3-5å¤©) ğŸŸ 

### ç›®æ ‡
æ¥å…¥çœŸå®æ•°æ®æºï¼Œæ›¿æ¢æ¨¡æ‹Ÿæ•°æ®ã€‚

### ä»»åŠ¡æ¸…å•

#### 3.1 Qlibæ•°æ®é…ç½® (1-2å¤©)
**ä»»åŠ¡**:
1. ä¸‹è½½å¹¶åˆå§‹åŒ–Qlib cn_data
2. é…ç½®provider_uri
3. æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½
4. éªŒè¯å› å­è®¡ç®—æ­£ç¡®æ€§

**å®æ–½æ­¥éª¤**:
```bash
# 1. ä¸‹è½½æ•°æ®
python -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# 2. éªŒè¯æ•°æ®
python scripts/validate_qlib_data.py

# 3. æ€§èƒ½æµ‹è¯•
python scripts/benchmark_qlib.py
```

**éªŒè¯è„šæœ¬**:
```python
# scripts/validate_qlib_data.py
import qlib
from qlib.data import D

qlib.init(provider_uri='~/.qlib/qlib_data/cn_data')

# æµ‹è¯•æ•°æ®åŠ è½½
instruments = D.instruments(market='csi300')
print(f"åŠ è½½è‚¡ç¥¨æ•°: {len(instruments)}")

# æµ‹è¯•ç‰¹å¾è·å–
features = D.features(instruments[:10], ['$close', '$volume'], '2024-01-01', '2024-06-30')
print(f"ç‰¹å¾å½¢çŠ¶: {features.shape}")
print("âœ… Qlibæ•°æ®éªŒè¯é€šè¿‡")
```

---

#### 3.2 AKShareé›†æˆ (1-2å¤©)
**ä»»åŠ¡**:
1. å®ç°çœŸå®çš„AKShare APIè°ƒç”¨
2. å¤„ç†APIé™æµï¼ˆæ¯åˆ†é’Ÿ60æ¬¡ï¼‰
3. å®ç°é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
4. æ·»åŠ æœ¬åœ°ç¼“å­˜

**å®ç°**:
```python
# data_pipeline/adapters/akshare_adapter.py
import akshare as ak
import time
from functools import lru_cache
from typing import Optional
import pandas as pd

class RateLimiter:
    """APIè°ƒç”¨é¢‘ç‡é™åˆ¶å™¨"""
    def __init__(self, calls_per_minute: int = 60):
        self.calls_per_minute = calls_per_minute
        self.calls = []
    
    def wait_if_needed(self):
        now = time.time()
        # ç§»é™¤1åˆ†é’Ÿå‰çš„è®°å½•
        self.calls = [t for t in self.calls if now - t < 60]
        
        if len(self.calls) >= self.calls_per_minute:
            sleep_time = 60 - (now - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(now)

class RealAKShareAdapter:
    """çœŸå®çš„AKShareæ•°æ®é€‚é…å™¨"""
    
    def __init__(self):
        self.rate_limiter = RateLimiter(calls_per_minute=60)
        self.cache = {}
    
    def _call_with_retry(self, func, *args, max_retries=3, **kwargs):
        """å¸¦é‡è¯•çš„APIè°ƒç”¨"""
        for attempt in range(max_retries):
            try:
                self.rate_limiter.wait_if_needed()
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
    
    def get_realtime_data(self, symbol: str) -> Optional[pd.DataFrame]:
        """è·å–å®æ—¶è¡Œæƒ…"""
        cache_key = f"realtime_{symbol}_{int(time.time() // 60)}"
        
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        try:
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            code = symbol.split('.')[0]
            df = self._call_with_retry(ak.stock_zh_a_spot_em)
            data = df[df['ä»£ç '] == code]
            
            self.cache[cache_key] = data
            return data
        except Exception as e:
            print(f"è·å–å®æ—¶æ•°æ®å¤±è´¥ {symbol}: {e}")
            return None
    
    def get_historical_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str
    ) -> Optional[pd.DataFrame]:
        """è·å–å†å²æ•°æ®"""
        cache_key = f"hist_{symbol}_{start_date}_{end_date}"
        
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        try:
            code = symbol.split('.')[0]
            df = self._call_with_retry(
                ak.stock_zh_a_hist,
                symbol=code,
                period="daily",
                start_date=start_date.replace('-', ''),
                end_date=end_date.replace('-', ''),
                adjust="qfq"
            )
            
            self.cache[cache_key] = df
            return df
        except Exception as e:
            print(f"è·å–å†å²æ•°æ®å¤±è´¥ {symbol}: {e}")
            return None
```

**æµ‹è¯•**:
```python
# tests/test_akshare_real.py
import pytest
from data_pipeline.adapters.akshare_adapter import RealAKShareAdapter

def test_akshare_realtime():
    adapter = RealAKShareAdapter()
    data = adapter.get_realtime_data('000001.SZ')
    assert data is not None
    assert len(data) > 0

def test_akshare_historical():
    adapter = RealAKShareAdapter()
    data = adapter.get_historical_data('000001.SZ', '2024-01-01', '2024-06-30')
    assert data is not None
    assert len(data) > 0
```

---

#### 3.3 æ•°æ®è´¨é‡æ£€æŸ¥ (1å¤©)
**ä»»åŠ¡**:
1. å®ç°æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
2. æ£€æµ‹å¼‚å¸¸å€¼
3. å¤„ç†ç¼ºå¤±æ•°æ®
4. æ•°æ®æ¸…æ´—æµç¨‹

**å®ç°**:
```python
# data_pipeline/quality_check.py
from typing import List, Dict
import pandas as pd
import numpy as np

class DataQualityChecker:
    """æ•°æ®è´¨é‡æ£€æŸ¥å™¨"""
    
    def check_completeness(self, df: pd.DataFrame) -> Dict:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        total = len(df)
        missing = df.isnull().sum()
        
        return {
            'total_rows': total,
            'missing_values': missing.to_dict(),
            'completeness': 1 - (missing.sum() / (total * len(df.columns)))
        }
    
    def detect_outliers(self, df: pd.DataFrame, column: str) -> List[int]:
        """æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰"""
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
        return outliers.index.tolist()
    
    def check_time_series_gaps(self, df: pd.DataFrame, date_column: str) -> List[str]:
        """æ£€æŸ¥æ—¶é—´åºåˆ—æ–­ç‚¹"""
        dates = pd.to_datetime(df[date_column])
        date_range = pd.date_range(dates.min(), dates.max(), freq='D')
        
        # æ’é™¤å‘¨æœ«
        business_days = date_range[date_range.dayofweek < 5]
        missing_dates = set(business_days) - set(dates)
        
        return [d.strftime('%Y-%m-%d') for d in missing_dates]
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—"""
        df_clean = df.copy()
        
        # 1. åˆ é™¤å…¨ç©ºè¡Œ
        df_clean = df_clean.dropna(how='all')
        
        # 2. å¡«å……ç¼ºå¤±å€¼ï¼ˆå‰å‘å¡«å……ï¼‰
        df_clean = df_clean.fillna(method='ffill')
        
        # 3. å¤„ç†å¼‚å¸¸å€¼ï¼ˆé™åˆ¶åœ¨3ä¸ªæ ‡å‡†å·®å†…ï¼‰
        for col in df_clean.select_dtypes(include=[np.number]).columns:
            mean = df_clean[col].mean()
            std = df_clean[col].std()
            df_clean[col] = df_clean[col].clip(mean - 3*std, mean + 3*std)
        
        return df_clean
    
    def generate_quality_report(self, df: pd.DataFrame) -> Dict:
        """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
        return {
            'completeness': self.check_completeness(df),
            'shape': df.shape,
            'dtypes': df.dtypes.to_dict(),
            'summary': df.describe().to_dict()
        }
```

---

## é˜¶æ®µ4: ç›‘æ§éƒ¨ç½² (2å¤©) ğŸŸ 

### ç›®æ ‡
éƒ¨ç½²å®Œæ•´çš„ç›‘æ§æ ˆï¼Œå®ç°å¯è§†åŒ–å’Œå‘Šè­¦ã€‚

### ä»»åŠ¡æ¸…å•

#### 4.1 Prometheusé…ç½® (0.5å¤©)
**é…ç½®æ–‡ä»¶**:
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'qilin-stack'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'

rule_files:
  - 'alerts.yml'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['localhost:9093']
```

**å¯åŠ¨**:
```bash
# Dockeræ–¹å¼
docker run -d \
  --name prometheus \
  -p 9090:9090 \
  -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \
  prom/prometheus
```

---

#### 4.2 Grafanaé¢æ¿ (1å¤©)
**é¢æ¿é…ç½®JSON** (`grafana/qilin-stack-dashboard.json`):
```json
{
  "dashboard": {
    "title": "Qilin Stack ç›‘æ§é¢æ¿",
    "panels": [
      {
        "title": "å†³ç­–æ•°é‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(decision_made_total[5m])",
            "legendFormat": "{{symbol}}"
          }
        ]
      },
      {
        "title": "ä¿¡å·ç½®ä¿¡åº¦",
        "type": "gauge",
        "targets": [
          {
            "expr": "avg(signal_confidence)",
            "legendFormat": "å¹³å‡ç½®ä¿¡åº¦"
          }
        ]
      },
      {
        "title": "ç³»ç»Ÿæƒé‡åˆ†å¸ƒ",
        "type": "pie",
        "targets": [
          {
            "expr": "system_weight",
            "legendFormat": "{{system}}"
          }
        ]
      },
      {
        "title": "å†³ç­–å»¶è¿Ÿ (P95)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(decision_latency_seconds_bucket[5m]))",
            "legendFormat": "P95å»¶è¿Ÿ"
          }
        ]
      }
    ]
  }
}
```

**å¯¼å…¥æ­¥éª¤**:
1. è®¿é—® http://localhost:3000
2. æ·»åŠ Prometheusæ•°æ®æº
3. å¯¼å…¥dashboard JSON
4. é…ç½®åˆ·æ–°é—´éš”

---

#### 4.3 å‘Šè­¦è§„åˆ™ (0.5å¤©)
**é…ç½®**:
```yaml
# alerts.yml
groups:
  - name: qilin_stack_alerts
    interval: 30s
    rules:
      # é«˜é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: rate(error_count_total[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "é”™è¯¯ç‡è¿‡é«˜"
          description: "è¿‡å»5åˆ†é’Ÿé”™è¯¯ç‡: {{ $value }}"
      
      # ä½ç½®ä¿¡åº¦å‘Šè­¦
      - alert: LowConfidence
        expr: avg(signal_confidence) < 0.4
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ä¿¡å·ç½®ä¿¡åº¦è¿‡ä½"
          description: "å¹³å‡ç½®ä¿¡åº¦: {{ $value }}"
      
      # å†³ç­–å»¶è¿Ÿå‘Šè­¦
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(decision_latency_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å†³ç­–å»¶è¿Ÿè¿‡é«˜"
          description: "P95å»¶è¿Ÿ: {{ $value }}ç§’"
      
      # æœåŠ¡å®•æœºå‘Šè­¦
      - alert: ServiceDown
        expr: up{job="qilin-stack"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æœåŠ¡å®•æœº"
          description: "Qilin StackæœåŠ¡æ— å“åº”"
```

**AlertManageré…ç½®**:
```yaml
# alertmanager.yml
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'

receivers:
  - name: 'default'
    webhook_configs:
      - url: 'http://localhost:5001/alert'  # è‡ªå®šä¹‰webhook
    email_configs:
      - to: 'alert@example.com'
        from: 'prometheus@example.com'
        smarthost: 'smtp.example.com:587'
        auth_username: 'user'
        auth_password: 'pass'
```

---

## é˜¶æ®µ5-7 (è¯¦ç»†è®¡åˆ’è§åç»­ä»»åŠ¡...)

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œé˜¶æ®µ5-7çš„è¯¦ç»†å®æ–½æ­¥éª¤å°†åœ¨å¼€å§‹æ‰§è¡Œæ—¶é€æ­¥å±•å¼€ã€‚

---

## ğŸ“… æ—¶é—´è¡¨

### ç¬¬1-2å‘¨: æµ‹è¯•ä¸æ–‡æ¡£ (P0)
- Day 1-3: å•å…ƒæµ‹è¯•
- Day 4-5: é›†æˆæµ‹è¯• + CI
- Day 6-8: APIæ–‡æ¡£
- Day 9-10: ç”¨æˆ·æŒ‡å— + éƒ¨ç½²æ–‡æ¡£

### ç¬¬3å‘¨: æ•°æ®ä¸ç›‘æ§ (P1)
- Day 11-12: Qlibæ•°æ®æ¥å…¥
- Day 13-14: AKShareé›†æˆ
- Day 15: æ•°æ®è´¨é‡æ£€æŸ¥
- Day 16-17: ç›‘æ§éƒ¨ç½²

### ç¬¬4-5å‘¨: ä¼˜åŒ–ä¸å›æµ‹ (P2)
- Day 18-19: å¹¶å‘ä¼˜åŒ–
- Day 20: ç¼“å­˜ç­–ç•¥
- Day 21-22: æ•°æ®åº“æŒä¹…åŒ–
- Day 23-26: å›æµ‹ç³»ç»Ÿ
- Day 27-29: å®ç›˜æ¨¡æ‹Ÿ

### ç¬¬6å‘¨: ç”Ÿäº§éƒ¨ç½² (P3)
- Day 30-32: å®¹å™¨åŒ–å’Œç¼–æ’
- Day 33-35: éƒ¨ç½²éªŒè¯å’Œä¼˜åŒ–

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### é˜¶æ®µ1å®Œæˆæ ‡å‡†
- [ ] æµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%
- [ ] CIå…¨éƒ¨é€šè¿‡
- [ ] ä»£ç è´¨é‡è¯„åˆ† â‰¥ 8.0

### é˜¶æ®µ2å®Œæˆæ ‡å‡†
- [ ] APIæ–‡æ¡£å®Œæ•´å¯æµè§ˆ
- [ ] ç”¨æˆ·æŒ‡å—æ¸…æ™°æ˜“æ‡‚
- [ ] éƒ¨ç½²æ–‡æ¡£å¯æ“ä½œ

### é˜¶æ®µ3å®Œæˆæ ‡å‡†
- [ ] çœŸå®æ•°æ®åŠ è½½æˆåŠŸ
- [ ] æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡
- [ ] æ€§èƒ½ç¬¦åˆé¢„æœŸ

### é˜¶æ®µ4å®Œæˆæ ‡å‡†
- [ ] Prometheusæ­£å¸¸é‡‡é›†æŒ‡æ ‡
- [ ] Grafanaé¢æ¿å±•ç¤ºæ­£ç¡®
- [ ] å‘Šè­¦è§„åˆ™è§¦å‘æ­£å¸¸

### æœ€ç»ˆäº¤ä»˜æ ‡å‡†
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ–‡æ¡£å®Œæ•´
- [ ] ç›‘æ§æ­£å¸¸
- [ ] æ€§èƒ½è¾¾æ ‡
- [ ] å¯ç”Ÿäº§éƒ¨ç½²

---

## ğŸ“ è”ç³»ä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ:
- ğŸ“– [APIæ–‡æ¡£](docs/build/html/index.html)
- ğŸ’¬ [Issue Tracker](https://github.com/your-repo/issues)
- ğŸ“§ support@example.com

---

**å‡†å¤‡å¼€å§‹ç¬¬ä¸€ä¸ªä»»åŠ¡ â†’ é˜¶æ®µ1.1: å•å…ƒæµ‹è¯•**
