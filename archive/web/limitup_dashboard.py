# -*- coding: utf-8 -*-
"""
éº’éºŸé‡åŒ–ç³»ç»Ÿ - æ¶¨åœæ¿é€‰è‚¡ Web Dashboard
å®æ—¶æ˜¾ç¤ºç«ä»·ç›‘æ§ã€AIå†³ç­–ã€æ¶¨åœåŸå› è§£é‡Šã€Thompson Samplingæ¨è
"""
import os
import glob
import json
import datetime as dt
from pathlib import Path
import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # é¿å…GUIå†²çª

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="éº’éºŸæ¶¨åœæ¿é€‰è‚¡ç³»ç»Ÿ",
    page_icon="ğŸ‰",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .main { padding-top: 2rem !important; }
    .stMetric {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .success-box {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border-left: 4px solid #17a2b8;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# ==================== è¾…åŠ©å‡½æ•° ====================

def find_latest(pattern):
    """æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶"""
    files = glob.glob(pattern)
    if not files:
        return None
    return max(files, key=os.path.getmtime)

def load_json_safe(path):
    """å®‰å…¨åŠ è½½JSON"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥: {path}\né”™è¯¯: {e}")
        return None

def load_csv_safe(path):
    """å®‰å…¨åŠ è½½CSV"""
    try:
        return pd.read_csv(path)
    except Exception as e:
        st.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥: {path}\né”™è¯¯: {e}")
        return None

# ==================== ä¾§è¾¹æ é…ç½® ====================

st.sidebar.title("âš™ï¸ é…ç½®")
reports_dir = st.sidebar.text_input("Reportsç›®å½•", value="reports")
config_dir = st.sidebar.text_input("Configç›®å½•", value="config")
selected_date = st.sidebar.date_input(
    "é€‰æ‹©æ—¥æœŸ",
    value=dt.datetime.now(),
    help="æŸ¥çœ‹æŒ‡å®šæ—¥æœŸçš„æ•°æ®"
)
date_str = selected_date.strftime("%Y-%m-%d")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“š å¿«é€Ÿå¯¼èˆª")
st.sidebar.markdown("- [ä»Šæ—¥ä¿¡å·](#tab-signals)")
st.sidebar.markdown("- [AIå†³ç­–](#tab-ai)")
st.sidebar.markdown("- [æ¶¨åœåŸå› ](#tab-reasons)")
st.sidebar.markdown("- [RLæ¨è](#tab-rl)")
st.sidebar.markdown("- [å›æµ‹ç»“æœ](#tab-backtest)")

# ==================== ä¸»æ ‡é¢˜ ====================

st.title("ğŸ‰ éº’éºŸæ¶¨åœæ¿é€‰è‚¡ç³»ç»Ÿ")
st.markdown(f"**å½“å‰æ—¥æœŸ**: {date_str} | **æ›´æ–°æ—¶é—´**: {dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ==================== æ ‡ç­¾é¡µ ====================

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“‹ ä»Šæ—¥ä¿¡å·",
    "ğŸ¤– AIå†³ç­–è¿‡ç¨‹",
    "ğŸ§  æ¶¨åœåŸå› è§£é‡Š",
    "âš™ï¸ RLå‚æ•°æ¨è",
    "ğŸ“Š å›æµ‹ç»“æœ"
])

# ==================== Tab 1: ä»Šæ—¥ä¿¡å· ====================

with tab1:
    st.subheader("ğŸ“‹ ä»Šæ—¥æ¶¨åœæ¿å€™é€‰ä¿¡å·")
    
    col1, col2, col3 = st.columns(3)
    
    # æŸ¥æ‰¾å½“æ—¥ç«ä»·æŠ¥å‘Š
    auction_pattern = os.path.join(reports_dir, f"auction_report_{date_str}*.json")
    auction_file = find_latest(auction_pattern)
    
    if auction_file and os.path.exists(auction_file):
        auction_data = load_json_safe(auction_file)
        
        if auction_data:
            col1.metric("å€™é€‰è‚¡ç¥¨æ•°", len(auction_data.get("stocks", [])))
            
            # æå–ç»Ÿè®¡ä¿¡æ¯
            stocks = auction_data.get("stocks", [])
            if stocks:
                avg_strength = np.mean([s.get("auction_info", {}).get("strength", 0) for s in stocks])
                col2.metric("å¹³å‡ç«ä»·å¼ºåº¦", f"{avg_strength:.1f}")
                
                first_boards = sum(1 for s in stocks if s.get("yesterday_info", {}).get("is_first_board", False))
                col3.metric("é¦–æ¿æ•°é‡", first_boards)
                
                # æ˜¾ç¤ºè‚¡ç¥¨åˆ—è¡¨
                st.markdown("### å€™é€‰è‚¡ç¥¨è¯¦æƒ…")
                
                rows = []
                for stock in stocks:
                    yesterday = stock.get("yesterday_info", {})
                    auction = stock.get("auction_info", {})
                    
                    rows.append({
                        "ä»£ç ": stock.get("symbol", ""),
                        "åç§°": stock.get("name", ""),
                        "è¿æ¿å¤©æ•°": yesterday.get("consecutive_days", 0),
                        "å°å•å¼ºåº¦": f"{yesterday.get('seal_ratio', 0):.2%}",
                        "è´¨é‡åˆ†": f"{yesterday.get('quality_score', 0):.1f}",
                        "ç«ä»·æ¶¨å¹…": f"{auction.get('final_change', 0):.2%}",
                        "ç«ä»·å¼ºåº¦": f"{auction.get('strength', 0):.1f}",
                        "æ˜¯å¦é¦–æ¿": "âœ…" if yesterday.get("is_first_board") else "âŒ",
                        "æ˜¯å¦é¾™å¤´": "â­" if yesterday.get("is_leader") else "",
                    })
                
                df_stocks = pd.DataFrame(rows)
                st.dataframe(df_stocks, use_container_width=True)
                
                # ç«ä»·å¼ºåº¦åˆ†å¸ƒå›¾
                st.markdown("### ç«ä»·å¼ºåº¦åˆ†å¸ƒ")
                strengths = [s.get("auction_info", {}).get("strength", 0) for s in stocks]
                
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.hist(strengths, bins=20, edgecolor='black', alpha=0.7, color='#1f77b4')
                ax.set_xlabel("ç«ä»·å¼ºåº¦")
                ax.set_ylabel("æ•°é‡")
                ax.set_title("ç«ä»·å¼ºåº¦åˆ†å¸ƒ")
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close()
            else:
                st.info("å½“æ—¥æ— å€™é€‰è‚¡ç¥¨")
    else:
        st.warning(f"æœªæ‰¾åˆ° {date_str} çš„ç«ä»·æŠ¥å‘Š\n\nè¯·è¿è¡Œ: `python app/auction_monitor_system.py`")

# ==================== Tab 2: AIå†³ç­–è¿‡ç¨‹ ====================

with tab2:
    st.subheader("ğŸ¤– AIå†³ç­–è¿‡ç¨‹ä¸æƒé‡")
    
    # åŠ è½½RLå†³ç­–ç»“æœ
    rl_result_pattern = os.path.join(reports_dir, f"rl_decision_{date_str}*.json")
    rl_result_file = find_latest(rl_result_pattern)
    
    if rl_result_file and os.path.exists(rl_result_file):
        rl_data = load_json_safe(rl_result_file)
        
        if rl_data:
            col1, col2, col3 = st.columns(3)
            
            selected = rl_data.get("selected_stocks", [])
            col1.metric("æœ€ç»ˆé€‰ä¸­", len(selected), help="é€šè¿‡RLé˜ˆå€¼ç­›é€‰çš„è‚¡ç¥¨æ•°")
            
            config = rl_data.get("config", {})
            col2.metric("RLå¾—åˆ†é˜ˆå€¼", config.get("min_rl_score", 70))
            col3.metric("Top N", config.get("top_n_stocks", 5))
            
            # æ˜¾ç¤ºé€‰ä¸­çš„è‚¡ç¥¨
            if selected:
                st.markdown("### ğŸ¯ æœ€ç»ˆé€‰ä¸­è‚¡ç¥¨")
                
                rows = []
                for i, stock in enumerate(selected, 1):
                    yesterday = stock.get("yesterday_info", {})
                    reasons = stock.get("reasons", [])
                    
                    rows.append({
                        "æ’å": i,
                        "ä»£ç ": stock.get("symbol", ""),
                        "åç§°": stock.get("name", ""),
                        "RLå¾—åˆ†": f"{stock.get('rl_score', 0):.2f}",
                        "è¿æ¿å¤©æ•°": yesterday.get("consecutive_days", 0),
                        "æ¶¨åœåŸå› ": ", ".join(reasons[:3]),
                    })
                
                df_selected = pd.DataFrame(rows)
                st.dataframe(df_selected, use_container_width=True)
                
                # RLå¾—åˆ†åˆ†å¸ƒ
                st.markdown("### RLå¾—åˆ†åˆ†å¸ƒ")
                
                all_ranked = rl_data.get("ranked_stocks", [])
                if all_ranked:
                    scores = [s.get("rl_score", 0) for s in all_ranked]
                    
                    fig, ax = plt.subplots(figsize=(10, 4))
                    ax.hist(scores, bins=30, edgecolor='black', alpha=0.7, color='#ff7f0e')
                    ax.axvline(config.get("min_rl_score", 70), color='red', linestyle='--', label='é˜ˆå€¼')
                    ax.set_xlabel("RLå¾—åˆ†")
                    ax.set_ylabel("æ•°é‡")
                    ax.set_title("RLå¾—åˆ†åˆ†å¸ƒ")
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    st.pyplot(fig)
                    plt.close()
    else:
        st.warning(f"æœªæ‰¾åˆ° {date_str} çš„RLå†³ç­–ç»“æœ")
    
    # æ˜¾ç¤ºç‰¹å¾æƒé‡
    st.markdown("### ğŸ“Š ç‰¹å¾æƒé‡é…ç½®")
    
    weights_file = os.path.join(config_dir, "rl_weights.json")
    if os.path.exists(weights_file):
        weights_data = load_json_safe(weights_file)
        
        if weights_data and "feature_weights" in weights_data:
            weights = weights_data["feature_weights"]
            
            # æƒé‡å¯è§†åŒ–
            fig, ax = plt.subplots(figsize=(10, 6))
            features = list(weights.keys())
            values = list(weights.values())
            
            ax.barh(features, values, color='#2ca02c', alpha=0.7)
            ax.set_xlabel("æƒé‡")
            ax.set_title("ç‰¹å¾æƒé‡åˆ†å¸ƒ")
            ax.grid(True, alpha=0.3, axis='x')
            st.pyplot(fig)
            plt.close()
            
            # æ˜¾ç¤ºæƒé‡è¡¨æ ¼
            with st.expander("æŸ¥çœ‹è¯¦ç»†æƒé‡"):
                df_weights = pd.DataFrame({
                    "ç‰¹å¾": features,
                    "æƒé‡": values
                }).sort_values("æƒé‡", ascending=False)
                st.dataframe(df_weights, use_container_width=True)
    else:
        st.info("æœªæ‰¾åˆ°æƒé‡é…ç½®æ–‡ä»¶")

# ==================== Tab 3: æ¶¨åœåŸå› è§£é‡Š ====================

with tab3:
    st.subheader("ğŸ§  æ¶¨åœåŸå› è§£é‡Š")
    
    # ä»RLå†³ç­–ç»“æœä¸­æå–æ¶¨åœåŸå› 
    rl_result_pattern = os.path.join(reports_dir, f"rl_decision_{date_str}*.json")
    rl_result_file = find_latest(rl_result_pattern)
    
    if rl_result_file and os.path.exists(rl_result_file):
        rl_data = load_json_safe(rl_result_file)
        
        if rl_data:
            all_ranked = rl_data.get("ranked_stocks", [])
            
            if all_ranked:
                # ç»Ÿè®¡æ‰€æœ‰åŸå› 
                all_reasons = []
                for stock in all_ranked:
                    reasons = stock.get("reasons", [])
                    all_reasons.extend(reasons)
                
                if all_reasons:
                    # åŸå› é¢‘æ¬¡ç»Ÿè®¡
                    from collections import Counter
                    reason_counts = Counter(all_reasons)
                    
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.markdown("### æ¶¨åœåŸå› Top10")
                        
                        top_reasons = reason_counts.most_common(10)
                        reasons_list = [r[0] for r in top_reasons]
                        counts_list = [r[1] for r in top_reasons]
                        
                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.barh(reasons_list, counts_list, color='#d62728', alpha=0.7)
                        ax.set_xlabel("å‡ºç°æ¬¡æ•°")
                        ax.set_title("æ¶¨åœåŸå› é¢‘æ¬¡ç»Ÿè®¡")
                        ax.grid(True, alpha=0.3, axis='x')
                        st.pyplot(fig)
                        plt.close()
                    
                    with col2:
                        st.markdown("### è¯¦ç»†ç»Ÿè®¡")
                        for reason, count in top_reasons:
                            percentage = count / len(all_ranked) * 100
                            st.metric(reason, count, f"{percentage:.1f}%")
                    
                    # æ˜¾ç¤ºæ¯åªè‚¡ç¥¨çš„åŸå› 
                    st.markdown("### ä¸ªè‚¡æ¶¨åœåŸå› è¯¦æƒ…")
                    
                    rows = []
                    for stock in all_ranked[:20]:  # åªæ˜¾ç¤ºå‰20åª
                        reasons = stock.get("reasons", [])
                        reason_scores = stock.get("reason_scores", [])
                        
                        # æ ¼å¼åŒ–åŸå› 
                        reason_str = ""
                        for i, (reason, score_tuple) in enumerate(zip(reasons, reason_scores)):
                            if isinstance(score_tuple, (list, tuple)) and len(score_tuple) >= 2:
                                score = score_tuple[1]
                            else:
                                score = 1.0
                            reason_str += f"{i+1}. {reason} ({score:.2f})\n"
                        
                        rows.append({
                            "ä»£ç ": stock.get("symbol", ""),
                            "åç§°": stock.get("name", ""),
                            "RLå¾—åˆ†": f"{stock.get('rl_score', 0):.2f}",
                            "æ¶¨åœåŸå› ": reason_str.strip() or "æ— "
                        })
                    
                    df_reasons = pd.DataFrame(rows)
                    st.dataframe(df_reasons, use_container_width=True, height=400)
                else:
                    st.info("æš‚æ— æ¶¨åœåŸå› æ•°æ®")
            else:
                st.info("æš‚æ— æ’åºè‚¡ç¥¨æ•°æ®")
    else:
        st.warning(f"æœªæ‰¾åˆ° {date_str} çš„å†³ç­–ç»“æœ")

# ==================== Tab 4: RLå‚æ•°æ¨è ====================

with tab4:
    st.subheader("âš™ï¸ Thompson Sampling RLå‚æ•°æ¨è")
    
    weights_file = os.path.join(config_dir, "rl_weights.json")
    
    if os.path.exists(weights_file):
        weights_data = load_json_safe(weights_file)
        
        if weights_data:
            col1, col2, col3 = st.columns(3)
            
            best_action = weights_data.get("best_action", [70.0, 5])
            col1.metric("æ¨èmin_score", f"{best_action[0]:.1f}", help="æœ€ä½RLå¾—åˆ†é˜ˆå€¼")
            col2.metric("æ¨ètopk", best_action[1], help="æ¯æ—¥é€‰æ‹©è‚¡ç¥¨æ•°")
            col3.metric("è¿­ä»£æ¬¡æ•°", weights_data.get("iteration", 0), help="ç´¯è®¡å­¦ä¹ æ¬¡æ•°")
            
            # BanditçŠ¶æ€
            st.markdown("### BanditçŠ¶æ€ï¼ˆBetaåˆ†å¸ƒå‚æ•°ï¼‰")
            
            bandit_state = weights_data.get("bandit_state", {})
            if bandit_state:
                rows = []
                for action_key, params in bandit_state.items():
                    alpha, beta = params
                    # è§£æaction
                    parts = action_key.split("_")
                    min_score = float(parts[0])
                    topk = int(parts[1])
                    
                    # è®¡ç®—æœŸæœ›å€¼
                    expected = alpha / (alpha + beta)
                    
                    rows.append({
                        "min_score": min_score,
                        "topk": topk,
                        "alpha": f"{alpha:.2f}",
                        "beta": f"{beta:.2f}",
                        "æœŸæœ›æˆåŠŸç‡": f"{expected:.2%}",
                        "æ ·æœ¬æ•°": int(alpha + beta - 2)
                    })
                
                df_bandit = pd.DataFrame(rows).sort_values("æœŸæœ›æˆåŠŸç‡", ascending=False)
                st.dataframe(df_bandit, use_container_width=True)
                
                # å¯è§†åŒ–æœŸæœ›æˆåŠŸç‡
                st.markdown("### æœŸæœ›æˆåŠŸç‡åˆ†å¸ƒ")
                
                fig, ax = plt.subplots(figsize=(12, 6))
                
                # æŒ‰topkåˆ†ç»„
                for topk in sorted(df_bandit["topk"].unique()):
                    subset = df_bandit[df_bandit["topk"] == topk]
                    expected_rates = [float(r.strip('%'))/100 for r in subset["æœŸæœ›æˆåŠŸç‡"]]
                    min_scores = subset["min_score"].values
                    ax.plot(min_scores, expected_rates, marker='o', label=f'TopK={topk}', linewidth=2)
                
                ax.set_xlabel("Min Score")
                ax.set_ylabel("æœŸæœ›æˆåŠŸç‡")
                ax.set_title("ä¸åŒå‚æ•°ç»„åˆçš„æœŸæœ›æˆåŠŸç‡")
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                plt.close()
            else:
                st.info("BanditçŠ¶æ€ä¸ºç©ºï¼Œéœ€è¦ç§¯ç´¯æ›´å¤šæ•°æ®")
    else:
        st.warning("æœªæ‰¾åˆ°RLæƒé‡æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿ")

# ==================== Tab 5: å›æµ‹ç»“æœ ====================

with tab5:
    st.subheader("ğŸ“Š å›æµ‹ç»“æœ")
    
    # æŸ¥æ‰¾æœ€æ–°çš„å›æµ‹æŠ¥å‘Š
    backtest_pattern = os.path.join(reports_dir, "backtest", "metrics_*.json")
    backtest_file = find_latest(backtest_pattern)
    
    if backtest_file and os.path.exists(backtest_file):
        metrics = load_json_safe(backtest_file)
        
        if metrics:
            col1, col2, col3, col4 = st.columns(4)
            
            col1.metric("æ€»æ”¶ç›Šç‡", f"{metrics.get('total_return', 0):.2%}")
            col2.metric("å¹´åŒ–æ”¶ç›Šç‡", f"{metrics.get('annualized_return', 0):.2%}")
            col3.metric("Sharpeæ¯”ç‡", f"{metrics.get('sharpe_ratio', 0):.2f}")
            col4.metric("æœ€å¤§å›æ’¤", f"{metrics.get('max_drawdown', 0):.2%}")
            
            col5, col6, col7, col8 = st.columns(4)
            
            col5.metric("èƒœç‡", f"{metrics.get('win_rate', 0):.2%}")
            col6.metric("æ€»äº¤æ˜“æ¬¡æ•°", metrics.get('total_trades', 0))
            col7.metric("å¹³å‡å•ç¬”æ”¶ç›Š", f"{metrics.get('avg_profit', 0):.2f}")
            col8.metric("å¹³å‡æ”¶ç›Šç‡", f"{metrics.get('avg_profit_rate', 0):.2%}")
            
            # åŠ è½½å‡€å€¼æ›²çº¿
            equity_pattern = os.path.join(reports_dir, "backtest", "equity_curve_*.csv")
            equity_file = find_latest(equity_pattern)
            
            if equity_file and os.path.exists(equity_file):
                equity_df = load_csv_safe(equity_file)
                
                if equity_df is not None and not equity_df.empty:
                    st.markdown("### å‡€å€¼æ›²çº¿")
                    
                    fig, ax = plt.subplots(figsize=(12, 6))
                    
                    if "date" in equity_df.columns and "total_value" in equity_df.columns:
                        equity_df["date"] = pd.to_datetime(equity_df["date"])
                        equity_df = equity_df.sort_values("date")
                        
                        # å½’ä¸€åŒ–å‡€å€¼
                        initial_value = equity_df["total_value"].iloc[0]
                        equity_df["å‡€å€¼"] = equity_df["total_value"] / initial_value
                        
                        ax.plot(equity_df["date"], equity_df["å‡€å€¼"], linewidth=2, color='#1f77b4')
                        ax.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5)
                        ax.set_xlabel("æ—¥æœŸ")
                        ax.set_ylabel("å‡€å€¼ï¼ˆå½’ä¸€åŒ–ï¼‰")
                        ax.set_title("å›æµ‹å‡€å€¼æ›²çº¿")
                        ax.grid(True, alpha=0.3)
                        plt.xticks(rotation=45)
                        st.pyplot(fig)
                        plt.close()
            
            # äº¤æ˜“è®°å½•
            trades_pattern = os.path.join(reports_dir, "backtest", "trade_log_*.csv")
            trades_file = find_latest(trades_pattern)
            
            if trades_file and os.path.exists(trades_file):
                trades_df = load_csv_safe(trades_file)
                
                if trades_df is not None and not trades_df.empty:
                    st.markdown("### æœ€è¿‘äº¤æ˜“è®°å½•")
                    st.dataframe(trades_df.tail(20), use_container_width=True)
    else:
        st.warning("æœªæ‰¾åˆ°å›æµ‹ç»“æœ\n\nè¯·è¿è¡Œ: `python app/backtest_engine.py`")

# ==================== é¡µè„š ====================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>éº’éºŸé‡åŒ–æ¶¨åœæ¿é€‰è‚¡ç³»ç»Ÿ v2.0 | Powered by Streamlit</p>
    <p>é›†åˆç«ä»·ç›‘æ§ â†’ AIæ™ºèƒ½å†³ç­– â†’ æ¶¨åœåŸå› è§£é‡Š â†’ Thompson Samplingä¼˜åŒ–</p>
</div>
""", unsafe_allow_html=True)
