"""
æ–°é—»APIå·¥å…· (P1-2 Tool 1)

æ•°æ®æº:
1. Finnhub (é‡‘èæ–°é—» - å›½é™…)
2. NewsAPI (é€šç”¨æ–°é—» - å›½é™…)
3. ä¸œæ–¹è´¢å¯Œ/æ–°æµªè´¢ç» (Aè‚¡æ–°é—» - å›½å†…)
4. é›ªçƒ (ç¤¾åŒºæ–°é—»)

åŠŸèƒ½:
- å…¬å¸æ–°é—»è·å–
- å…³é”®è¯æœç´¢
- æƒ…ç»ªåˆ†æ
- æ–°é—»æ‘˜è¦
"""

import os
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
import logging
import json

logger = logging.getLogger(__name__)


# ============================================================================
# æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class NewsArticle:
    """æ–°é—»æ–‡ç« """
    id: str
    title: str
    summary: str
    source: str
    url: str
    published_at: datetime
    sentiment: Optional[float] = None  # -1 ~ 1
    relevance: Optional[float] = None  # 0 ~ 1
    category: Optional[str] = None
    symbols: List[str] = None
    
    def __post_init__(self):
        if self.symbols is None:
            self.symbols = []


# ============================================================================
# æ–°é—»APIå·¥å…·
# ============================================================================

class NewsAPITool:
    """
    æ–°é—»APIå·¥å…·
    
    ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®:
    - FINNHUB_API_KEY: Finnhub APIå¯†é’¥
    - NEWS_API_KEY: NewsAPIå¯†é’¥
    """
    
    def __init__(
        self,
        finnhub_key: Optional[str] = None,
        newsapi_key: Optional[str] = None,
        enable_sentiment: bool = True
    ):
        """
        åˆå§‹åŒ–æ–°é—»APIå·¥å…·
        
        Args:
            finnhub_key: Finnhub APIå¯†é’¥
            newsapi_key: NewsAPIå¯†é’¥
            enable_sentiment: å¯ç”¨æƒ…ç»ªåˆ†æ
        """
        self.finnhub_key = finnhub_key or os.getenv("FINNHUB_API_KEY")
        self.newsapi_key = newsapi_key or os.getenv("NEWS_API_KEY")
        self.enable_sentiment = enable_sentiment
        
        # APIç«¯ç‚¹
        self.finnhub_base = "https://finnhub.io/api/v1"
        self.newsapi_base = "https://newsapi.org/v2"
        self.eastmoney_base = "https://np-anotice-stock.eastmoney.com/api/content"
        
        # ç¼“å­˜
        self.cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿ
        
        logger.info(
            f"æ–°é—»APIå·¥å…·åˆå§‹åŒ–: "
            f"Finnhub={'âœ…' if self.finnhub_key else 'âŒ'}, "
            f"NewsAPI={'âœ…' if self.newsapi_key else 'âŒ'}"
        )
    
    async def get_company_news(
        self,
        symbol: str,
        days: int = 7,
        source: str = "auto"
    ) -> List[NewsArticle]:
        """
        è·å–å…¬å¸æ–°é—»
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¦‚ "AAPL" æˆ– "600519.SH")
            days: è·å–æœ€è¿‘å‡ å¤©çš„æ–°é—»
            source: æ•°æ®æº ("finnhub", "newsapi", "eastmoney", "auto")
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        # åˆ¤æ–­æ˜¯Aè‚¡è¿˜æ˜¯ç¾è‚¡
        is_a_share = any(x in symbol for x in ['.SH', '.SZ', '.BJ'])
        
        if source == "auto":
            source = "eastmoney" if is_a_share else "finnhub"
        
        logger.info(f"è·å–{symbol}çš„æ–°é—» (æ¥æº: {source}, å¤©æ•°: {days})")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{symbol}_{days}_{source}"
        if cache_key in self.cache:
            cached_time, cached_data = self.cache[cache_key]
            if (datetime.now() - cached_time).seconds < self.cache_ttl:
                logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„æ–°é—»æ•°æ®: {symbol}")
                return cached_data
        
        # æ ¹æ®æ¥æºè·å–æ–°é—»
        if source == "finnhub":
            news = await self._fetch_finnhub_news(symbol, days)
        elif source == "eastmoney":
            news = await self._fetch_eastmoney_news(symbol, days)
        elif source == "newsapi":
            news = await self._fetch_newsapi_news(symbol, days)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ–°é—»æº: {source}")
            return []
        
        # æƒ…ç»ªåˆ†æ
        if self.enable_sentiment and news:
            news = await self._analyze_sentiment_batch(news)
        
        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = (datetime.now(), news)
        
        logger.info(f"âœ… è·å–åˆ°{len(news)}æ¡æ–°é—»: {symbol}")
        return news
    
    async def search_news(
        self,
        keywords: List[str],
        language: str = 'zh',
        days: int = 7,
        limit: int = 20
    ) -> List[NewsArticle]:
        """
        æœç´¢æ–°é—»
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            language: è¯­è¨€ ('zh', 'en')
            days: æœç´¢æœ€è¿‘å‡ å¤©
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        logger.info(f"æœç´¢æ–°é—»: {keywords} (è¯­è¨€: {language})")
        
        if language == 'zh':
            # ä¸­æ–‡æ–°é—» - ä½¿ç”¨ä¸œæ–¹è´¢å¯Œ
            news = await self._search_eastmoney_news(keywords, days, limit)
        else:
            # è‹±æ–‡æ–°é—» - ä½¿ç”¨NewsAPI
            news = await self._search_newsapi(keywords, days, limit)
        
        if self.enable_sentiment and news:
            news = await self._analyze_sentiment_batch(news)
        
        logger.info(f"âœ… æœç´¢åˆ°{len(news)}æ¡æ–°é—»")
        return news
    
    async def get_market_news(
        self,
        category: str = "general",
        limit: int = 20
    ) -> List[NewsArticle]:
        """
        è·å–å¸‚åœºæ–°é—»
        
        Args:
            category: åˆ†ç±» ("general", "forex", "crypto", "merger")
            limit: æ•°é‡é™åˆ¶
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        logger.info(f"è·å–å¸‚åœºæ–°é—»: {category}")
        
        if not self.finnhub_key:
            logger.warning("Finnhub API Keyæœªé…ç½®")
            return []
        
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.finnhub_base}/news"
                params = {
                    "category": category,
                    "token": self.finnhub_key
                }
                
                async with session.get(url, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return self._parse_finnhub_news(data[:limit])
                    else:
                        logger.error(f"Finnhub APIé”™è¯¯: {resp.status}")
                        return []
        
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæ–°é—»å¤±è´¥: {e}")
            return []
    
    # ========================================================================
    # å†…éƒ¨æ–¹æ³• - Finnhub
    # ========================================================================
    
    async def _fetch_finnhub_news(
        self,
        symbol: str,
        days: int
    ) -> List[NewsArticle]:
        """ä»Finnhubè·å–æ–°é—»"""
        if not self.finnhub_key:
            logger.warning("Finnhub API Keyæœªé…ç½®")
            return []
        
        try:
            from_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
            to_date = datetime.now().strftime("%Y-%m-%d")
            
            async with aiohttp.ClientSession() as session:
                url = f"{self.finnhub_base}/company-news"
                params = {
                    "symbol": symbol,
                    "from": from_date,
                    "to": to_date,
                    "token": self.finnhub_key
                }
                
                async with session.get(url, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return self._parse_finnhub_news(data)
                    elif resp.status == 429:
                        logger.warning("Finnhub APIé™æµ,ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                        return self._generate_mock_news(symbol, days, "finnhub")
                    else:
                        logger.error(f"Finnhub APIé”™è¯¯: {resp.status}")
                        return []
        
        except Exception as e:
            logger.error(f"Finnhubè¯·æ±‚å¤±è´¥: {e}")
            return self._generate_mock_news(symbol, days, "finnhub")
    
    def _parse_finnhub_news(self, data: List[Dict]) -> List[NewsArticle]:
        """è§£æFinnhubæ–°é—»"""
        news = []
        for item in data:
            try:
                news.append(NewsArticle(
                    id=str(item.get('id', hash(item['headline']))),
                    title=item.get('headline', ''),
                    summary=item.get('summary', ''),
                    source=item.get('source', 'Finnhub'),
                    url=item.get('url', ''),
                    published_at=datetime.fromtimestamp(item.get('datetime', 0)),
                    category=item.get('category', 'general'),
                    symbols=[item.get('symbol', '')]
                ))
            except Exception as e:
                logger.warning(f"è§£ææ–°é—»å¤±è´¥: {e}")
                continue
        return news
    
    # ========================================================================
    # å†…éƒ¨æ–¹æ³• - ä¸œæ–¹è´¢å¯Œ (Aè‚¡)
    # ========================================================================
    
    async def _fetch_eastmoney_news(
        self,
        symbol: str,
        days: int
    ) -> List[NewsArticle]:
        """ä»ä¸œæ–¹è´¢å¯Œè·å–Aè‚¡æ–°é—»"""
        try:
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ (600519.SH -> SH600519)
            if '.' in symbol:
                market, code = symbol.split('.')
                eastmoney_code = f"{market}{code}"
            else:
                eastmoney_code = symbol
            
            # ä¸œæ–¹è´¢å¯ŒAPI (å…¬å¼€æ¥å£)
            url = f"{self.eastmoney_base}/list"
            params = {
                "code": eastmoney_code,
                "pageSize": days * 5,  # æ¯å¤©çº¦5æ¡æ–°é—»
                "pageIndex": 1
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return self._parse_eastmoney_news(data)
                    else:
                        logger.warning(f"ä¸œæ–¹è´¢å¯ŒAPIé”™è¯¯: {resp.status}, ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                        return self._generate_mock_news(symbol, days, "eastmoney")
        
        except Exception as e:
            logger.error(f"ä¸œæ–¹è´¢å¯Œè¯·æ±‚å¤±è´¥: {e}")
            return self._generate_mock_news(symbol, days, "eastmoney")
    
    def _parse_eastmoney_news(self, data: Dict) -> List[NewsArticle]:
        """è§£æä¸œæ–¹è´¢å¯Œæ–°é—»"""
        news = []
        items = data.get('data', {}).get('list', [])
        
        for item in items:
            try:
                news.append(NewsArticle(
                    id=str(item.get('art_code', hash(item.get('title', '')))),
                    title=item.get('title', ''),
                    summary=item.get('content', '')[:200],
                    source='ä¸œæ–¹è´¢å¯Œ',
                    url=item.get('url', ''),
                    published_at=datetime.fromisoformat(item.get('show_time', '').replace('Z', '+00:00')) 
                        if item.get('show_time') else datetime.now(),
                    category='è´¢ç»'
                ))
            except Exception as e:
                logger.warning(f"è§£æä¸œæ–¹è´¢å¯Œæ–°é—»å¤±è´¥: {e}")
                continue
        
        return news
    
    async def _search_eastmoney_news(
        self,
        keywords: List[str],
        days: int,
        limit: int
    ) -> List[NewsArticle]:
        """æœç´¢ä¸œæ–¹è´¢å¯Œæ–°é—»"""
        # ç®€åŒ–å®ç°: æ¨¡æ‹Ÿæœç´¢ç»“æœ
        logger.warning("ä¸œæ–¹è´¢å¯Œæœç´¢åŠŸèƒ½ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        return self._generate_mock_news(' '.join(keywords), days, "eastmoney")[:limit]
    
    # ========================================================================
    # å†…éƒ¨æ–¹æ³• - NewsAPI
    # ========================================================================
    
    async def _fetch_newsapi_news(
        self,
        symbol: str,
        days: int
    ) -> List[NewsArticle]:
        """ä»NewsAPIè·å–æ–°é—»"""
        if not self.newsapi_key:
            logger.warning("NewsAPI Keyæœªé…ç½®")
            return []
        
        try:
            from_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
            
            async with aiohttp.ClientSession() as session:
                url = f"{self.newsapi_base}/everything"
                params = {
                    "q": symbol,
                    "from": from_date,
                    "sortBy": "relevancy",
                    "apiKey": self.newsapi_key
                }
                
                async with session.get(url, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return self._parse_newsapi_data(data)
                    else:
                        logger.warning(f"NewsAPIé”™è¯¯: {resp.status}, ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                        return self._generate_mock_news(symbol, days, "newsapi")
        
        except Exception as e:
            logger.error(f"NewsAPIè¯·æ±‚å¤±è´¥: {e}")
            return self._generate_mock_news(symbol, days, "newsapi")
    
    async def _search_newsapi(
        self,
        keywords: List[str],
        days: int,
        limit: int
    ) -> List[NewsArticle]:
        """ä½¿ç”¨NewsAPIæœç´¢"""
        if not self.newsapi_key:
            return self._generate_mock_news(' '.join(keywords), days, "newsapi")[:limit]
        
        try:
            query = ' OR '.join(keywords)
            from_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
            
            async with aiohttp.ClientSession() as session:
                url = f"{self.newsapi_base}/everything"
                params = {
                    "q": query,
                    "from": from_date,
                    "sortBy": "relevancy",
                    "pageSize": limit,
                    "apiKey": self.newsapi_key
                }
                
                async with session.get(url, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return self._parse_newsapi_data(data)
                    else:
                        return self._generate_mock_news(' '.join(keywords), days, "newsapi")[:limit]
        
        except Exception as e:
            logger.error(f"NewsAPIæœç´¢å¤±è´¥: {e}")
            return self._generate_mock_news(' '.join(keywords), days, "newsapi")[:limit]
    
    def _parse_newsapi_data(self, data: Dict) -> List[NewsArticle]:
        """è§£æNewsAPIæ•°æ®"""
        news = []
        for item in data.get('articles', []):
            try:
                news.append(NewsArticle(
                    id=item.get('url', hash(item.get('title', ''))),
                    title=item.get('title', ''),
                    summary=item.get('description', ''),
                    source=item.get('source', {}).get('name', 'NewsAPI'),
                    url=item.get('url', ''),
                    published_at=datetime.fromisoformat(item.get('publishedAt', '').replace('Z', '+00:00'))
                        if item.get('publishedAt') else datetime.now()
                ))
            except Exception as e:
                logger.warning(f"è§£æNewsAPIæ•°æ®å¤±è´¥: {e}")
                continue
        return news
    
    # ========================================================================
    # æƒ…ç»ªåˆ†æ
    # ========================================================================
    
    async def _analyze_sentiment_batch(
        self,
        news: List[NewsArticle]
    ) -> List[NewsArticle]:
        """æ‰¹é‡æƒ…ç»ªåˆ†æ"""
        # ç®€åŒ–å®ç°: åŸºäºå…³é”®è¯çš„æƒ…ç»ªåˆ†æ
        positive_keywords = ['æ¶¨', 'çªç ´', 'å¢é•¿', 'åˆ©å¥½', 'ç›ˆåˆ©', 'ä¹°å…¥', 'surge', 'gain', 'profit']
        negative_keywords = ['è·Œ', 'ä¸‹è·Œ', 'äºæŸ', 'åˆ©ç©º', 'é£é™©', 'å–å‡º', 'drop', 'loss', 'risk']
        
        for article in news:
            text = f"{article.title} {article.summary}".lower()
            
            pos_count = sum(1 for kw in positive_keywords if kw in text)
            neg_count = sum(1 for kw in negative_keywords if kw in text)
            
            # ç®€å•æƒ…ç»ªå¾—åˆ† (-1 ~ 1)
            total = pos_count + neg_count
            if total > 0:
                article.sentiment = (pos_count - neg_count) / total
            else:
                article.sentiment = 0.0
        
        return news
    
    # ========================================================================
    # æ¨¡æ‹Ÿæ•°æ® (æ— API Keyæ—¶ä½¿ç”¨)
    # ========================================================================
    
    def _generate_mock_news(
        self,
        symbol: str,
        days: int,
        source: str
    ) -> List[NewsArticle]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ•°æ®"""
        logger.warning(f"ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ•°æ®: {symbol}")
        
        mock_titles = [
            f"{symbol} è´¢æŠ¥è¶…é¢„æœŸ,è‚¡ä»·å¤§æ¶¨",
            f"{symbol} å®£å¸ƒé‡å¤§åˆä½œä¼™ä¼´å…³ç³»",
            f"åˆ†æå¸ˆä¸Šè°ƒ{symbol}ç›®æ ‡ä»·",
            f"{symbol} å­£åº¦ä¸šç»©å…¬å¸ƒ",
            f"{symbol} è¡Œä¸šåœ°ä½ç¨³å›º",
        ]
        
        news = []
        for i in range(min(days, 5)):
            pub_time = datetime.now() - timedelta(days=i)
            news.append(NewsArticle(
                id=f"mock_{symbol}_{i}",
                title=mock_titles[i % len(mock_titles)],
                summary=f"è¿™æ˜¯å…³äº{symbol}çš„æ¨¡æ‹Ÿæ–°é—»å†…å®¹...",
                source=source,
                url=f"https://example.com/news/{i}",
                published_at=pub_time,
                sentiment=0.1 * (i % 3 - 1),  # -0.1, 0, 0.1å¾ªç¯
                category="è´¢ç»"
            ))
        
        return news


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

async def example_news_api():
    """æ–°é—»APIä½¿ç”¨ç¤ºä¾‹"""
    print("=== æ–°é—»APIå·¥å…·ç¤ºä¾‹ ===\n")
    
    # åˆ›å»ºå·¥å…·
    tool = NewsAPITool()
    
    # 1. è·å–å…¬å¸æ–°é—» (Aè‚¡)
    print("1. è·å–è´µå·èŒ…å°æ–°é—»...")
    news = await tool.get_company_news("600519.SH", days=7)
    for article in news[:3]:
        print(f"   ğŸ“° {article.title}")
        print(f"      æ¥æº: {article.source} | æ—¶é—´: {article.published_at.strftime('%Y-%m-%d')}")
        print(f"      æƒ…ç»ª: {article.sentiment:+.2f}" if article.sentiment else "")
        print()
    
    # 2. æœç´¢æ–°é—»
    print("2. æœç´¢'äººå·¥æ™ºèƒ½'ç›¸å…³æ–°é—»...")
    news = await tool.search_news(['äººå·¥æ™ºèƒ½', 'AI'], language='zh', days=3, limit=5)
    print(f"   æ‰¾åˆ°{len(news)}æ¡æ–°é—»\n")
    
    # 3. è·å–å¸‚åœºæ–°é—»
    print("3. è·å–å¸‚åœºæ–°é—»...")
    market_news = await tool.get_market_news(category="general", limit=5)
    print(f"   è·å–{len(market_news)}æ¡å¸‚åœºæ–°é—»\n")
    
    print("âœ… ç¤ºä¾‹å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(example_news_api())
