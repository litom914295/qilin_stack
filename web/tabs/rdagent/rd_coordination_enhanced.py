"""
R&Då¾ªç¯å’ŒMLE-Benchå¢å¼ºæ¨¡å—
å®Œæ•´çš„Research/Developmenté˜¶æ®µå±•ç¤ºå’ŒTraceå†å²æŸ¥è¯¢
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime


def render_rd_coordination_enhanced():
    """ç ”å‘ååŒtab - å¢å¼ºç‰ˆ"""
    st.header("ğŸ”¬ ç ”å‘ååŒ")
    st.markdown("""
    **R&Då¾ªç¯ç®¡ç†** âœ¨å¢å¼ºç‰ˆ
    - ğŸ”¬ **Research Agenté˜¶æ®µå±•ç¤º**
    - ğŸ› ï¸ **Development Agenté˜¶æ®µå±•ç¤º**
    - ğŸ“œ **Traceå†å²æŸ¥è¯¢** âœ¨æ–°å¢
    - ğŸ”„ ååŒè¿›åŒ–å¾ªç¯
    """)
    
    # åˆå§‹åŒ–session state
    if 'rd_loop_running' not in st.session_state:
        st.session_state.rd_loop_running = False
    if 'rd_loop_result' not in st.session_state:
        st.session_state.rd_loop_result = None
    if 'rd_trace_history' not in st.session_state:
        st.session_state.rd_trace_history = []
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("R&Då¾ªç¯è½®æ¬¡", "12", "+2")
    with col2:
        st.metric("å®éªŒæ€»æ•°", "58", "+7")
    with col3:
        st.metric("æˆåŠŸç‡", "76%", "+8%")
    
    st.divider()
    
    # R&Dæµç¨‹å¯è§†åŒ–
    st.subheader("ğŸ“Š R&Då¾ªç¯æµç¨‹")
    
    fig = go.Figure(data=[go.Sankey(
        node=dict(
            label=["Research Agent", "Hypothesis", "Experiment", "Development Agent", "Results", "Feedback"],
            color=["blue", "lightblue", "green", "purple", "orange", "red"]
        ),
        link=dict(
            source=[0, 1, 2, 3, 4],
            target=[1, 2, 3, 4, 0],
            value=[10, 10, 10, 10, 10]
        )
    )])
    fig.update_layout(title="R&Då¾ªç¯æ•°æ®æµ", height=400)
    st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    # Researché˜¶æ®µè¯¦ç»†å±•ç¤º
    st.subheader("ğŸ”¬ Research Agent é˜¶æ®µ")
    
    research_tab1, research_tab2, research_tab3 = st.tabs([
        "ğŸ’¡ å‡è®¾ç”Ÿæˆ",
        "ğŸ“š æ–‡çŒ®æ£€ç´¢",
        "ğŸ§ª å®éªŒè®¾è®¡"
    ])
    
    with research_tab1:
        st.markdown("**å½“å‰å‡è®¾åˆ—è¡¨**")
        
        # Mockå‡è®¾æ•°æ®
        hypotheses = [
            {"id": 1, "hypothesis": "åŠ¨é‡å› å­åœ¨çŸ­æœŸäº¤æ˜“ä¸­æ•ˆæœæ˜¾è‘—", "confidence": 0.85, "status": "æµ‹è¯•ä¸­"},
            {"id": 2, "hypothesis": "æˆäº¤é‡ä¸ä»·æ ¼èƒŒç¦»é¢„ç¤ºåè½¬", "confidence": 0.72, "status": "å·²éªŒè¯"},
            {"id": 3, "hypothesis": "å¤šå› å­ç»„åˆå¯æå‡é¢„æµ‹å‡†ç¡®ç‡", "confidence": 0.68, "status": "è®¾è®¡ä¸­"}
        ]
        
        for hyp in hypotheses:
            with st.expander(f"ğŸ’¡ å‡è®¾ #{hyp['id']}: {hyp['hypothesis']}", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ç½®ä¿¡åº¦", f"{hyp['confidence']:.0%}")
                with col2:
                    st.metric("çŠ¶æ€", hyp['status'])
    
    with research_tab2:
        st.markdown("**ç›¸å…³æ–‡çŒ®**")
        
        papers = [
            {"title": "Momentum Strategies in Stock Trading", "year": 2023, "citations": 145},
            {"title": "Volume-Price Divergence Analysis", "year": 2022, "citations": 89},
            {"title": "Multi-Factor Alpha Models", "year": 2024, "citations": 67}
        ]
        
        for paper in papers:
            with st.container():
                col1, col2, col3 = st.columns([5, 1, 1])
                with col1:
                    st.markdown(f"**{paper['title']}**")
                with col2:
                    st.text(paper['year'])
                with col3:
                    st.text(f"ğŸ“œ {paper['citations']}")
                st.divider()
    
    with research_tab3:
        st.markdown("**å®éªŒè®¾è®¡æ–¹æ¡ˆ**")
        
        exp_design = {
            "æ•°æ®é›†": "CSI 300, 2020-2024",
            "è®­ç»ƒé›†": "2020-2023 (70%)",
            "éªŒè¯é›†": "2023-2024 (30%)",
            "è¯„ä¼°æŒ‡æ ‡": "IC, IR, Sharpe Ratio",
            "åŸºå‡†æ¨¡å‹": "Linear Regression, GBDT"
        }
        
        for key, value in exp_design.items():
            st.text(f"{key}: {value}")
    
    st.divider()
    
    # Developmenté˜¶æ®µè¯¦ç»†å±•ç¤º
    st.subheader("ğŸ› ï¸ Development Agent é˜¶æ®µ")
    
    dev_tab1, dev_tab2, dev_tab3 = st.tabs([
        "ğŸ’» ä»£ç å®ç°",
        "âœ… æµ‹è¯•éªŒè¯",
        "ğŸš€ éƒ¨ç½²é›†æˆ"
    ])
    
    with dev_tab1:
        st.markdown("**ä»£ç å®ç°è¿›åº¦**")
        
        impl_progress = [
            {"task": "å› å­è®¡ç®—æ¨¡å—", "progress": 100, "status": "âœ… å®Œæˆ"},
            {"task": "å›æµ‹å¼•æ“", "progress": 75, "status": "ğŸ”„ è¿›è¡Œä¸­"},
            {"task": "ç»“æœåˆ†æ", "progress": 30, "status": "ğŸš§ å¾…å®Œæˆ"}
        ]
        
        for task in impl_progress:
            st.text(f"{task['status']} {task['task']}")
            st.progress(task['progress'] / 100)
    
    with dev_tab2:
        st.markdown("**æµ‹è¯•ç»“æœ**")
        
        test_results = pd.DataFrame({
            "æµ‹è¯•ç”¨ä¾‹": ["Unit Test", "Integration Test", "Performance Test"],
            "é€šè¿‡": [45, 28, 12],
            "å¤±è´¥": [2, 1, 0],
            "è¦†ç›–ç‡": ["95%", "87%", "100%"]
        })
        
        st.dataframe(test_results, use_container_width=True, hide_index=True)
    
    with dev_tab3:
        st.markdown("**éƒ¨ç½²çŠ¶æ€**")
        
        deployment_status = [
            {"env": "Development", "version": "v1.2.3", "status": "âœ… æ­£å¸¸"},
            {"env": "Staging", "version": "v1.2.2", "status": "ğŸŸ¡ å¾…æ›´æ–°"},
            {"env": "Production", "version": "v1.2.1", "status": "âœ… æ­£å¸¸"}
        ]
        
        for dep in deployment_status:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.text(dep['env'])
            with col2:
                st.text(dep['version'])
            with col3:
                st.text(dep['status'])
    
    st.divider()
    
    # Traceå†å²æŸ¥è¯¢
    st.subheader("ğŸ“œ Trace å†å²æŸ¥è¯¢")
    
    col_filter1, col_filter2, col_filter3 = st.columns(3)
    with col_filter1:
        trace_type = st.selectbox("ç±»å‹è¿‡æ»¤", ["All", "Research", "Development", "Experiment"], key="rdc_trace_type")
    with col_filter2:
        trace_status = st.selectbox("çŠ¶æ€è¿‡æ»¤", ["All", "Success", "Failed", "Running"], key="rdc_trace_status")
    with col_filter3:
        date_range = st.date_input("æ—¥æœŸèŒƒå›´", value=(datetime.now().date(), datetime.now().date()))
    
    if st.button("ğŸ” æŸ¥è¯¢Traceå†å²"):
        from .rdagent_api import RDAgentAPI
        import asyncio
        
        api = RDAgentAPI()
        
        with st.spinner("æ­£åœ¨æŸ¥è¯¢Traceå†å²..."):
            result = asyncio.run(api.get_rd_loop_trace(
                trace_type=trace_type if trace_type != "All" else None,
                status=trace_status if trace_status != "All" else None
            ))
        
        if result['success']:
            st.session_state.rd_trace_history = result['traces']
            st.success(f"âœ… æŸ¥è¯¢æˆåŠŸ! æ‰¾åˆ° {len(result['traces'])} æ¡è®°å½•")
        else:
            st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    # æ˜¾ç¤ºTraceå†å²
    if st.session_state.rd_trace_history:
        st.markdown("**Traceè®°å½•åˆ—è¡¨**")
        
        for idx, trace in enumerate(st.session_state.rd_trace_history):
            with st.expander(f"ğŸ“ Trace #{trace['id']}: {trace['type']} - {trace['timestamp']}", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ç±»å‹", trace['type'])
                with col2:
                    st.metric("çŠ¶æ€", trace['status'])
                with col3:
                    st.metric("è€—æ—¶", f"{trace.get('duration', 0):.1f}s")
                
                st.markdown("**è¯¦æƒ…:**")
                st.json(trace.get('details', {}))
    
    st.divider()
    
    # å¯åŠ¨R&Då¾ªç¯
    st.subheader("ğŸš€ å¯åŠ¨R&Då¾ªç¯")
    
    col_config1, col_config2 = st.columns(2)
    with col_config1:
        max_iterations = st.number_input("æœ€å¤§è¿­ä»£æ¬¡æ•°", min_value=1, max_value=20, value=5)
    with col_config2:
        auto_deploy = st.checkbox("è‡ªåŠ¨éƒ¨ç½²", value=False)
    
    if st.button("ğŸ”„ å¯åŠ¨æ–°ä¸€è½®R&Då¾ªç¯", type="primary"):
        from .rdagent_api import RDAgentAPI
        api = RDAgentAPI()
        
        st.session_state.rd_loop_running = True
        
        with st.spinner(f"æ­£åœ¨è¿è¡ŒR&Då¾ªç¯ (æœ€å¤§{max_iterations}è¿­ä»£)..."):
            result = api.run_rd_loop(
                max_iterations=max_iterations,
                auto_deploy=auto_deploy
            )
        
        st.session_state.rd_loop_running = False
        
        if result['success']:
            st.session_state.rd_loop_result = result
            st.success(f"âœ… {result['message']}")
            
            # æ˜¾ç¤ºç»“æœ
            col_res1, col_res2, col_res3 = st.columns(3)
            with col_res1:
                st.metric("ç”Ÿæˆå‡è®¾æ•°", result.get('hypotheses_generated', 0))
            with col_res2:
                st.metric("å®éªŒæ¬¡æ•°", result.get('experiments_run', 0))
            with col_res3:
                st.metric("æˆåŠŸç‡", f"{result.get('success_rate', 0):.0%}")
        else:
            st.error(f"âŒ {result.get('message', 'è¿è¡Œå¤±è´¥')}")


def render_mle_bench_enhanced():
    """MLE-Bench tab - å¢å¼ºç‰ˆ"""
    st.header("ğŸ“Š MLE-Bench")
    st.markdown("""
    **æœºå™¨å­¦ä¹ å·¥ç¨‹è¯„ä¼°** âœ¨å¢å¼ºç‰ˆ
    - ğŸ† **MLE-BenchåŸºå‡†æµ‹è¯•**
    - ğŸ¯ **å®é™…è¿è¡Œè¯„ä¼°** âœ¨æ–°å¢
    - ğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ
    - ğŸ“ˆ æŒç»­æ”¹è¿›è¿½è¸ª
    """)
    
    # åˆå§‹åŒ–session state
    if 'mle_bench_running' not in st.session_state:
        st.session_state.mle_bench_running = False
    if 'mle_bench_result' not in st.session_state:
        st.session_state.mle_bench_result = None
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»å¾—åˆ†", "30.22%", "+1.5%")
    with col2:
        st.metric("Lowéš¾åº¦", "51.52%", "+6.9%")
    with col3:
        st.metric("Mediuméš¾åº¦", "19.3%", "+5.5%")
    with col4:
        st.metric("Highéš¾åº¦", "26.67%", "0%")
    
    st.divider()
    
    # æ€§èƒ½å¯¹æ¯”è¡¨
    st.subheader("ğŸ† ä¸ç«äº‰å¯¹æ‰‹å¯¹æ¯”")
    
    comparison_data = {
        "Agent": ["R&D-Agent (Ours)", "AIDE", "Baseline"],
        "Low (%)": [51.52, 34.3, 28.1],
        "Medium (%)": [19.3, 8.8, 5.2],
        "High (%)": [26.67, 10.0, 6.8],
        "All (%)": [30.22, 16.9, 12.3]
    }
    
    df = pd.DataFrame(comparison_data)
    st.dataframe(
        df.style.highlight_max(subset=["Low (%)", "Medium (%)", "High (%)", "All (%)"], color="lightgreen"),
        use_container_width=True,
        hide_index=True
    )
    
    st.divider()
    
    # æ€§èƒ½è¶‹åŠ¿
    st.subheader("ğŸ“ˆ æ€§èƒ½æ”¹è¿›è¶‹åŠ¿")
    
    dates = pd.date_range(end=datetime.now(), periods=10, freq='W')
    scores = [20.1, 22.3, 24.5, 25.8, 27.2, 28.1, 28.9, 29.5, 30.0, 30.22]
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=dates, y=scores,
        mode='lines+markers',
        name='MLE-Benchå¾—åˆ†',
        line=dict(color='green', width=3),
        marker=dict(size=10)
    ))
    fig.update_layout(
        title="MLE-Benchå¾—åˆ†è¶‹åŠ¿",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="å¾—åˆ† (%)",
        hovermode='x unified'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    # è¿è¡Œé…ç½®
    st.subheader("âš™ï¸ è¿è¡Œé…ç½®")
    
    col_config1, col_config2, col_config3 = st.columns(3)
    with col_config1:
        difficulty = st.selectbox("éš¾åº¦çº§åˆ«", ["All", "Low", "Medium", "High"], key="rdc_mle_difficulty")
    with col_config2:
        task_type = st.selectbox("ä»»åŠ¡ç±»å‹", ["All", "Classification", "Regression", "Time Series"], key="rdc_mle_task_type")
    with col_config3:
        timeout = st.number_input("è¶…æ—¶æ—¶é—´(åˆ†é’Ÿ)", min_value=5, max_value=120, value=30)
    
    col_res1, col_res2 = st.columns(2)
    with col_res1:
        max_memory = st.number_input("æœ€å¤§å†…å­˜(GB)", min_value=4, max_value=64, value=16)
    with col_res2:
        num_workers = st.number_input("å¹¶è¡Œä»»åŠ¡æ•°", min_value=1, max_value=16, value=4)
    
    st.divider()
    
    # å¯åŠ¨è¯„ä¼°
    st.subheader("ğŸš€ å¯åŠ¨è¯„ä¼°")
    
    if st.button("ğŸš€ è¿è¡ŒMLE-Benchæµ‹è¯•", type="primary"):
        from .rdagent_api import RDAgentAPI
        api = RDAgentAPI()
        
        st.session_state.mle_bench_running = True
        
        config = {
            "difficulty": difficulty,
            "task_type": task_type,
            "timeout": timeout * 60,  # è½¬æ¢ä¸ºç§’
            "max_memory": max_memory * 1024,  # è½¬æ¢ä¸ºMB
            "num_workers": num_workers
        }
        
        # åˆ›å»ºè¿›åº¦å®¹å™¨
        progress_container = st.empty()
        status_container = st.empty()
        
        with st.spinner(f"æ­£åœ¨è¿è¡ŒMLE-Benchè¯„ä¼° (éš¾åº¦: {difficulty})..."):
            result = api.run_mle_bench(config)
        
        st.session_state.mle_bench_running = False
        
        if result['success']:
            st.session_state.mle_bench_result = result
            st.success(f"âœ… {result['message']}")
            
            # æ˜¾ç¤ºç»“æœ
            st.subheader("ğŸ“Š è¯„ä¼°ç»“æœ")
            
            col_result1, col_result2, col_result3, col_result4 = st.columns(4)
            with col_result1:
                st.metric("å®Œæˆä»»åŠ¡", result.get('completed_tasks', 0))
            with col_result2:
                st.metric("æ€»å¾—åˆ†", f"{result.get('total_score', 0):.2%}")
            with col_result3:
                st.metric("å¹³å‡è€—æ—¶", f"{result.get('avg_time', 0):.1f}s")
            with col_result4:
                st.metric("æˆåŠŸç‡", f"{result.get('success_rate', 0):.0%}")
            
            # è¯¦ç»†ç»“æœè¡¨
            if 'task_results' in result:
                st.markdown("**ä»»åŠ¡è¯¦æƒ…**")
                task_df = pd.DataFrame(result['task_results'])
                st.dataframe(task_df, use_container_width=True, hide_index=True)
        else:
            st.error(f"âŒ {result.get('message', 'è¯„ä¼°å¤±è´¥')}")
    
    # æ˜¾ç¤ºä¹‹å‰çš„ç»“æœ
    if st.session_state.mle_bench_result and not st.session_state.mle_bench_running:
        st.divider()
        st.subheader("ğŸ“œ å†å²è¿è¡Œç»“æœ")
        
        result = st.session_state.mle_bench_result
        with st.expander("æŸ¥çœ‹è¯¦ç»†æ—¥å¿—", expanded=False):
            if 'logs' in result:
                st.text_area("è¿è¡Œæ—¥å¿—", result['logs'], height=300)
