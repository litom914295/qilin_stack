"""
Data Mining Agent - æ•°æ®è´¨é‡æ£€æµ‹å’Œåˆ†ææ¨¡å—

åŠŸèƒ½:
1. æ•°æ®è´¨é‡æ£€æµ‹
2. ç¼ºå¤±å€¼åˆ†æ
3. å¼‚å¸¸å€¼æ£€æµ‹
4. æ•°æ®åˆ†å¸ƒå¯è§†åŒ–
5. ç‰¹å¾ç›¸å…³æ€§åˆ†æ
6. æ•°æ®æŠ¥å‘Šç”Ÿæˆ
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from pathlib import Path
import json
from datetime import datetime


class DataMiningAgent:
    """æ•°æ®æŒ–æ˜Agent"""
    
    def __init__(self):
        self.init_session_state()
    
    def init_session_state(self):
        """åˆå§‹åŒ–sessionçŠ¶æ€"""
        if 'dm_uploaded_data' not in st.session_state:
            st.session_state.dm_uploaded_data = None
        if 'dm_analysis_results' not in st.session_state:
            st.session_state.dm_analysis_results = {}
    
    def analyze_missing_values(self, df: pd.DataFrame) -> Dict:
        """åˆ†æç¼ºå¤±å€¼"""
        missing_counts = df.isnull().sum()
        missing_pcts = (missing_counts / len(df)) * 100
        
        missing_info = []
        for col in df.columns:
            if missing_counts[col] > 0:
                missing_info.append({
                    'column': col,
                    'count': int(missing_counts[col]),
                    'percentage': float(missing_pcts[col]),
                    'dtype': str(df[col].dtype)
                })
        
        return {
            'total_missing': int(missing_counts.sum()),
            'columns_with_missing': len([c for c in missing_counts if c > 0]),
            'details': sorted(missing_info, key=lambda x: x['percentage'], reverse=True)
        }
    
    def detect_outliers(self, df: pd.DataFrame, method: str = 'iqr') -> Dict:
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        outliers = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            data = df[col].dropna()
            
            if method == 'iqr':
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)
                outlier_count = outlier_mask.sum()
                
                if outlier_count > 0:
                    outliers[col] = {
                        'count': int(outlier_count),
                        'percentage': float((outlier_count / len(df)) * 100),
                        'lower_bound': float(lower_bound),
                        'upper_bound': float(upper_bound),
                        'min_outlier': float(df[col][outlier_mask].min()),
                        'max_outlier': float(df[col][outlier_mask].max())
                    }
            
            elif method == 'zscore':
                z_scores = np.abs((data - data.mean()) / data.std())
                outlier_mask = z_scores > 3
                outlier_count = outlier_mask.sum()
                
                if outlier_count > 0:
                    outliers[col] = {
                        'count': int(outlier_count),
                        'percentage': float((outlier_count / len(data)) * 100),
                        'method': 'Z-Score > 3'
                    }
        
        return outliers
    
    def analyze_data_distribution(self, df: pd.DataFrame) -> Dict:
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        
        distributions = {
            'numeric': {},
            'categorical': {}
        }
        
        # æ•°å€¼å‹ç‰¹å¾
        for col in numeric_cols:
            data = df[col].dropna()
            distributions['numeric'][col] = {
                'mean': float(data.mean()),
                'median': float(data.median()),
                'std': float(data.std()),
                'min': float(data.min()),
                'max': float(data.max()),
                'skewness': float(data.skew()),
                'kurtosis': float(data.kurtosis())
            }
        
        # ç±»åˆ«å‹ç‰¹å¾
        for col in categorical_cols:
            value_counts = df[col].value_counts()
            distributions['categorical'][col] = {
                'unique_count': int(df[col].nunique()),
                'top_values': value_counts.head(10).to_dict(),
                'is_high_cardinality': df[col].nunique() > 50
            }
        
        return distributions
    
    def calculate_correlation(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[Dict]]:
        """è®¡ç®—ç‰¹å¾ç›¸å…³æ€§"""
        numeric_df = df.select_dtypes(include=[np.number])
        
        if len(numeric_df.columns) < 2:
            return pd.DataFrame(), []
        
        corr_matrix = numeric_df.corr()
        
        # æ‰¾å‡ºé«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i + 1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:  # ç›¸å…³æ€§é˜ˆå€¼
                    high_corr_pairs.append({
                        'feature1': corr_matrix.columns[i],
                        'feature2': corr_matrix.columns[j],
                        'correlation': float(corr_val)
                    })
        
        high_corr_pairs = sorted(high_corr_pairs, key=lambda x: abs(x['correlation']), reverse=True)
        
        return corr_matrix, high_corr_pairs
    
    def generate_quality_score(self, df: pd.DataFrame, missing_info: Dict, outliers: Dict) -> Dict:
        """ç”Ÿæˆæ•°æ®è´¨é‡è¯„åˆ†"""
        total_cells = df.shape[0] * df.shape[1]
        missing_cells = missing_info['total_missing']
        missing_ratio = missing_cells / total_cells
        
        total_outliers = sum(v['count'] for v in outliers.values())
        outlier_ratio = total_outliers / (df.shape[0] * len(df.select_dtypes(include=[np.number]).columns)) if len(df.select_dtypes(include=[np.number]).columns) > 0 else 0
        
        # è®¡ç®—è´¨é‡è¯„åˆ† (0-100)
        completeness_score = (1 - missing_ratio) * 100
        validity_score = (1 - outlier_ratio) * 100
        
        overall_score = (completeness_score * 0.6 + validity_score * 0.4)
        
        return {
            'overall_score': float(overall_score),
            'completeness_score': float(completeness_score),
            'validity_score': float(validity_score),
            'grade': 'A' if overall_score >= 90 else 'B' if overall_score >= 80 else 'C' if overall_score >= 70 else 'D'
        }
    
    def render_data_upload(self):
        """æ¸²æŸ“æ•°æ®ä¸Šä¼ ç•Œé¢"""
        st.subheader("ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæ–‡ä»¶è¿›è¡Œåˆ†æ",
            type=['csv'],
            help="æ”¯æŒCSVæ ¼å¼,æ–‡ä»¶å¤§å°ä¸è¶…è¿‡200MB"
        )
        
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                st.session_state.dm_uploaded_data = df
                
                st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {uploaded_file.name}")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»è¡Œæ•°", f"{len(df):,}")
                with col2:
                    st.metric("æ€»åˆ—æ•°", f"{len(df.columns):,}")
                with col3:
                    numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
                    st.metric("æ•°å€¼åˆ—", numeric_cols)
                with col4:
                    categorical_cols = len(df.select_dtypes(include=['object', 'category']).columns)
                    st.metric("ç±»åˆ«åˆ—", categorical_cols)
                
                # æ•°æ®é¢„è§ˆ
                with st.expander("ğŸ” æ•°æ®é¢„è§ˆ", expanded=True):
                    st.dataframe(df.head(20), use_container_width=True)
                
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        
        elif st.session_state.dm_uploaded_data is not None:
            df = st.session_state.dm_uploaded_data
            st.info(f"å½“å‰æ•°æ®: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
    
    def render_quality_overview(self):
        """æ¸²æŸ“æ•°æ®è´¨é‡æ€»è§ˆ"""
        if st.session_state.dm_uploaded_data is None:
            st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
            return
        
        df = st.session_state.dm_uploaded_data
        
        st.subheader("ğŸ“Š æ•°æ®è´¨é‡æ€»è§ˆ")
        
        with st.spinner("åˆ†æä¸­..."):
            # åˆ†æ
            missing_info = self.analyze_missing_values(df)
            outliers = self.detect_outliers(df, method='iqr')
            quality_score = self.generate_quality_score(df, missing_info, outliers)
            
            # ä¿å­˜ç»“æœ
            st.session_state.dm_analysis_results = {
                'missing_info': missing_info,
                'outliers': outliers,
                'quality_score': quality_score
            }
        
        # è´¨é‡è¯„åˆ†å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            score = quality_score['overall_score']
            st.metric(
                "æ€»ä½“è´¨é‡è¯„åˆ†",
                f"{score:.1f}",
                delta=f"ç­‰çº§: {quality_score['grade']}",
                delta_color="normal"
            )
        
        with col2:
            st.metric(
                "å®Œæ•´æ€§",
                f"{quality_score['completeness_score']:.1f}",
                delta=f"{missing_info['total_missing']:,} ç¼ºå¤±å€¼"
            )
        
        with col3:
            st.metric(
                "æœ‰æ•ˆæ€§",
                f"{quality_score['validity_score']:.1f}",
                delta=f"{sum(v['count'] for v in outliers.values()):,} å¼‚å¸¸å€¼"
            )
        
        with col4:
            st.metric(
                "é—®é¢˜åˆ—æ•°",
                missing_info['columns_with_missing'] + len(outliers),
                delta=f"å…±{len(df.columns)}åˆ—"
            )
        
        # è´¨é‡è¯„åˆ†å¯è§†åŒ–
        fig = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=quality_score['overall_score'],
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "æ•°æ®è´¨é‡è¯„åˆ†", 'font': {'size': 24}},
            delta={'reference': 80, 'increasing': {'color': "green"}},
            gauge={
                'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
                'bar': {'color': "darkblue"},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [0, 50], 'color': '#ffcccc'},
                    {'range': [50, 70], 'color': '#ffffcc'},
                    {'range': [70, 90], 'color': '#ccffcc'},
                    {'range': [90, 100], 'color': '#99ff99'}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    def render_missing_analysis(self):
        """æ¸²æŸ“ç¼ºå¤±å€¼åˆ†æ"""
        if 'missing_info' not in st.session_state.dm_analysis_results:
            st.warning("è¯·å…ˆè¿›è¡Œæ•°æ®è´¨é‡åˆ†æ")
            return
        
        st.subheader("ğŸ” ç¼ºå¤±å€¼åˆ†æ")
        
        missing_info = st.session_state.dm_analysis_results['missing_info']
        
        if missing_info['total_missing'] == 0:
            st.success("âœ… æ•°æ®å®Œæ•´,æ— ç¼ºå¤±å€¼!")
            return
        
        st.warning(f"âš ï¸ å‘ç° {missing_info['total_missing']:,} ä¸ªç¼ºå¤±å€¼,æ¶‰åŠ {missing_info['columns_with_missing']} åˆ—")
        
        # ç¼ºå¤±å€¼è¯¦æƒ…è¡¨
        if missing_info['details']:
            df_missing = pd.DataFrame(missing_info['details'])
            
            st.dataframe(
                df_missing,
                column_config={
                    "column": st.column_config.TextColumn("åˆ—å"),
                    "count": st.column_config.NumberColumn("ç¼ºå¤±æ•°é‡", format="%d"),
                    "percentage": st.column_config.ProgressColumn(
                        "ç¼ºå¤±æ¯”ä¾‹",
                        format="%.2f%%",
                        min_value=0,
                        max_value=100
                    ),
                    "dtype": st.column_config.TextColumn("æ•°æ®ç±»å‹")
                },
                hide_index=True,
                use_container_width=True
            )
            
            # ç¼ºå¤±å€¼å¯è§†åŒ–
            fig = px.bar(
                df_missing,
                x='column',
                y='percentage',
                title="å„åˆ—ç¼ºå¤±å€¼æ¯”ä¾‹",
                labels={'column': 'åˆ—å', 'percentage': 'ç¼ºå¤±æ¯”ä¾‹ (%)'},
                color='percentage',
                color_continuous_scale='Reds'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # å¤„ç†å»ºè®®
            st.subheader("ğŸ’¡ å¤„ç†å»ºè®®")
            for item in missing_info['details'][:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                if item['percentage'] > 50:
                    st.warning(f"ğŸ“Œ **{item['column']}**: ç¼ºå¤±ç‡{item['percentage']:.1f}%,å»ºè®®åˆ é™¤è¯¥åˆ—")
                elif item['percentage'] > 20:
                    st.info(f"ğŸ“Œ **{item['column']}**: ç¼ºå¤±ç‡{item['percentage']:.1f}%,å»ºè®®è°¨æ…å¡«å……æˆ–ä½¿ç”¨æ¨¡å‹é¢„æµ‹")
                else:
                    st.success(f"ğŸ“Œ **{item['column']}**: ç¼ºå¤±ç‡{item['percentage']:.1f}%,å¯ä½¿ç”¨å‡å€¼/ä¸­ä½æ•°/ä¼—æ•°å¡«å……")
    
    def render_outlier_analysis(self):
        """æ¸²æŸ“å¼‚å¸¸å€¼åˆ†æ"""
        if 'outliers' not in st.session_state.dm_analysis_results:
            st.warning("è¯·å…ˆè¿›è¡Œæ•°æ®è´¨é‡åˆ†æ")
            return
        
        st.subheader("ğŸš¨ å¼‚å¸¸å€¼æ£€æµ‹")
        
        outliers = st.session_state.dm_analysis_results['outliers']
        
        if not outliers:
            st.success("âœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸å€¼!")
            return
        
        total_outliers = sum(v['count'] for v in outliers.values())
        st.warning(f"âš ï¸ æ£€æµ‹åˆ° {total_outliers:,} ä¸ªå¼‚å¸¸å€¼,æ¶‰åŠ {len(outliers)} åˆ—")
        
        # å¼‚å¸¸å€¼è¯¦æƒ…
        outlier_data = []
        for col, info in outliers.items():
            outlier_data.append({
                'column': col,
                'count': info['count'],
                'percentage': info['percentage'],
                'lower_bound': info.get('lower_bound', 'N/A'),
                'upper_bound': info.get('upper_bound', 'N/A')
            })
        
        df_outliers = pd.DataFrame(outlier_data)
        
        st.dataframe(
            df_outliers,
            column_config={
                "column": st.column_config.TextColumn("åˆ—å"),
                "count": st.column_config.NumberColumn("å¼‚å¸¸å€¼æ•°é‡", format="%d"),
                "percentage": st.column_config.ProgressColumn(
                    "å¼‚å¸¸æ¯”ä¾‹",
                    format="%.2f%%",
                    min_value=0,
                    max_value=100
                ),
                "lower_bound": st.column_config.NumberColumn("ä¸‹ç•Œ", format="%.2f"),
                "upper_bound": st.column_config.NumberColumn("ä¸Šç•Œ", format="%.2f")
            },
            hide_index=True,
            use_container_width=True
        )
        
        # å¼‚å¸¸å€¼å¯è§†åŒ– (é€‰æ‹©ä¸€åˆ—)
        selected_col = st.selectbox("é€‰æ‹©åˆ—æŸ¥çœ‹è¯¦æƒ…", list(outliers.keys()))
        
        if selected_col:
            df = st.session_state.dm_uploaded_data
            data = df[selected_col].dropna()
            
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=("æ•°æ®åˆ†å¸ƒ", "ç®±çº¿å›¾")
            )
            
            # ç›´æ–¹å›¾
            fig.add_trace(
                go.Histogram(x=data, name="åˆ†å¸ƒ", nbinsx=50),
                row=1, col=1
            )
            
            # ç®±çº¿å›¾
            fig.add_trace(
                go.Box(y=data, name="ç®±çº¿å›¾"),
                row=1, col=2
            )
            
            fig.update_layout(height=400, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
    
    def render_distribution_analysis(self):
        """æ¸²æŸ“åˆ†å¸ƒåˆ†æ"""
        if st.session_state.dm_uploaded_data is None:
            st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
            return
        
        st.subheader("ğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ")
        
        df = st.session_state.dm_uploaded_data
        
        # é€‰æ‹©åˆ†æç±»å‹
        analysis_type = st.radio(
            "é€‰æ‹©åˆ†æç±»å‹",
            ["æ•°å€¼å‹ç‰¹å¾", "ç±»åˆ«å‹ç‰¹å¾"],
            horizontal=True
        )
        
        if analysis_type == "æ•°å€¼å‹ç‰¹å¾":
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if not numeric_cols:
                st.info("æ•°æ®ä¸­æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾")
                return
            
            selected_col = st.selectbox("é€‰æ‹©ç‰¹å¾", numeric_cols)
            
            if selected_col:
                data = df[selected_col].dropna()
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("å‡å€¼", f"{data.mean():.2f}")
                with col2:
                    st.metric("ä¸­ä½æ•°", f"{data.median():.2f}")
                with col3:
                    st.metric("æ ‡å‡†å·®", f"{data.std():.2f}")
                with col4:
                    st.metric("ååº¦", f"{data.skew():.2f}")
                
                # åˆ†å¸ƒå›¾
                fig = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=("ç›´æ–¹å›¾", "Q-Qå›¾", "ç®±çº¿å›¾", "å°æç´å›¾"),
                    specs=[[{"type": "histogram"}, {"type": "scatter"}],
                           [{"type": "box"}, {"type": "violin"}]]
                )
                
                # ç›´æ–¹å›¾
                fig.add_trace(
                    go.Histogram(x=data, name="é¢‘æ¬¡", nbinsx=50),
                    row=1, col=1
                )
                
                # Q-Qå›¾ (ç®€åŒ–ç‰ˆ)
                sorted_data = np.sort(data)
                theoretical_quantiles = np.linspace(0, 1, len(sorted_data))
                fig.add_trace(
                    go.Scatter(x=theoretical_quantiles, y=sorted_data, mode='markers', name="Q-Q"),
                    row=1, col=2
                )
                
                # ç®±çº¿å›¾
                fig.add_trace(
                    go.Box(y=data, name="ç®±çº¿å›¾"),
                    row=2, col=1
                )
                
                # å°æç´å›¾
                fig.add_trace(
                    go.Violin(y=data, name="å°æç´å›¾"),
                    row=2, col=2
                )
                
                fig.update_layout(height=600, showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
        
        else:  # ç±»åˆ«å‹ç‰¹å¾
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            
            if not categorical_cols:
                st.info("æ•°æ®ä¸­æ²¡æœ‰ç±»åˆ«å‹ç‰¹å¾")
                return
            
            selected_col = st.selectbox("é€‰æ‹©ç‰¹å¾", categorical_cols)
            
            if selected_col:
                value_counts = df[selected_col].value_counts()
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å”¯ä¸€å€¼æ•°é‡", df[selected_col].nunique())
                with col2:
                    st.metric("æœ€å¸¸è§å€¼", value_counts.index[0])
                with col3:
                    st.metric("æœ€å¸¸è§å€¼å æ¯”", f"{(value_counts.iloc[0] / len(df)) * 100:.1f}%")
                
                # æ˜¾ç¤ºå‰20ä¸ªç±»åˆ«
                top_values = value_counts.head(20)
                
                fig = px.bar(
                    x=top_values.index,
                    y=top_values.values,
                    title=f"{selected_col} ç±»åˆ«åˆ†å¸ƒ (Top 20)",
                    labels={'x': 'ç±»åˆ«', 'y': 'æ•°é‡'}
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
    
    def render_correlation_analysis(self):
        """æ¸²æŸ“ç›¸å…³æ€§åˆ†æ"""
        if st.session_state.dm_uploaded_data is None:
            st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
            return
        
        st.subheader("ğŸ”— ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
        
        df = st.session_state.dm_uploaded_data
        corr_matrix, high_corr_pairs = self.calculate_correlation(df)
        
        if corr_matrix.empty:
            st.info("æ•°æ®ä¸­æ•°å€¼å‹ç‰¹å¾å°‘äº2ä¸ª,æ— æ³•è®¡ç®—ç›¸å…³æ€§")
            return
        
        # ç›¸å…³æ€§çƒ­åŠ›å›¾
        fig = px.imshow(
            corr_matrix,
            text_auto='.2f',
            aspect="auto",
            color_continuous_scale='RdBu_r',
            title="ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾"
        )
        fig.update_layout(height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
        if high_corr_pairs:
            st.subheader("âš ï¸ é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|ç›¸å…³ç³»æ•°| > 0.7)")
            
            df_corr = pd.DataFrame(high_corr_pairs)
            st.dataframe(
                df_corr,
                column_config={
                    "feature1": st.column_config.TextColumn("ç‰¹å¾1"),
                    "feature2": st.column_config.TextColumn("ç‰¹å¾2"),
                    "correlation": st.column_config.NumberColumn("ç›¸å…³ç³»æ•°", format="%.3f")
                },
                hide_index=True,
                use_container_width=True
            )
            
            st.info("ğŸ’¡ é«˜ç›¸å…³æ€§ç‰¹å¾å¯èƒ½å­˜åœ¨å¤šé‡å…±çº¿æ€§,å»ºè®®è€ƒè™‘ç‰¹å¾é€‰æ‹©")
        else:
            st.success("âœ… æœªå‘ç°é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹")
    
    def render_report_generation(self):
        """æ¸²æŸ“æŠ¥å‘Šç”Ÿæˆ"""
        if 'missing_info' not in st.session_state.dm_analysis_results:
            st.warning("è¯·å…ˆè¿›è¡Œæ•°æ®è´¨é‡åˆ†æ")
            return
        
        st.subheader("ğŸ“„ ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        
        if st.button("ğŸ“¥ å¯¼å‡ºå®Œæ•´æŠ¥å‘Š (JSON)", type="primary"):
            report = {
                'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data_shape': st.session_state.dm_uploaded_data.shape,
                'quality_score': st.session_state.dm_analysis_results['quality_score'],
                'missing_values': st.session_state.dm_analysis_results['missing_info'],
                'outliers': st.session_state.dm_analysis_results['outliers']
            }
            
            report_json = json.dumps(report, indent=2, ensure_ascii=False)
            st.download_button(
                label="ä¸‹è½½æŠ¥å‘Š",
                data=report_json,
                file_name=f"data_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
            
            st.success("âœ… æŠ¥å‘Šå·²ç”Ÿæˆ!")
    
    def render(self):
        """ä¸»æ¸²æŸ“å‡½æ•°"""
        st.title("ğŸ”¬ Data Mining Agent - æ•°æ®è´¨é‡åˆ†æ")
        
        # æ•°æ®ä¸Šä¼ 
        self.render_data_upload()
        
        if st.session_state.dm_uploaded_data is not None:
            st.divider()
            
            # Tabåˆ‡æ¢
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                "ğŸ“Š è´¨é‡æ€»è§ˆ",
                "ğŸ” ç¼ºå¤±å€¼",
                "ğŸš¨ å¼‚å¸¸å€¼",
                "ğŸ“ˆ åˆ†å¸ƒåˆ†æ",
                "ğŸ”— ç›¸å…³æ€§",
                "ğŸ“„ æŠ¥å‘Š"
            ])
            
            with tab1:
                self.render_quality_overview()
            
            with tab2:
                self.render_missing_analysis()
            
            with tab3:
                self.render_outlier_analysis()
            
            with tab4:
                self.render_distribution_analysis()
            
            with tab5:
                self.render_correlation_analysis()
            
            with tab6:
                self.render_report_generation()


def main():
    """ä¸»å‡½æ•°"""
    agent = DataMiningAgent()
    agent.render()


if __name__ == "__main__":
    main()
