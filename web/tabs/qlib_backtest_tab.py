"""
QlibåŸç”Ÿå›æµ‹æ‰§è¡Œå™¨UIé›†æˆ
å®ç°å®Œæ•´çš„Qlibå›æµ‹åŠŸèƒ½å¹¶å±•ç¤ºæ ‡å‡†æŠ¥å‘Šå’ŒæŒ‡æ ‡
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from pathlib import Path
import json
from typing import Optional, Dict, Any, Tuple
import logging

logger = logging.getLogger(__name__)

# Qlib å¯¼å…¥
try:
    import qlib
    from qlib.backtest import backtest, get_exchange
    from qlib.constant import REG_CN
    from qlib.data import D
    from qlib.contrib.strategy.signal_strategy import TopkDropoutStrategy
    from qlib.contrib.evaluate import risk_analysis
    from qlib.backtest.exchange import Exchange
    QLIB_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Qlibå¯¼å…¥å¤±è´¥: {e}")
    QLIB_AVAILABLE = False


def _ensure_qlib_initialized():
    """ç¡®ä¿Qlibå·²ç»åˆå§‹åŒ–"""
    if not QLIB_AVAILABLE:
        return False
    
    try:
        # æ£€æŸ¥Qlibæ˜¯å¦å·²åˆå§‹åŒ–
        from qlib.config import C
        if C.get("provider_uri") is None:
            # å°è¯•ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–
            default_path = Path.home() / ".qlib/qlib_data/cn_data"
            if default_path.exists():
                qlib.init(provider_uri=str(default_path), region=REG_CN)
                return True
            else:
                return False
        return True
    except Exception as e:
        logger.error(f"Qlibåˆå§‹åŒ–æ£€æŸ¥å¤±è´¥: {e}")
        return False


def render_qlib_backtest_tab():
    """æ¸²æŸ“QlibåŸç”Ÿå›æµ‹é¡µé¢"""
    st.header("âª QlibåŸç”Ÿå›æµ‹å¼•æ“")
    
    if not QLIB_AVAILABLE:
        st.error("âŒ Qlibæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
        st.info("è¯·å…ˆå®‰è£…Qlib: `pip install pyqlib`")
        return
    
    if not _ensure_qlib_initialized():
        st.warning("âš ï¸ Qlibæœªåˆå§‹åŒ–æˆ–æ•°æ®è·¯å¾„ä¸å­˜åœ¨")
        st.info("è¯·å…ˆåœ¨'æ•°æ®ç®¡ç†'é¡µé¢åˆå§‹åŒ–Qlibå¹¶ä¸‹è½½æ•°æ®")
        
        # æä¾›å¿«é€Ÿåˆå§‹åŒ–é€‰é¡¹
        with st.expander("ğŸ”§ å¿«é€Ÿåˆå§‹åŒ–Qlib"):
            data_path = st.text_input(
                "Qlibæ•°æ®è·¯å¾„",
                value=str(Path.home() / ".qlib/qlib_data/cn_data"),
                help="Qlibæ•°æ®å­˜å‚¨è·¯å¾„"
            )
            if st.button("åˆå§‹åŒ–Qlib"):
                try:
                    qlib.init(provider_uri=data_path, region=REG_CN)
                    st.success("âœ… Qlibåˆå§‹åŒ–æˆåŠŸï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ å›æµ‹é…ç½®", "ğŸ“Š å›æµ‹ç»“æœ", "ğŸ“ˆ é£é™©åˆ†æ"])
    
    with tab1:
        render_backtest_config()
    
    with tab2:
        render_backtest_results()
    
    with tab3:
        render_backtest_risk_analysis()


def render_backtest_config():
    """æ¸²æŸ“å›æµ‹é…ç½®ç•Œé¢"""
    st.subheader("ğŸ“‹ å›æµ‹å‚æ•°é…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**åŸºæœ¬å‚æ•°**")
        
        # é¢„æµ‹ä¿¡å·æº
        signal_source = st.selectbox(
            "é¢„æµ‹ä¿¡å·æº",
            ["ä»å®éªŒåŠ è½½", "ä»æ–‡ä»¶ä¸Šä¼ ", "ä½¿ç”¨ç¤ºä¾‹æ•°æ®"],
            help="é€‰æ‹©é¢„æµ‹ä¿¡å·çš„æ¥æº"
        )
        
        pred_score = None
        
        if signal_source == "ä»å®éªŒåŠ è½½":
            exp_name = st.text_input("å®éªŒåç§°", value="qlib_models")
            recorder_id = st.text_input("Recorder ID (å¯é€‰)", value="")
            artifact_name = st.text_input("é¢„æµ‹æ–‡ä»¶å", value="pred.pkl")
            
            if st.button("åŠ è½½é¢„æµ‹ç»“æœ"):
                try:
                    from qlib.workflow import R
                    if recorder_id:
                        recorder = R.get_recorder(
                            recorder_id=recorder_id,
                            experiment_name=exp_name
                        )
                    else:
                        recorder = R.get_recorder(experiment_name=exp_name)
                    
                    pred_score = recorder.load_object(artifact_name)
                    st.session_state['backtest_pred_score'] = pred_score
                    st.success(f"âœ… åŠ è½½æˆåŠŸï¼é¢„æµ‹æ•°æ®shape: {pred_score.shape}")
                except Exception as e:
                    st.error(f"åŠ è½½å¤±è´¥: {e}")
        
        elif signal_source == "ä»æ–‡ä»¶ä¸Šä¼ ":
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ é¢„æµ‹ç»“æœæ–‡ä»¶ (CSV/PKL)",
                type=['csv', 'pkl'],
                help="CSVæ ¼å¼éœ€åŒ…å«datetimeç´¢å¼•å’Œinstrumentåˆ—"
            )
            if uploaded_file:
                try:
                    if uploaded_file.name.endswith('.csv'):
                        pred_score = pd.read_csv(uploaded_file, index_col=0)
                        pred_score.index = pd.to_datetime(pred_score.index)
                    else:
                        pred_score = pd.read_pickle(uploaded_file)
                    
                    st.session_state['backtest_pred_score'] = pred_score
                    st.success(f"âœ… ä¸Šä¼ æˆåŠŸï¼é¢„æµ‹æ•°æ®shape: {pred_score.shape}")
                except Exception as e:
                    st.error(f"ä¸Šä¼ å¤±è´¥: {e}")
        
        else:  # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
            st.info("å°†ä½¿ç”¨éšæœºç”Ÿæˆçš„ç¤ºä¾‹é¢„æµ‹æ•°æ®")
            if st.button("ç”Ÿæˆç¤ºä¾‹æ•°æ®"):
                pred_score = _generate_sample_predictions()
                st.session_state['backtest_pred_score'] = pred_score
                st.success(f"âœ… ç”ŸæˆæˆåŠŸï¼é¢„æµ‹æ•°æ®shape: {pred_score.shape}")
        
        # æ—¶é—´èŒƒå›´
        st.markdown("**å›æµ‹æ—¶é—´èŒƒå›´**")
        col_start, col_end = st.columns(2)
        with col_start:
            start_time = st.date_input(
                "å¼€å§‹æ—¥æœŸ",
                value=datetime(2020, 1, 1),
                key="bt_start_time"
            )
        with col_end:
            end_time = st.date_input(
                "ç»“æŸæ—¥æœŸ",
                value=datetime(2020, 12, 31),
                key="bt_end_time"
            )
        
        # è‚¡ç¥¨æ± 
        benchmark = st.selectbox(
            "åŸºå‡†æŒ‡æ•°",
            ["SH000300", "SH000905", "SH000852", "SZ399006"],
            help="ç”¨äºå¯¹æ¯”çš„åŸºå‡†æŒ‡æ•°"
        )
    
    with col2:
        st.markdown("**ç­–ç•¥å‚æ•°**")
        
        # åˆå§‹èµ„é‡‘
        init_cash = st.number_input(
            "åˆå§‹èµ„é‡‘(å…ƒ)",
            min_value=10000,
            max_value=100000000,
            value=1000000,
            step=100000
        )
        
        # æŒä»“æ•°é‡
        topk = st.slider(
            "æŒä»“è‚¡ç¥¨æ•°é‡",
            min_value=5,
            max_value=100,
            value=30,
            help="æ¯æ¬¡è°ƒä»“æ—¶æŒæœ‰çš„è‚¡ç¥¨æ•°é‡"
        )
        
        # Dropoutå‚æ•°
        n_drop = st.slider(
            "æ¯æ¬¡å–å‡ºæ•°é‡",
            min_value=0,
            max_value=50,
            value=5,
            help="æ¯æ¬¡è°ƒä»“æ—¶å¼ºåˆ¶å–å‡ºçš„è‚¡ç¥¨æ•°é‡"
        )
        
        st.markdown("**äº¤æ˜“æˆæœ¬**")
        col_open, col_close = st.columns(2)
        with col_open:
            open_cost = st.number_input(
                "ä¹°å…¥æ‰‹ç»­è´¹(%)",
                min_value=0.0,
                max_value=1.0,
                value=0.15,
                step=0.01,
                format="%.2f"
            ) / 100
        
        with col_close:
            close_cost = st.number_input(
                "å–å‡ºæ‰‹ç»­è´¹(%)",
                min_value=0.0,
                max_value=1.0,
                value=0.25,
                step=0.01,
                format="%.2f"
            ) / 100
        
        # ===== Alphaèåˆï¼ˆP2-1ï¼‰=====
        st.markdown("**Alphaèåˆ(å¯é€‰)**")
        try:
            from qlib_enhanced.analysis import load_factor_from_qlib as _load_factor
            alpha_enable = st.checkbox("å¯ç”¨ alpha_confluence / alpha_zs_* èåˆåˆ°é¢„æµ‹å¾—åˆ†", value=False)
            if alpha_enable:
                colw1, colw2, colw3 = st.columns(3)
                with colw1:
                    w_conf = st.number_input("w_confluence", value=0.30, step=0.05, format="%.2f")
                with colw2:
                    w_move = st.number_input("w_zs_movement", value=0.15, step=0.05, format="%.2f")
                with colw3:
                    w_upgr = st.number_input("w_zs_upgrade", value=0.10, step=0.05, format="%.2f")
                instruments_alpha = st.selectbox("å› å­æ•°æ®è‚¡ç¥¨æ± ", ["csi300","csi500","all"], index=0)
                col_alpha1, col_alpha2 = st.columns(2)
                with col_alpha1:
                    if st.button("åº”ç”¨AlphaåŠ æƒ", use_container_width=True):
                        try:
                            pred = st.session_state.get('backtest_pred_score', None)
                            if pred is None:
                                st.warning("è¯·å…ˆåœ¨å·¦ä¾§åŠ è½½/ç”Ÿæˆé¢„æµ‹ç»“æœ")
                        else:
                            s = str(st.session_state.get('bt_start_time', start_time))
                            e = str(st.session_state.get('bt_end_time', end_time))
                            df_c = _load_factor(instruments=instruments_alpha, start=str(start_time), end=str(end_time), factor_expr="$alpha_confluence", label_expr="Ref($close,-1)/$close-1")
                            df_m = _load_factor(instruments=instruments_alpha, start=str(start_time), end=str(end_time), factor_expr="$alpha_zs_movement", label_expr="Ref($close,-1)/$close-1")
                            df_u = _load_factor(instruments=instruments_alpha, start=str(start_time), end=str(end_time), factor_expr="$alpha_zs_upgrade", label_expr="Ref($close,-1)/$close-1")
                            # ç»Ÿä¸€ä¸ºé•¿è¡¨
                            def _to_long(x, name):
                                if isinstance(x.index, pd.MultiIndex):
                                    xx = x.copy()
                                    xx.columns = [name]
                                    return xx.reset_index().rename(columns={xx.columns[-1]: name})
                                elif 'instrument' in x.columns:
                                    return x.rename(columns={'factor': name})[['datetime','instrument',name]]
                                else:
                                    return x.reset_index().rename(columns={'index':'datetime','factor':name})
                            
                            c_long = _to_long(df_c, 'alpha_confluence')
                            m_long = _to_long(df_m, 'alpha_zs_movement')
                            u_long = _to_long(df_u, 'alpha_zs_upgrade')
                            
                            # é¢„æµ‹å¾—åˆ†é•¿è¡¨
                            if isinstance(pred.index, pd.MultiIndex):
                                pred_long = pred.stack().reset_index()
                                pred_long.columns = ['datetime','instrument','score']
                            else:
                                try:
                                    pred_long = pred.reset_index().melt(id_vars=['datetime'], var_name='instrument', value_name='score')
                                except Exception:
                                    st.error("é¢„æµ‹ç»“æœæ ¼å¼ä¸å…¼å®¹ï¼Œéœ€(index=datetime, columns=instrument)")
                                    pred_long = None
                            if pred_long is not None:
                                df_merged = pred_long.merge(c_long, on=['datetime','instrument'], how='left') \
                                                   .merge(m_long, on=['datetime','instrument'], how='left') \
                                                   .merge(u_long, on=['datetime','instrument'], how='left')
                                for col in ['alpha_confluence','alpha_zs_movement','alpha_zs_upgrade']:
                                    if col not in df_merged.columns:
                                        df_merged[col] = 0.0
                                df_merged['score_adj'] = df_merged['score'] * (1 + w_conf*df_merged['alpha_confluence'].fillna(0.0)
                                                                                 + w_move*df_merged['alpha_zs_movement'].fillna(0.0)
                                                                                 + w_upgr*df_merged['alpha_zs_upgrade'].fillna(0.0))
                                # è¿˜åŸåˆ°å®½è¡¨
                                try:
                                    adj = df_merged.pivot(index='datetime', columns='instrument', values='score_adj')
                                    st.session_state['backtest_pred_score'] = adj
                                    # ä¿å­˜AlphaåŠ æƒå‚æ•°
                                    st.session_state['alpha_weighting_applied'] = True
                                    st.session_state['alpha_weighting_params'] = {
                                        'w_confluence': w_conf,
                                        'w_zs_movement': w_move,
                                        'w_zs_upgrade': w_upgr,
                                        'instruments_alpha': instruments_alpha,
                                        'start_time': str(start_time),
                                        'end_time': str(end_time)
                                    }
                                    st.success("âœ… å·²åº”ç”¨AlphaåŠ æƒåˆ°é¢„æµ‹å¾—åˆ†")
                                except Exception as e2:
                                    st.error(f"åŠ æƒè¿˜åŸå¤±è´¥: {e2}")
                        except Exception as ee:
                            st.error(f"èåˆå¤±è´¥: {ee}")
                with col_alpha2:
                    if st.button("æ¸…é™¤åŠ æƒ", use_container_width=True, help="é‡ç½®ä¸ºåŸå§‹é¢„æµ‹å¾—åˆ†"):
                        st.session_state['alpha_weighting_applied'] = False
                        st.session_state.pop('alpha_weighting_params', None)
                        st.info("âœ… å·²æ¸…é™¤AlphaåŠ æƒæ ‡è®°")
        except Exception:
            st.caption("Alphaèåˆå¯é€‰ï¼šéœ€è¦ qlib_enhanced.analysis.load_factor_from_qlib æ”¯æŒ")
        
        min_cost = st.number_input(
            "æœ€ä½æ‰‹ç»­è´¹(å…ƒ)",
            min_value=0.0,
            max_value=10.0,
            value=5.0,
            step=0.5
        )
    
    st.divider()
    
    # è¿è¡Œå›æµ‹æŒ‰é’®
    col_run, col_save = st.columns([1, 1])
    
    with col_run:
        if st.button("ğŸš€ è¿è¡Œå›æµ‹", type="primary", use_container_width=True):
            if 'backtest_pred_score' not in st.session_state:
                st.error("è¯·å…ˆåŠ è½½æˆ–ç”Ÿæˆé¢„æµ‹æ•°æ®ï¼")
            else:
                with st.spinner("æ­£åœ¨è¿è¡Œå›æµ‹..."):
                    try:
                        results = run_qlib_backtest(
                            pred_score=st.session_state['backtest_pred_score'],
                            start_time=start_time.strftime("%Y-%m-%d"),
                            end_time=end_time.strftime("%Y-%m-%d"),
                            benchmark=benchmark,
                            topk=topk,
                            n_drop=n_drop,
                            init_cash=init_cash,
                            open_cost=open_cost,
                            close_cost=close_cost,
                            min_cost=min_cost
                        )
                        
                        st.session_state['backtest_results'] = results
                        st.session_state['last_backtest_returns'] = results.get('daily_returns')
                        st.success("âœ… å›æµ‹å®Œæˆï¼è¯·åˆ‡æ¢åˆ°'å›æµ‹ç»“æœ'æ ‡ç­¾æŸ¥çœ‹")
                        
                    except Exception as e:
                        st.error(f"å›æµ‹å¤±è´¥: {e}")
                        import traceback
                        with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
                            st.code(traceback.format_exc())
    
    with col_save:
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True):
            config = {
                "start_time": start_time.strftime("%Y-%m-%d"),
                "end_time": end_time.strftime("%Y-%m-%d"),
                "benchmark": benchmark,
                "topk": topk,
                "n_drop": n_drop,
                "init_cash": init_cash,
                "open_cost": open_cost,
                "close_cost": close_cost,
                "min_cost": min_cost,
            }
            st.session_state['backtest_config'] = config
            st.success("âœ… é…ç½®å·²ä¿å­˜")


def render_backtest_results():
    """æ¸²æŸ“å›æµ‹ç»“æœ"""
    st.subheader("ğŸ“Š å›æµ‹ç»“æœåˆ†æ")
    
    # P2-Backtest-UI: AlphaåŠ æƒæ ‡æ³¨
    if st.session_state.get('alpha_weighting_applied', False):
        st.success("âœ… **å·²ä½¿ç”¨ Alpha åŠ æƒ**")
        params = st.session_state.get('alpha_weighting_params', {})
        with st.expander("ğŸ” AlphaåŠ æƒå‚æ•°", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("w_confluence", f"{params.get('w_confluence', 0):.2f}")
            with col2:
                st.metric("w_zs_movement", f"{params.get('w_zs_movement', 0):.2f}")
            with col3:
                st.metric("w_zs_upgrade", f"{params.get('w_zs_upgrade', 0):.2f}")
            with col4:
                st.metric("è‚¡ç¥¨æ± ", params.get('instruments_alpha', 'N/A'))
            st.caption(f"ğŸ“… å› å­æ—¶é—´èŒƒå›´: {params.get('start_time', 'N/A')} ~ {params.get('end_time', 'N/A')}")
            st.caption("â„¹ï¸ è°ƒæ•´å…¬å¼: score_adj = score Ã— (1 + w_confÃ—alpha_confluence + w_moveÃ—alpha_zs_movement + w_upgrÃ—alpha_zs_upgrade)")
    
    if 'backtest_results' not in st.session_state:
        st.info("è¯·å…ˆåœ¨'å›æµ‹é…ç½®'æ ‡ç­¾è¿è¡Œå›æµ‹")
        return
    
    results = st.session_state['backtest_results']
    
    # å…³é”®æŒ‡æ ‡å¡ç‰‡
    st.markdown("### ğŸ“ˆ å…³é”®ç»©æ•ˆæŒ‡æ ‡")
    metrics = results.get('metrics', {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        ann_return = metrics.get('annualized_return', 0)
        st.metric(
            "å¹´åŒ–æ”¶ç›Šç‡",
            f"{ann_return:.2%}",
            delta=f"{ann_return:.2%}" if ann_return > 0 else None
        )
    
    with col2:
        sharpe = metrics.get('information_ratio', 0)
        st.metric("å¤æ™®æ¯”ç‡", f"{sharpe:.3f}")
    
    with col3:
        max_dd = metrics.get('max_drawdown', 0)
        st.metric("æœ€å¤§å›æ’¤", f"{max_dd:.2%}")
    
    with col4:
        win_rate = metrics.get('win_rate', 0)
        st.metric("èƒœç‡", f"{win_rate:.2%}")
    
    # å‡€å€¼æ›²çº¿
    st.markdown("### ğŸ’° å‡€å€¼æ›²çº¿")
    portfolio_value = results.get('portfolio_value')
    if portfolio_value is not None and not portfolio_value.empty:
        fig = go.Figure()
        
        # ç­–ç•¥å‡€å€¼
        fig.add_trace(go.Scatter(
            x=portfolio_value.index,
            y=portfolio_value.values,
            name='ç­–ç•¥å‡€å€¼',
            line=dict(color='#1f77b4', width=2)
        ))
        
        # åŸºå‡†å‡€å€¼
        benchmark_value = results.get('benchmark_value')
        if benchmark_value is not None and not benchmark_value.empty:
            fig.add_trace(go.Scatter(
                x=benchmark_value.index,
                y=benchmark_value.values,
                name='åŸºå‡†å‡€å€¼',
                line=dict(color='#ff7f0e', width=2, dash='dash')
            ))
        
        fig.update_layout(
            title="ç»„åˆå‡€å€¼èµ°åŠ¿",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="å‡€å€¼",
            hovermode='x unified',
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # å›æ’¤åˆ†æ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‰ å›æ’¤åˆ†æ")
        drawdown = results.get('drawdown')
        if drawdown is not None and not drawdown.empty:
            fig_dd = go.Figure()
            fig_dd.add_trace(go.Scatter(
                x=drawdown.index,
                y=drawdown.values * 100,
                fill='tozeroy',
                name='å›æ’¤',
                line=dict(color='red')
            ))
            fig_dd.update_layout(
                xaxis_title="æ—¥æœŸ",
                yaxis_title="å›æ’¤ (%)",
                height=300
            )
            st.plotly_chart(fig_dd, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ“Š æ”¶ç›Šåˆ†å¸ƒ")
        daily_returns = results.get('daily_returns')
        if daily_returns is not None and not daily_returns.empty:
            fig_hist = go.Figure()
            fig_hist.add_trace(go.Histogram(
                x=daily_returns.values * 100,
                nbinsx=50,
                name='æ—¥æ”¶ç›Š',
                marker=dict(color='lightblue')
            ))
            fig_hist.update_layout(
                xaxis_title="æ—¥æ”¶ç›Šç‡ (%)",
                yaxis_title="é¢‘æ•°",
                height=300
            )
            st.plotly_chart(fig_hist, use_container_width=True)
    
    # è¯¦ç»†æŒ‡æ ‡è¡¨æ ¼
    st.markdown("### ğŸ“‹ è¯¦ç»†æŒ‡æ ‡")
    
    if metrics:
        metrics_df = pd.DataFrame([
            {"æŒ‡æ ‡": "å¹´åŒ–æ”¶ç›Šç‡", "æ•°å€¼": f"{metrics.get('annualized_return', 0):.2%}"},
            {"æŒ‡æ ‡": "ç´¯è®¡æ”¶ç›Šç‡", "æ•°å€¼": f"{metrics.get('cumulative_return', 0):.2%}"},
            {"æŒ‡æ ‡": "å¤æ™®æ¯”ç‡", "æ•°å€¼": f"{metrics.get('information_ratio', 0):.3f}"},
            {"æŒ‡æ ‡": "æœ€å¤§å›æ’¤", "æ•°å€¼": f"{metrics.get('max_drawdown', 0):.2%}"},
            {"æŒ‡æ ‡": "æ³¢åŠ¨ç‡", "æ•°å€¼": f"{metrics.get('volatility', 0):.2%}"},
            {"æŒ‡æ ‡": "èƒœç‡", "æ•°å€¼": f"{metrics.get('win_rate', 0):.2%}"},
        ])
        st.dataframe(metrics_df, use_container_width=True, hide_index=True)
    
    # äº¤æ˜“è®°å½•
    st.markdown("### ğŸ“ äº¤æ˜“è®°å½•")
    trades = results.get('trades')
    if trades is not None and not trades.empty:
        st.dataframe(
            trades.head(100),
            use_container_width=True,
            height=300
        )
        
        # ä¸‹è½½äº¤æ˜“è®°å½•
        csv = trades.to_csv(index=True).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´äº¤æ˜“è®°å½•",
            data=csv,
            file_name=f"backtest_trades_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    else:
        st.info("æ— äº¤æ˜“è®°å½•")


def render_backtest_risk_analysis():
    """æ¸²æŸ“é£é™©åˆ†æ"""
    st.subheader("ğŸ“ˆ é£é™©åˆ†æ")
    
    if 'backtest_results' not in st.session_state:
        st.info("è¯·å…ˆåœ¨'å›æµ‹é…ç½®'æ ‡ç­¾è¿è¡Œå›æµ‹")
        return
    
    results = st.session_state['backtest_results']
    daily_returns = results.get('daily_returns')
    
    if daily_returns is None or daily_returns.empty:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æ”¶ç›Šæ•°æ®è¿›è¡Œé£é™©åˆ†æ")
        return
    
    # VaRå’ŒCVaRåˆ†æ
    st.markdown("### âš ï¸ VaR / CVaR åˆ†æ")
    
    confidence_level = st.slider(
        "ç½®ä¿¡æ°´å¹³",
        min_value=0.90,
        max_value=0.99,
        value=0.95,
        step=0.01,
        format="%.2f"
    )
    
    var_value = daily_returns.quantile(1 - confidence_level)
    cvar_value = daily_returns[daily_returns <= var_value].mean()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            f"VaR ({confidence_level:.0%})",
            f"{var_value:.2%}",
            help=f"æœ‰{confidence_level:.0%}çš„æŠŠæ¡ï¼Œæ—¥æŸå¤±ä¸è¶…è¿‡æ­¤å€¼"
        )
    
    with col2:
        st.metric(
            f"CVaR ({confidence_level:.0%})",
            f"{cvar_value:.2%}",
            help="è¶…è¿‡VaRæ—¶çš„å¹³å‡æŸå¤±"
        )
    
    with col3:
        downside_risk = daily_returns[daily_returns < 0].std()
        st.metric(
            "ä¸‹è¡Œé£é™©",
            f"{downside_risk:.2%}",
            help="è´Ÿæ”¶ç›Šçš„æ ‡å‡†å·®"
        )
    
    # æ»šåŠ¨é£é™©æŒ‡æ ‡
    st.markdown("### ğŸ“Š æ»šåŠ¨é£é™©æŒ‡æ ‡")
    
    window = st.select_slider(
        "æ»šåŠ¨çª—å£(å¤©)",
        options=[20, 40, 60, 120, 250],
        value=60
    )
    
    rolling_vol = daily_returns.rolling(window).std() * np.sqrt(252)
    rolling_sharpe = (
        daily_returns.rolling(window).mean() * 252 /
        (daily_returns.rolling(window).std() * np.sqrt(252))
    )
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=rolling_vol.index,
        y=rolling_vol.values * 100,
        name=f'{window}æ—¥æ»šåŠ¨æ³¢åŠ¨ç‡',
        yaxis='y',
        line=dict(color='blue')
    ))
    
    fig.add_trace(go.Scatter(
        x=rolling_sharpe.index,
        y=rolling_sharpe.values,
        name=f'{window}æ—¥æ»šåŠ¨å¤æ™®',
        yaxis='y2',
        line=dict(color='green')
    ))
    
    fig.update_layout(
        title=f"{window}æ—¥æ»šåŠ¨é£é™©æŒ‡æ ‡",
        xaxis=dict(title="æ—¥æœŸ"),
        yaxis=dict(title="æ³¢åŠ¨ç‡ (%)", side='left'),
        yaxis2=dict(title="å¤æ™®æ¯”ç‡", side='right', overlaying='y'),
        hovermode='x unified',
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾
    st.markdown("### ğŸ“… æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾")
    
    monthly_returns = daily_returns.resample('M').apply(lambda x: (1 + x).prod() - 1)
    monthly_returns_pivot = monthly_returns.to_frame('return')
    monthly_returns_pivot['year'] = monthly_returns_pivot.index.year
    monthly_returns_pivot['month'] = monthly_returns_pivot.index.month
    
    pivot_table = monthly_returns_pivot.pivot_table(
        values='return',
        index='year',
        columns='month'
    )
    
    fig_heatmap = go.Figure(data=go.Heatmap(
        z=pivot_table.values * 100,
        x=[f'{i}æœˆ' for i in pivot_table.columns],
        y=pivot_table.index,
        colorscale='RdYlGn',
        zmid=0,
        text=np.round(pivot_table.values * 100, 2),
        texttemplate='%{text:.1f}%',
        textfont={"size": 10},
        colorbar=dict(title="æ”¶ç›Šç‡(%)")
    ))
    
    fig_heatmap.update_layout(
        title="æœˆåº¦æ”¶ç›Šç‡çƒ­åŠ›å›¾",
        xaxis_title="æœˆä»½",
        yaxis_title="å¹´ä»½",
        height=400
    )
    
    st.plotly_chart(fig_heatmap, use_container_width=True)


def run_qlib_backtest(
    pred_score: pd.DataFrame,
    start_time: str,
    end_time: str,
    benchmark: str,
    topk: int,
    n_drop: int,
    init_cash: float,
    open_cost: float,
    close_cost: float,
    min_cost: float
) -> Dict[str, Any]:
    """
    è¿è¡ŒQlibå›æµ‹
    
    Args:
        pred_score: é¢„æµ‹åˆ†æ•°DataFrame
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        benchmark: åŸºå‡†æŒ‡æ•°
        topk: æŒä»“æ•°é‡
        n_drop: æ¯æ¬¡å–å‡ºæ•°é‡
        init_cash: åˆå§‹èµ„é‡‘
        open_cost: ä¹°å…¥æˆæœ¬
        close_cost: å–å‡ºæˆæœ¬
        min_cost: æœ€ä½æˆæœ¬
    
    Returns:
        åŒ…å«å›æµ‹ç»“æœçš„å­—å…¸
    """
    from qlib.contrib.strategy.signal_strategy import TopkDropoutStrategy
    from qlib.backtest import backtest
    from qlib.contrib.evaluate import risk_analysis  # âœ… å¯¼å…¥å®˜æ–¹ risk_analysis
    
    # é…ç½®ç­–ç•¥
    strategy_config = {
        "class": "TopkDropoutStrategy",
        "module_path": "qlib.contrib.strategy.signal_strategy",
        "kwargs": {
            "signal": pred_score,
            "topk": topk,
            "n_drop": n_drop,
        },
    }
    
    # é…ç½®æ‰§è¡Œå™¨
    executor_config = {
        "class": "SimulatorExecutor",
        "module_path": "qlib.backtest.executor",
        "kwargs": {
            "time_per_step": "day",
            "generate_portfolio_metrics": True,
        },
    }
    
    # é…ç½®äº¤æ˜“æ‰€
    exchange_kwargs = {
        "freq": "day",
        "start_time": start_time,
        "end_time": end_time,
        "codes": "all",
        "open_cost": open_cost,
        "close_cost": close_cost,
        "min_cost": min_cost,
    }
    
    # è¿è¡Œå›æµ‹
    portfolio_metric, indicator_metric = backtest(
        start_time=start_time,
        end_time=end_time,
        strategy=strategy_config,
        executor=executor_config,
        benchmark=benchmark,
        account=init_cash,
        exchange_kwargs=exchange_kwargs,
    )
    
    # æå–ç»“æœ
    analysis_freq = 'day'
    portfolio_df = portfolio_metric[analysis_freq][0]
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    daily_returns = portfolio_df['return'].dropna()
    cumulative_returns = (1 + daily_returns).cumprod()
    
    # å‡€å€¼
    portfolio_value = cumulative_returns
    
    # å›æ’¤
    running_max = cumulative_returns.expanding().max()
    drawdown = (cumulative_returns - running_max) / running_max
    
    # âœ… ä½¿ç”¨å®˜æ–¹ risk_analysis è®¡ç®—æ ‡å‡†é£é™©æŒ‡æ ‡ (ä¿®å¤ P0 é—®é¢˜)
    risk_metrics_df = risk_analysis(daily_returns, freq="day")
    risk_dict = risk_metrics_df["risk"].to_dict()
    
    # è¡¥å……é¢å¤–æŒ‡æ ‡
    win_rate = (daily_returns > 0).sum() / len(daily_returns) if len(daily_returns) > 0 else 0
    cumulative_return = cumulative_returns.iloc[-1] - 1
    
    # æ•´ç†æŒ‡æ ‡ (ä½¿ç”¨å®˜æ–¹è®¡ç®—ç»“æœ)
    metrics = {
        'annualized_return': risk_dict.get('annualized_return', 0),
        'cumulative_return': cumulative_return,
        'information_ratio': risk_dict.get('information_ratio', 0),  # å®˜æ–¹åç§°
        'max_drawdown': risk_dict.get('max_drawdown', 0),
        'volatility': risk_dict.get('std', 0) * np.sqrt(252),  # å¹´åŒ–æ³¢åŠ¨ç‡
        'win_rate': win_rate,
        # ä¿ç•™å®˜æ–¹å®Œæ•´æŒ‡æ ‡ä¾›è°ƒè¯•
        '_qlib_risk_metrics': risk_dict,
    }
    
    # è·å–äº¤æ˜“è®°å½•
    trades = None
    if 'orders' in portfolio_df.columns:
        trades = portfolio_df[portfolio_df['orders'].notna()][['orders']].copy()
    
    # åŸºå‡†æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    benchmark_value = None
    try:
        benchmark_returns = D.features(
            [benchmark],
            ['$close/Ref($close, 1)-1'],
            start_time=start_time,
            end_time=end_time
        )
        if not benchmark_returns.empty:
            benchmark_value = (1 + benchmark_returns).cumprod()
    except:
        pass
    
    return {
        'portfolio_value': portfolio_value,
        'benchmark_value': benchmark_value,
        'daily_returns': daily_returns,
        'drawdown': drawdown,
        'metrics': metrics,
        'trades': trades,
        'raw_portfolio': portfolio_df,
    }


def _generate_sample_predictions() -> pd.DataFrame:
    """ç”Ÿæˆç¤ºä¾‹é¢„æµ‹æ•°æ®"""
    # ç”Ÿæˆæ—¥æœŸèŒƒå›´
    dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')
    
    # ç”Ÿæˆè‚¡ç¥¨ä»£ç 
    stocks = [f'{str(i).zfill(6)}.SH' for i in range(1, 51)]
    
    # ç”Ÿæˆéšæœºé¢„æµ‹åˆ†æ•°
    np.random.seed(42)
    data = []
    
    for date in dates:
        for stock in stocks:
            score = np.random.randn()  # æ ‡å‡†æ­£æ€åˆ†å¸ƒ
            data.append({
                'datetime': date,
                'instrument': stock,
                'score': score
            })
    
    df = pd.DataFrame(data)
    df = df.set_index(['datetime', 'instrument'])
    
    return df['score']


if __name__ == "__main__":
    render_qlib_backtest_tab()
