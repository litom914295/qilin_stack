"""
RD-Agentæ™ºèƒ½ç ”ç©¶ç³»ç»Ÿé›†æˆ
å®ç°è‡ªåŠ¨åŒ–å› å­æŒ–æ˜ã€ç­–ç•¥ç ”ç©¶ã€æ¨¡å‹ä¼˜åŒ–ç­‰åŠŸèƒ½
"""

import os
import sys
import json
import yaml
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
import asyncio
import logging
from pathlib import Path
import ast
import inspect
import subprocess
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import pickle
import hashlib

# ä»£ç æ²™ç›’ (P1-3)
from rd_agent.code_sandbox import execute_safe, SecurityLevel

# æœºå™¨å­¦ä¹ ç›¸å…³
from sklearn.metrics import mean_squared_error, accuracy_score, f1_score
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
import optuna
from optuna.samplers import TPESampler

# å¤§è¯­è¨€æ¨¡å‹ç›¸å…³
import openai

# langchain 1.0+ å¯¼å…¥æ–¹å¼
try:
    # æ–°ç‰ˆlangchain (1.0+) - æ¨¡å—åŒ–ç»“æ„
    from langchain_community.chains import LLMChain
    from langchain_core.prompts import PromptTemplate
    from langchain_openai import OpenAI
    from langchain.agents import Tool, AgentExecutor
    LANGCHAIN_NEW = True
except ImportError as e:
    try:
        # å°è¯•æ—§ç‰ˆå¯¼å…¥æ–¹å¼
        from langchain import LLMChain, PromptTemplate
        from langchain.llms import OpenAI
        from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
        LANGCHAIN_NEW = False
    except ImportError:
        # langchainåŠŸèƒ½ä¸å¯ç”¨,ä½¿ç”¨é™çº§æ–¹æ¡ˆ
        LLMChain = None
        PromptTemplate = None
        OpenAI = None
        Tool = None
        AgentExecutor = None
        LANGCHAIN_NEW = None
        import warnings
        warnings.warn(f"langchainåŠŸèƒ½ä¸å¯ç”¨: {e}. éƒ¨åˆ†AIåŠŸèƒ½å°†è¢«ç¦ç”¨")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ResearchHypothesis:
    """ç ”ç©¶å‡è®¾"""
    id: str
    title: str
    description: str
    category: str  # factor/strategy/model
    confidence: float
    created_at: datetime
    status: str = "pending"  # pending/testing/validated/rejected
    results: Dict[str, Any] = field(default_factory=dict)


@dataclass
class FactorDefinition:
    """å› å­å®šä¹‰"""
    name: str
    expression: str
    description: str
    category: str
    parameters: Dict[str, Any]
    performance: Dict[str, float] = field(default_factory=dict)


@dataclass
class StrategyTemplate:
    """ç­–ç•¥æ¨¡æ¿"""
    name: str
    description: str
    entry_conditions: List[str]
    exit_conditions: List[str]
    risk_management: Dict[str, Any]
    parameters: Dict[str, Any]
    backtest_results: Dict[str, Any] = field(default_factory=dict)


class RDAgent:
    """RD-Agentä¸»ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–RD-Agent
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.hypothesis_generator = HypothesisGenerator(config)
        self.code_generator = CodeGenerator(config)
        self.execution_engine = ExecutionEngine(config)
        self.feedback_evaluator = FeedbackEvaluator(config)
        self.knowledge_base = KnowledgeBase(config)
        
        # æ‰§è¡Œå™¨
        self.thread_executor = ThreadPoolExecutor(max_workers=4)
        self.process_executor = ProcessPoolExecutor(max_workers=2)
        
        # ç ”ç©¶å†å²
        self.research_history = []
        
    async def research_pipeline(self, 
                               research_topic: str,
                               data: pd.DataFrame,
                               max_iterations: int = 10) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ç ”ç©¶æµç¨‹
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            data: å†å²æ•°æ®
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Returns:
            ç ”ç©¶ç»“æœ
        """
        results = {
            "topic": research_topic,
            "hypotheses": [],
            "factors": [],
            "strategies": [],
            "models": [],
            "best_solution": None
        }
        
        for iteration in range(max_iterations):
            logger.info(f"Research iteration {iteration + 1}/{max_iterations}")
            
            # 1. ç”Ÿæˆå‡è®¾
            hypotheses = await self.hypothesis_generator.generate(
                research_topic, data, self.knowledge_base
            )
            results["hypotheses"].extend(hypotheses)
            
            # 2. å¯¹æ¯ä¸ªå‡è®¾è¿›è¡Œç ”ç©¶
            for hypothesis in hypotheses:
                if hypothesis.status != "pending":
                    continue
                
                # ç”Ÿæˆä»£ç 
                code = await self.code_generator.generate_code(hypothesis)
                
                # æ‰§è¡Œæµ‹è¯•
                test_results = await self.execution_engine.execute(
                    code, data, hypothesis
                )
                
                # è¯„ä¼°åé¦ˆ
                evaluation = await self.feedback_evaluator.evaluate(
                    hypothesis, test_results, data
                )
                
                # æ›´æ–°å‡è®¾çŠ¶æ€
                hypothesis.status = evaluation["status"]
                hypothesis.results = evaluation
                
                # ä¿å­˜æœ‰æ•ˆçš„å› å­/ç­–ç•¥
                if hypothesis.status == "validated":
                    if hypothesis.category == "factor":
                        results["factors"].append(evaluation["factor"])
                    elif hypothesis.category == "strategy":
                        results["strategies"].append(evaluation["strategy"])
                    elif hypothesis.category == "model":
                        results["models"].append(evaluation["model"])
                
                # æ›´æ–°çŸ¥è¯†åº“
                self.knowledge_base.update(hypothesis, evaluation)
            
            # 3. æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æ»¡æ„çš„è§£å†³æ–¹æ¡ˆ
            if self._check_convergence(results):
                logger.info(f"Research converged at iteration {iteration + 1}")
                break
        
        # 4. é€‰æ‹©æœ€ä½³è§£å†³æ–¹æ¡ˆ
        results["best_solution"] = self._select_best_solution(results)
        
        # ä¿å­˜ç ”ç©¶å†å²
        self.research_history.append(results)
        
        return results
    
    async def discover_factors(self, 
                              data: pd.DataFrame,
                              target: str = "returns",
                              n_factors: int = 10) -> List[FactorDefinition]:
        """
        è‡ªåŠ¨å‘ç°å› å­
        
        Args:
            data: å†å²æ•°æ®
            target: ç›®æ ‡å˜é‡
            n_factors: è¦å‘ç°çš„å› å­æ•°é‡
            
        Returns:
            å› å­åˆ—è¡¨
        """
        factors = []
        
        # ç”Ÿæˆå› å­å‡è®¾
        factor_hypotheses = await self.hypothesis_generator.generate_factor_hypotheses(
            data, target, n_factors * 2  # ç”Ÿæˆæ›´å¤šä»¥ä¾›ç­›é€‰
        )
        # æµ‹è¯•æ¯ä¸ªå› å­
        for hypothesis in factor_hypotheses:
            # ç”Ÿæˆå› å­è®¡ç®—ä»£ç 
            factor_code = await self.code_generator.generate_factor_code(hypothesis)
            
            # è®¡ç®—å› å­å€¼
            factor_values = await self.execution_engine.calculate_factor(
                factor_code, data
            )
            
            # è¯„ä¼°å› å­æœ‰æ•ˆæ€§
            evaluation = await self.feedback_evaluator.evaluate_factor(
                factor_values, data[target]
            )
                
            if evaluation["is_valid"]:
                factor = FactorDefinition(
                    name=hypothesis.title,
                    expression=factor_code,
                    description=hypothesis.description,
                    category="technical",  # å¯ä»¥æ›´ç»†åˆ†
                    parameters={},
                    performance=evaluation["metrics"]
                )
                factors.append(factor)
                
                if len(factors) >= n_factors:
                    break
        
        return factors
    
    async def optimize_strategy(self,
                               strategy: StrategyTemplate,
                               data: pd.DataFrame,
                               n_trials: int = 100) -> StrategyTemplate:
        """
        ä¼˜åŒ–ç­–ç•¥å‚æ•°
        
        Args:
            strategy: ç­–ç•¥æ¨¡æ¿
            data: å†å²æ•°æ®
            n_trials: ä¼˜åŒ–è¯•éªŒæ¬¡æ•°
            
        Returns:
            ä¼˜åŒ–åçš„ç­–ç•¥
        """
        # ä½¿ç”¨Optunaè¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
        study = optuna.create_study(
            direction="maximize",
            sampler=TPESampler(seed=42)
        )
        def objective(trial):
            # é‡‡æ ·å‚æ•°
            params = {}
            for param_name, param_config in strategy.parameters.items():
                if param_config["type"] == "float":
                    params[param_name] = trial.suggest_float(
                        param_name,
                        param_config["min"],
                        param_config["max"]
                    )
                elif param_config["type"] == "int":
                    params[param_name] = trial.suggest_int(
                        param_name,
                        param_config["min"],
                        param_config["max"]
                    )
                elif param_config["type"] == "categorical":
                    params[param_name] = trial.suggest_categorical(
                        param_name,
                        param_config["choices"]
                    )
            
            # å›æµ‹ç­–ç•¥
            backtest_results = self._backtest_strategy(strategy, data, params)
            
            # è¿”å›ä¼˜åŒ–ç›®æ ‡ï¼ˆå¦‚å¤æ™®æ¯”ç‡ï¼‰
            return backtest_results.get("sharpe_ratio", 0)
        
        # è¿è¡Œä¼˜åŒ–
        study.optimize(objective, n_trials=n_trials)
        
        # æ›´æ–°ç­–ç•¥å‚æ•°ä¸ºæœ€ä¼˜å€¼
        best_params = study.best_params
        strategy.parameters.update(best_params)
        strategy.backtest_results = self._backtest_strategy(strategy, data, best_params)
        
        return strategy
    
    def _backtest_strategy(self,
                          strategy: StrategyTemplate,
                          data: pd.DataFrame,
                          params: Dict[str, Any]) -> Dict[str, Any]:
        """å›æµ‹ç­–ç•¥"""
        # ç®€åŒ–çš„å›æµ‹é€»è¾‘
        returns = []
        positions = []
        
        for i in range(len(data)):
            # æ£€æŸ¥å…¥åœºæ¡ä»¶
            if self._check_conditions(strategy.entry_conditions, data.iloc[i], params):
                positions.append(1)
            # æ£€æŸ¥å‡ºåœºæ¡ä»¶
            elif self._check_conditions(strategy.exit_conditions, data.iloc[i], params):
                positions.append(0)
            else:
                positions.append(positions[-1] if positions else 0)
            
            # è®¡ç®—æ”¶ç›Š
            if i > 0 and positions[i-1] > 0:
                returns.append(data.iloc[i]["returns"])
            else:
                returns.append(0)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        returns_series = pd.Series(returns)
        total_return = (1 + returns_series).prod() - 1
        sharpe_ratio = returns_series.mean() / (returns_series.std() + 1e-8) * np.sqrt(252)
        max_drawdown = self._calculate_max_drawdown(returns_series)
        
        return {
            "total_return": total_return,
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown,
            "win_rate": (returns_series > 0).sum() / (returns_series != 0).sum()
        }
    
    def _check_conditions(self, conditions: List[str], data: pd.Series, params: Dict) -> bool:
        """æ£€æŸ¥æ¡ä»¶æ˜¯å¦æ»¡è¶³"""
        for condition in conditions:
            # P1-3: ä½¿ç”¨ä»£ç æ²™ç›’æ‰§è¡Œæ¡ä»¶æ£€æŸ¥
            code = f"result = {condition}"
            execution_result = execute_safe(
                code=code,
                context={"data": data, "params": params},
                timeout=2
            )
            
            if not execution_result.success:
                logger.warning(f"Condition execution failed: {execution_result.error}")
                return False
            
            if not execution_result.locals.get('result', False):
                return False
        return True
    
    def _calculate_max_drawdown(self, returns: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.cummax()
        drawdown = (cumulative - running_max) / running_max
        return drawdown.min()
    
    def _check_convergence(self, results: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        # ç®€å•çš„æ”¶æ•›åˆ¤æ–­
        if len(results["factors"]) >= 5 or len(results["strategies"]) >= 3:
            return True
        return False
    
    def _select_best_solution(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """é€‰æ‹©æœ€ä½³è§£å†³æ–¹æ¡ˆ"""
        best_solution = {
            "type": None,
            "solution": None,
            "performance": {}
        }
        
        # é€‰æ‹©æœ€ä½³å› å­
        if results["factors"]:
            best_factor = max(results["factors"], 
                            key=lambda f: f.performance.get("ic", 0))
            best_solution = {
                "type": "factor",
                "solution": best_factor,
                "performance": best_factor.performance
            }
        
        # é€‰æ‹©æœ€ä½³ç­–ç•¥
        if results["strategies"]:
            best_strategy = max(results["strategies"],
                              key=lambda s: s.backtest_results.get("sharpe_ratio", 0))
            if best_strategy.backtest_results.get("sharpe_ratio", 0) > \
               best_solution["performance"].get("sharpe_ratio", 0):
                best_solution = {
                    "type": "strategy",
                    "solution": best_strategy,
                    "performance": best_strategy.backtest_results
                }
        
        return best_solution


class HypothesisGenerator:
    """å‡è®¾ç”Ÿæˆå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.llm = self._init_llm()
        
    def _init_llm(self):
        """åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹"""
        # langchainä¸ºå¯é€‰ä¾èµ–,å½“å‰ä½¿ç”¨åŸºäºè§„åˆ™çš„ç”Ÿæˆå™¨
        if LANGCHAIN_NEW is None:
            logger.info("ğŸ’¡ langchainä¸å¯ç”¨,ä½¿ç”¨åŸºäºè§„åˆ™çš„ç”Ÿæˆå™¨")
            return None
        
        # æœªæ¥å¯ä»¥åœ¨è¿™é‡Œé…ç½®çœŸæ­£çš„LLM
        return None
    
    async def generate(self,
                       topic: str,
                       data: pd.DataFrame,
                       knowledge_base: 'KnowledgeBase') -> List[ResearchHypothesis]:
        """ç”Ÿæˆç ”ç©¶å‡è®¾"""
        hypotheses = []
        
        # åŸºäºå¸‚åœºç‰¹å¾ç”Ÿæˆå‡è®¾
        market_features = self._analyze_market_features(data)
        
        # ç”ŸæˆæŠ€æœ¯åˆ†æå‡è®¾
        tech_hypotheses = self._generate_technical_hypotheses(market_features)
        hypotheses.extend(tech_hypotheses)
        
        # ç”ŸæˆåŸºæœ¬é¢å‡è®¾
        fundamental_hypotheses = self._generate_fundamental_hypotheses(market_features)
        hypotheses.extend(fundamental_hypotheses)
        
        # åŸºäºçŸ¥è¯†åº“ç”Ÿæˆå‡è®¾
        kb_hypotheses = self._generate_from_knowledge_base(knowledge_base, market_features)
        hypotheses.extend(kb_hypotheses)
        
        return hypotheses
    
    async def generate_factor_hypotheses(self,
                                        data: pd.DataFrame,
                                        target: str,
                                        n_hypotheses: int) -> List[ResearchHypothesis]:
        """ç”Ÿæˆå› å­å‡è®¾"""
        hypotheses = []
        
        # åŠ¨é‡ç±»å› å­
        hypotheses.append(ResearchHypothesis(
            id=f"factor_{len(hypotheses)}",
            title="çŸ­æœŸåŠ¨é‡å› å­",
            description="åŸºäºè¿‡å»5æ—¥æ”¶ç›Šç‡çš„åŠ¨é‡å› å­",
            category="factor",
            confidence=0.7,
            created_at=datetime.now()
        ))
        
        # åè½¬ç±»å› å­
        hypotheses.append(ResearchHypothesis(
            id=f"factor_{len(hypotheses)}",
            title="å‡å€¼å›å½’å› å­",
            description="ä»·æ ¼åç¦»20æ—¥å‡çº¿çš„ç¨‹åº¦",
            category="factor",
            confidence=0.6,
            created_at=datetime.now()
        ))
        
        # æ³¢åŠ¨ç‡å› å­
        hypotheses.append(ResearchHypothesis(
            id=f"factor_{len(hypotheses)}",
            title="æ³¢åŠ¨ç‡å› å­",
            description="20æ—¥æ»šåŠ¨æ³¢åŠ¨ç‡",
            category="factor",
            confidence=0.8,
            created_at=datetime.now()
        ))
        
        # æˆäº¤é‡å› å­
        hypotheses.append(ResearchHypothesis(
            id=f"factor_{len(hypotheses)}",
            title="é‡ä»·èƒŒç¦»å› å­",
            description="ä»·æ ¼ä¸æˆäº¤é‡çš„èƒŒç¦»ç¨‹åº¦",
            category="factor",
            confidence=0.65,
            created_at=datetime.now()
        ))
        
        # æŠ€æœ¯æŒ‡æ ‡ç»„åˆå› å­
        hypotheses.append(ResearchHypothesis(
            id=f"factor_{len(hypotheses)}",
            title="RSI-MACDç»„åˆå› å­",
            description="RSIå’ŒMACDçš„ç»„åˆä¿¡å·",
            category="factor",
            confidence=0.75,
            created_at=datetime.now()
        ))
        
        return hypotheses[:n_hypotheses]
    
    def _analyze_market_features(self, data: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå¸‚åœºç‰¹å¾"""
        features = {}
        
        if "close" in data.columns:
            features["volatility"] = data["close"].pct_change().std()
            features["trend"] = (data["close"].iloc[-1] - data["close"].iloc[0]) / data["close"].iloc[0]
            features["mean_volume"] = data.get("volume", pd.Series()).mean()
        
        return features
    
    def _generate_technical_hypotheses(self, features: Dict[str, Any]) -> List[ResearchHypothesis]:
        """ç”ŸæˆæŠ€æœ¯åˆ†æå‡è®¾"""
        hypotheses = []
        
        # æ ¹æ®æ³¢åŠ¨ç‡ç”Ÿæˆå‡è®¾
        if features.get("volatility", 0) > 0.02:
            hypotheses.append(ResearchHypothesis(
                id=f"tech_{len(hypotheses)}",
                title="é«˜æ³¢åŠ¨ç‡äº¤æ˜“ç­–ç•¥",
                description="åœ¨é«˜æ³¢åŠ¨ç¯å¢ƒä¸‹ä½¿ç”¨å‡å€¼å›å½’ç­–ç•¥",
                category="strategy",
                confidence=0.7,
                created_at=datetime.now()
            ))
        
        # æ ¹æ®è¶‹åŠ¿ç”Ÿæˆå‡è®¾
        if abs(features.get("trend", 0)) > 0.1:
            hypotheses.append(ResearchHypothesis(
                id=f"tech_{len(hypotheses)}",
                title="è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥",
                description="ä½¿ç”¨ç§»åŠ¨å¹³å‡çº¿äº¤å‰ä¿¡å·è¿›è¡Œè¶‹åŠ¿è·Ÿè¸ª",
                category="strategy",
                confidence=0.75,
                created_at=datetime.now()
            ))
        
        return hypotheses
    
    def _generate_fundamental_hypotheses(self, features: Dict[str, Any]) -> List[ResearchHypothesis]:
        """ç”ŸæˆåŸºæœ¬é¢å‡è®¾"""
        hypotheses = []
        
        # è¿™é‡Œå¯ä»¥åŠ å…¥æ›´å¤šåŸºæœ¬é¢é€»è¾‘
        hypotheses.append(ResearchHypothesis(
            id=f"fund_0",
            title="ä»·å€¼æŠ•èµ„å› å­",
            description="åŸºäºå¸‚ç›ˆç‡å’Œå¸‚å‡€ç‡çš„ä»·å€¼å› å­",
            category="factor",
            confidence=0.8,
            created_at=datetime.now()
        ))
        
        return hypotheses
    
    def _generate_from_knowledge_base(self,
                                     knowledge_base: 'KnowledgeBase',
                                     features: Dict[str, Any]) -> List[ResearchHypothesis]:
        """åŸºäºçŸ¥è¯†åº“ç”Ÿæˆå‡è®¾"""
        hypotheses = []
        
        # æŸ¥è¯¢ç›¸ä¼¼çš„æˆåŠŸæ¡ˆä¾‹
        similar_cases = knowledge_base.find_similar_cases(features)
        
        for case in similar_cases[:3]:  # åªå–å‰3ä¸ª
            hypothesis = ResearchHypothesis(
                id=f"kb_{len(hypotheses)}",
                title=f"åŸºäºå†å²æ¡ˆä¾‹çš„{case['type']}",
                description=f"å‚è€ƒå†å²æˆåŠŸæ¡ˆä¾‹ï¼š{case['description']}",
                category=case['category'],
                confidence=case['success_rate'],
                created_at=datetime.now()
            )
            hypotheses.append(hypothesis)
        
        return hypotheses


class CodeGenerator:
    """ä»£ç ç”Ÿæˆå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.templates = self._load_templates()
    
    def _load_templates(self) -> Dict[str, str]:
        """åŠ è½½ä»£ç æ¨¡æ¿"""
        return {
            "factor": """
def calculate_factor(data):
    '''
    {description}
    '''
    {implementation}
    return factor_values
""",
            "strategy": """
class Strategy:
    def __init__(self, params):
        self.params = params
    
    def generate_signals(self, data):
        '''
        {description}
        '''
        signals = []
        {implementation}
        return signals
""",
            "model": """
class Model:
    def __init__(self, params):
        self.params = params
        
    def fit(self, X, y):
        {fit_implementation}
        
    def predict(self, X):
        {predict_implementation}
        return predictions
"""
        }
    
    async def generate_code(self, hypothesis: ResearchHypothesis) -> str:
        """ç”Ÿæˆä»£ç """
        if hypothesis.category == "factor":
            return await self.generate_factor_code(hypothesis)
        elif hypothesis.category == "strategy":
            return await self.generate_strategy_code(hypothesis)
        elif hypothesis.category == "model":
            return await self.generate_model_code(hypothesis)
        else:
            raise ValueError(f"Unknown category: {hypothesis.category}")
    
    async def generate_factor_code(self, hypothesis: ResearchHypothesis) -> str:
        """ç”Ÿæˆå› å­ä»£ç """
        implementations = {
            "çŸ­æœŸåŠ¨é‡å› å­": "factor_values = data['close'].pct_change(5)",
            "å‡å€¼å›å½’å› å­": "ma20 = data['close'].rolling(20).mean()\n    factor_values = (data['close'] - ma20) / ma20",
            "æ³¢åŠ¨ç‡å› å­": "factor_values = data['close'].pct_change().rolling(20).std()",
            "é‡ä»·èƒŒç¦»å› å­": "price_change = data['close'].pct_change()\n    volume_change = data['volume'].pct_change()\n    factor_values = price_change - volume_change",
            "RSI-MACDç»„åˆå› å­": """
    # RSI
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    
    # MACD
    ema12 = data['close'].ewm(span=12).mean()
    ema26 = data['close'].ewm(span=26).mean()
    macd = ema12 - ema26
    signal = macd.ewm(span=9).mean()
    
    # ç»„åˆ
    factor_values = (rsi - 50) / 50 + (macd - signal) / data['close']"""
        }
        
        implementation = implementations.get(
            hypothesis.title,
            "factor_values = data['close'].pct_change()"  # é»˜è®¤å®ç°
        )
        
        code = self.templates["factor"].format(
            description=hypothesis.description,
            implementation=implementation
        )
        
        return code
    
    async def generate_strategy_code(self, hypothesis: ResearchHypothesis) -> str:
        """ç”Ÿæˆç­–ç•¥ä»£ç """
        implementations = {
            "é«˜æ³¢åŠ¨ç‡äº¤æ˜“ç­–ç•¥": """
        for i in range(len(data)):
            if i < 20:
                signals.append(0)
                continue
            
            # è®¡ç®—æ³¢åŠ¨ç‡
            volatility = data.iloc[i-20:i]['close'].pct_change().std()
            
            # è®¡ç®—åç¦»åº¦
            ma20 = data.iloc[i-20:i]['close'].mean()
            deviation = (data.iloc[i]['close'] - ma20) / ma20
            
            # é«˜æ³¢åŠ¨ç‡ä¸‹çš„å‡å€¼å›å½’
            if volatility > self.params.get('vol_threshold', 0.02):
                if deviation < -self.params.get('entry_threshold', 0.03):
                    signals.append(1)  # ä¹°å…¥
                elif deviation > self.params.get('exit_threshold', 0.03):
                    signals.append(-1)  # å–å‡º
                else:
                    signals.append(0)
            else:
                signals.append(0)""",
                
            "è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥": """
        for i in range(len(data)):
            if i < 50:
                signals.append(0)
                continue
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            ma20 = data.iloc[i-20:i]['close'].mean()
            ma50 = data.iloc[i-50:i]['close'].mean()
            
            # äº¤å‰ä¿¡å·
            prev_ma20 = data.iloc[i-21:i-1]['close'].mean()
            prev_ma50 = data.iloc[i-51:i-1]['close'].mean()
            
            if ma20 > ma50 and prev_ma20 <= prev_ma50:
                signals.append(1)  # é‡‘å‰ä¹°å…¥
            elif ma20 < ma50 and prev_ma20 >= prev_ma50:
                signals.append(-1)  # æ­»å‰å–å‡º
            else:
                signals.append(0)"""
        }
        
        implementation = implementations.get(
            hypothesis.title,
            "signals = [0] * len(data)  # é»˜è®¤æ— ä¿¡å·"
        )
        
        code = self.templates["strategy"].format(
            description=hypothesis.description,
            implementation=implementation
        )
        
        return code
    
    async def generate_model_code(self, hypothesis: ResearchHypothesis) -> str:
        """ç”Ÿæˆæ¨¡å‹ä»£ç """
        # ç®€åŒ–çš„æ¨¡å‹ä»£ç ç”Ÿæˆ
        code = self.templates["model"].format(
            fit_implementation="# Model fitting logic here",
            predict_implementation="# Prediction logic here"
        )
        return code


class ExecutionEngine:
    """æ‰§è¡Œå¼•æ“"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.sandbox = self._create_sandbox()
    
    def _create_sandbox(self) -> Dict[str, Any]:
        """åˆ›å»ºå®‰å…¨çš„æ‰§è¡Œæ²™ç®±"""
        import numpy as np
        import pandas as pd
        
        sandbox = {
            'np': np,
            'pd': pd,
            'datetime': datetime,
            '__builtins__': {
                'len': len,
                'range': range,
                'min': min,
                'max': max,
                'abs': abs,
                'sum': sum,
                'print': print
            }
        }
        return sandbox
    
    async def execute(self,
                     code: str,
                     data: pd.DataFrame,
                     hypothesis: ResearchHypothesis) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç  (P1-3: ä½¿ç”¨ä»£ç æ²™ç›’)"""
        try:
            # P1-3: ä½¿ç”¨ä»£ç æ²™ç›’æ‰§è¡Œ
            context = {
                'data': data,
                'np': np,
                'pd': pd,
                'datetime': datetime
            }
            
            execution_result = execute_safe(
                code=code,
                context=context,
                timeout=10  # 10ç§’è¶…æ—¶
            )
            
            if not execution_result.success:
                logger.error(f"Execution error: {execution_result.error}")
                return {"success": False, "error": execution_result.error}
            
            # è·å–ç»“æœ
            if hypothesis.category == "factor":
                calculate_factor = execution_result.locals.get('calculate_factor')
                if calculate_factor:
                    result = calculate_factor(data)
                    return {"factor_values": result, "success": True}
            elif hypothesis.category == "strategy":
                # åˆ›å»ºç­–ç•¥å®ä¾‹
                strategy_class = execution_result.locals.get('Strategy')
                if strategy_class:
                    strategy = strategy_class({'vol_threshold': 0.02})
                    signals = strategy.generate_signals(data)
                    return {"signals": signals, "success": True}
            elif hypothesis.category == "model":
                model_class = execution_result.locals.get('Model')
                if model_class:
                    return {"model": model_class, "success": True}
            
            return {"success": False, "error": "No result found"}
            
        except Exception as e:
            logger.error(f"Execution error: {e}")
            return {"success": False, "error": str(e)}
    
    async def calculate_factor(self, factor_code: str, data: pd.DataFrame) -> pd.Series:
        """è®¡ç®—å› å­å€¼ (P1-3: ä½¿ç”¨ä»£ç æ²™ç›’)"""
        try:
            # P1-3: ä½¿ç”¨ä»£ç æ²™ç›’æ‰§è¡Œ
            context = {
                'data': data,
                'np': np,
                'pd': pd
            }
            
            execution_result = execute_safe(
                code=factor_code,
                context=context,
                timeout=10
            )
            
            if not execution_result.success:
                logger.error(f"Factor calculation error: {execution_result.error}")
                return pd.Series()
            
            calculate_func = execution_result.locals.get('calculate_factor')
            if calculate_func:
                return calculate_func(data)
            
            return pd.Series()
            
        except Exception as e:
            logger.error(f"Factor calculation error: {e}")
            return pd.Series()


class FeedbackEvaluator:
    """åé¦ˆè¯„ä¼°å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.metrics_calculator = MetricsCalculator()
    
    async def evaluate(self,
                      hypothesis: ResearchHypothesis,
                      test_results: Dict[str, Any],
                      data: pd.DataFrame) -> Dict[str, Any]:
        """è¯„ä¼°æµ‹è¯•ç»“æœ"""
        evaluation = {
            "status": "rejected",
            "metrics": {},
            "feedback": ""
        }
        
        if not test_results.get("success"):
            evaluation["feedback"] = f"Execution failed: {test_results.get('error')}"
            return evaluation
        
        if hypothesis.category == "factor":
            factor_eval = await self.evaluate_factor(
                test_results.get("factor_values"),
                data.get("returns", data["close"].pct_change())
            )
            evaluation.update(factor_eval)
            
        elif hypothesis.category == "strategy":
            strategy_eval = await self.evaluate_strategy(
                test_results.get("signals"),
                data
            )
            evaluation.update(strategy_eval)
            
        elif hypothesis.category == "model":
            model_eval = await self.evaluate_model(
                test_results.get("model"),
                data
            )
            evaluation.update(model_eval)
        
        return evaluation
    
    async def evaluate_factor(self,
                             factor_values: pd.Series,
                             returns: pd.Series) -> Dict[str, Any]:
        """è¯„ä¼°å› å­"""
        if factor_values is None or factor_values.empty:
            return {"status": "rejected", "feedback": "Empty factor values"}
        
        # è®¡ç®—ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰
        ic = factor_values.corr(returns.shift(-1))
        
        # è®¡ç®—IRï¼ˆä¿¡æ¯æ¯”ç‡ï¼‰
        ic_series = factor_values.rolling(20).corr(returns.shift(-1))
        ir = ic_series.mean() / (ic_series.std() + 1e-8)
        
        # è®¡ç®—å› å­æ”¶ç›Š
        factor_returns = self._calculate_factor_returns(factor_values, returns)
        
        metrics = {
            "ic": ic,
            "ir": ir,
            "factor_returns": factor_returns.mean(),
            "factor_sharpe": factor_returns.mean() / (factor_returns.std() + 1e-8) * np.sqrt(252)
        }
        
        # åˆ¤æ–­æ˜¯å¦æœ‰æ•ˆ
        is_valid = abs(ic) > 0.03 and abs(ir) > 0.5
        
        return {
            "status": "validated" if is_valid else "rejected",
            "metrics": metrics,
            "factor": FactorDefinition(
                name=f"factor_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                expression=str(factor_values),
                description="Auto-generated factor",
                category="technical",
                parameters={},
                performance=metrics
            ) if is_valid else None,
            "feedback": f"IC={ic:.4f}, IR={ir:.4f}"
        }
    
    async def evaluate_strategy(self,
                               signals: List[int],
                               data: pd.DataFrame) -> Dict[str, Any]:
        """è¯„ä¼°ç­–ç•¥"""
        if not signals:
            return {"status": "rejected", "feedback": "No signals generated"}
        
        # è®¡ç®—ç­–ç•¥æ”¶ç›Š
        returns = data["close"].pct_change()
        strategy_returns = pd.Series([
            returns.iloc[i] if i > 0 and signals[i-1] == 1 else 0
            for i in range(len(returns))
        ])
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        total_return = (1 + strategy_returns).prod() - 1
        sharpe_ratio = strategy_returns.mean() / (strategy_returns.std() + 1e-8) * np.sqrt(252)
        max_drawdown = self._calculate_max_drawdown(strategy_returns)
        win_rate = (strategy_returns > 0).sum() / (strategy_returns != 0).sum()
        
        metrics = {
            "total_return": total_return,
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown,
            "win_rate": win_rate
        }
        
        # åˆ¤æ–­æ˜¯å¦æœ‰æ•ˆ
        is_valid = sharpe_ratio > 0.5 and max_drawdown > -0.2
        
        return {
            "status": "validated" if is_valid else "rejected",
            "metrics": metrics,
            "strategy": StrategyTemplate(
                name=f"strategy_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                description="Auto-generated strategy",
                entry_conditions=[],
                exit_conditions=[],
                risk_management={},
                parameters={},
                backtest_results=metrics
            ) if is_valid else None,
            "feedback": f"Sharpe={sharpe_ratio:.2f}, MaxDD={max_drawdown:.2%}"
        }
    
    async def evaluate_model(self,
                           model_class: type,
                           data: pd.DataFrame) -> Dict[str, Any]:
        """è¯„ä¼°æ¨¡å‹"""
        # ç®€åŒ–çš„æ¨¡å‹è¯„ä¼°
        return {
            "status": "validated",
            "metrics": {},
            "model": model_class,
            "feedback": "Model validated"
        }
    
    def _calculate_factor_returns(self,
                                 factor_values: pd.Series,
                                 returns: pd.Series) -> pd.Series:
        """è®¡ç®—å› å­æ”¶ç›Š"""
        # æ ¹æ®å› å­å€¼åˆ†ç»„
        quantiles = pd.qcut(factor_values, q=5, labels=False)
        
        # è®¡ç®—å¤šç©ºç»„åˆæ”¶ç›Š
        top_returns = returns[quantiles == 4]
        bottom_returns = returns[quantiles == 0]
        
        factor_returns = top_returns.mean() - bottom_returns.mean()
        
        return pd.Series([factor_returns] * len(returns))
    
    def _calculate_max_drawdown(self, returns: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.cummax()
        drawdown = (cumulative - running_max) / running_max
        return drawdown.min()


class MetricsCalculator:
    """æŒ‡æ ‡è®¡ç®—å™¨"""
    
    def calculate_ic(self, factor: pd.Series, returns: pd.Series) -> float:
        """è®¡ç®—ä¿¡æ¯ç³»æ•°"""
        return factor.corr(returns.shift(-1))
    
    def calculate_ir(self, factor: pd.Series, returns: pd.Series, window: int = 20) -> float:
        """è®¡ç®—ä¿¡æ¯æ¯”ç‡"""
        ic_series = factor.rolling(window).corr(returns.shift(-1))
        return ic_series.mean() / (ic_series.std() + 1e-8)
    
    def calculate_sharpe(self, returns: pd.Series, risk_free: float = 0) -> float:
        """è®¡ç®—å¤æ™®æ¯”ç‡"""
        excess_returns = returns - risk_free
        return excess_returns.mean() / (excess_returns.std() + 1e-8) * np.sqrt(252)


class KnowledgeBase:
    """çŸ¥è¯†åº“"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.storage_path = Path(config.get("storage_path", "./knowledge_base"))
        self.storage_path.mkdir(exist_ok=True)
        self.cases = self._load_cases()
    
    def _load_cases(self) -> List[Dict[str, Any]]:
        """åŠ è½½å†å²æ¡ˆä¾‹"""
        cases_file = self.storage_path / "cases.json"
        if cases_file.exists():
            with open(cases_file, 'r') as f:
                return json.load(f)
        return []
    
    def update(self, hypothesis: ResearchHypothesis, evaluation: Dict[str, Any]):
        """æ›´æ–°çŸ¥è¯†åº“"""
        case = {
            "id": hypothesis.id,
            "title": hypothesis.title,
            "description": hypothesis.description,
            "category": hypothesis.category,
            "type": hypothesis.category,
            "status": hypothesis.status,
            "metrics": evaluation.get("metrics", {}),
            "success_rate": evaluation.get("metrics", {}).get("sharpe_ratio", 0),
            "created_at": hypothesis.created_at.isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        # æ›´æ–°æˆ–æ·»åŠ æ¡ˆä¾‹
        existing_index = next((i for i, c in enumerate(self.cases) 
                              if c["id"] == hypothesis.id), None)
        if existing_index is not None:
            self.cases[existing_index] = case
        else:
            self.cases.append(case)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_cases()
    
    def find_similar_cases(self, features: Dict[str, Any], n: int = 5) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹"""
        # ç®€åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
        valid_cases = [c for c in self.cases if c["status"] == "validated"]
        
        # æŒ‰æˆåŠŸç‡æ’åº
        valid_cases.sort(key=lambda c: c.get("success_rate", 0), reverse=True)
        
        return valid_cases[:n]
    
    def _save_cases(self):
        """ä¿å­˜æ¡ˆä¾‹"""
        cases_file = self.storage_path / "cases.json"
        with open(cases_file, 'w') as f:
            json.dump(self.cases, f, indent=2, default=str)
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_cases = len(self.cases)
        validated_cases = sum(1 for c in self.cases if c["status"] == "validated")
        
        stats = {
            "total_cases": total_cases,
            "validated_cases": validated_cases,
            "success_rate": validated_cases / total_cases if total_cases > 0 else 0,
            "by_category": {},
            "best_performers": []
        }
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        for category in ["factor", "strategy", "model"]:
            category_cases = [c for c in self.cases if c["category"] == category]
            stats["by_category"][category] = {
                "total": len(category_cases),
                "validated": sum(1 for c in category_cases if c["status"] == "validated")
            }
        
        # æœ€ä½³è¡¨ç°è€…
        validated = [c for c in self.cases if c["status"] == "validated"]
        validated.sort(key=lambda c: c.get("success_rate", 0), reverse=True)
        stats["best_performers"] = validated[:5]
        
        return stats


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        config = {
            "storage_path": "./rd_agent_knowledge"
        }
        
        rd_agent = RDAgent(config)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        dates = pd.date_range('2022-01-01', '2023-12-31')
        data = pd.DataFrame({
            'date': dates,
            'close': np.random.randn(len(dates)).cumsum() + 100,
            'volume': np.random.randint(1000000, 10000000, len(dates)),
            'returns': np.random.randn(len(dates)) * 0.02
        })
        
        # å‘ç°å› å­
        factors = await rd_agent.discover_factors(data, target="returns", n_factors=5)
        print(f"Discovered {len(factors)} factors")
        
        for factor in factors:
            print(f"- {factor.name}: IC={factor.performance.get('ic', 0):.4f}")
    
    # è¿è¡Œæµ‹è¯•
    # asyncio.run(test())