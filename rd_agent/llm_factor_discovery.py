#!/usr/bin/env python
"""
LLMé©±åŠ¨çš„æ¶¨åœæ¿å› å­è‡ªåŠ¨å‘ç°ç³»ç»Ÿ
ä½¿ç”¨ DeepSeek è‡ªåŠ¨ç”Ÿæˆå’Œè¯„ä¼°æ–°å› å­
Windows å®Œå…¨å…¼å®¹ï¼Œæ— éœ€ Docker
"""

import asyncio
import os
import json
import re
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import logging
import pandas as pd
import numpy as np
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# LLM å®¢æˆ·ç«¯
from openai import AsyncOpenAI

# ä»£ç æ²™ç›’ (P1-3)
from rd_agent.code_sandbox import execute_safe, SecurityLevel

logger = logging.getLogger(__name__)


class LLMFactorDiscovery:
    """
    LLMé©±åŠ¨çš„å› å­è‡ªåŠ¨å‘ç°ç³»ç»Ÿ
    
    åŠŸèƒ½ï¼š
    1. æ ¹æ®å¸‚åœºç‰¹å¾è‡ªåŠ¨ç”Ÿæˆæ–°å› å­
    2. ç”Ÿæˆå› å­çš„å¯æ‰§è¡Œä»£ç 
    3. è¯„ä¼°å› å­è´¨é‡
    4. æŒç»­è¿­ä»£ä¼˜åŒ–
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        model: str = "deepseek-chat",
        cache_dir: str = "./workspace/llm_factor_cache"
    ):
        """
        åˆå§‹åŒ– LLM å› å­å‘ç°ç³»ç»Ÿ
        
        Args:
            api_key: APIå¯†é’¥ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            api_base: APIåŸºç¡€URL
            model: ä½¿ç”¨çš„æ¨¡å‹
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.api_base = api_base or os.getenv("OPENAI_API_BASE", "https://api.deepseek.com")
        self.model = model
        
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼ˆå…¼å®¹ DeepSeekï¼‰
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.api_base
        )
        
        # ç¼“å­˜ç›®å½•
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # å› å­ç”Ÿæˆå†å²
        self.generation_history: List[Dict] = []
        
        logger.info(f"âœ… LLMå› å­å‘ç°ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"   æ¨¡å‹: {self.model}")
        logger.info(f"   API: {self.api_base}")
    
    async def discover_new_factors(
        self,
        n_factors: int = 5,
        focus_areas: Optional[List[str]] = None,
        context: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è‡ªåŠ¨å‘ç°æ–°å› å­
        
        Args:
            n_factors: è¦ç”Ÿæˆçš„å› å­æ•°é‡
            focus_areas: å…³æ³¨é¢†åŸŸ ['å°æ¿', 'è¿æ¿', 'é¢˜æ', 'èµ„é‡‘', 'æ—¶æœº']
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            æ–°å› å­åˆ—è¡¨
        """
        logger.info(f"ğŸ¤– å¼€å§‹LLMé©±åŠ¨å› å­å‘ç°ï¼Œç›®æ ‡ç”Ÿæˆ {n_factors} ä¸ªå› å­")
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_discovery_prompt(n_factors, focus_areas, context)
        
        # è°ƒç”¨ LLM
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.8,  # æé«˜åˆ›é€ æ€§
                max_tokens=4000
            )
            
            content = response.choices[0].message.content
            
            # è§£æå› å­
            factors = self._parse_factors_from_response(content)
            
            # éªŒè¯å’Œæ¸…ç†
            valid_factors = []
            for factor in factors:
                if self._validate_factor(factor):
                    valid_factors.append(factor)
            
            logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(valid_factors)} ä¸ªæœ‰æ•ˆå› å­")
            
            # ä¿å­˜åˆ°å†å²
            self._save_generation_history(prompt, content, valid_factors)
            
            return valid_factors
            
        except Exception as e:
            logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–å› å­ç ”ç©¶ä¸“å®¶ï¼Œä¸“æ³¨äºAè‚¡æ¶¨åœæ¿"ä¸€è¿›äºŒ"ç­–ç•¥ã€‚

ä½ çš„ä»»åŠ¡æ˜¯è®¾è®¡æ–°çš„é‡åŒ–å› å­æ¥é¢„æµ‹ï¼š
- ä»Šæ—¥æ¶¨åœçš„è‚¡ç¥¨ï¼Œæ˜æ—¥æ˜¯å¦ç»§ç»­æ¶¨åœï¼ˆä¸€è¿›äºŒï¼‰
- æ˜æ—¥çš„æ”¶ç›Šç‡å’Œæ¶¨å¹…

å…³é”®è€ƒè™‘å› ç´ ï¼š
1. å°æ¿è´¨é‡ï¼šå°å•å¼ºåº¦ã€å°æ¿æ—¶é—´ã€å¼€æ¿æ¬¡æ•°
2. è¿æ¿é«˜åº¦ï¼šé¦–æ¿ã€äºŒæ¿ã€ä¸‰æ¿ç­‰ä¸åŒé«˜åº¦çš„ç‰¹å¾
3. é¢˜æçƒ­åº¦ï¼šæ‰€å±æ¦‚å¿µã€æ¿å—è”åŠ¨ã€é¾™å¤´åœ°ä½
4. èµ„é‡‘è¡Œä¸ºï¼šå¤§å•æµå‘ã€æ¢æ‰‹ç‡ã€åˆ†æ—¶å½¢æ€
5. æ—¶æœºé€‰æ‹©ï¼šæ¶¨åœæ—¶é—´ã€ç«ä»·è¡¨ç°ã€å°¾ç›˜å¼ºåº¦

è¦æ±‚ï¼š
- å› å­å¿…é¡»å¯è®¡ç®—ã€å¯å®ç°
- æä¾›æ˜ç¡®çš„æ•°å­¦è¡¨è¾¾å¼
- ç»™å‡ºPythonä»£ç å®ç°
- è¯´æ˜å› å­çš„æŠ•èµ„é€»è¾‘
- ä¼°è®¡é¢„æœŸçš„ICå€¼ï¼ˆä¿¡æ¯ç³»æ•°ï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
```json
{
  "factors": [
    {
      "name": "å› å­åç§°",
      "expression": "æ•°å­¦è¡¨è¾¾å¼",
      "code": "Pythonä»£ç ",
      "category": "ç±»åˆ«",
      "logic": "æŠ•èµ„é€»è¾‘è¯´æ˜",
      "expected_ic": 0.XX,
      "data_requirements": ["å­—æ®µ1", "å­—æ®µ2"]
    }
  ]
}
```
"""
    
    def _build_discovery_prompt(
        self,
        n_factors: int,
        focus_areas: Optional[List[str]],
        context: Optional[str]
    ) -> str:
        """æ„å»ºå‘ç°æç¤ºè¯"""
        prompt = f"è¯·ä¸ºAè‚¡æ¶¨åœæ¿'ä¸€è¿›äºŒ'ç­–ç•¥è®¾è®¡ {n_factors} ä¸ªæ–°çš„é‡åŒ–å› å­ã€‚\n\n"
        
        if focus_areas:
            areas_text = "ã€".join(focus_areas)
            prompt += f"é‡ç‚¹å…³æ³¨ä»¥ä¸‹é¢†åŸŸï¼š{areas_text}\n\n"
        
        if context:
            prompt += f"é¢å¤–ä¸Šä¸‹æ–‡ï¼š{context}\n\n"
        
        prompt += """
è¦æ±‚ï¼š
1. å› å­è¦æœ‰åˆ›æ–°æ€§ï¼Œä¸æ˜¯ç®€å•çš„ä»·é‡æŒ‡æ ‡
2. å……åˆ†è€ƒè™‘æ¶¨åœæ¿çš„ç‰¹æ®Šæ€§ï¼ˆä»·æ ¼å°æ­»ã€æˆäº¤å—é™ï¼‰
3. ç»“åˆAè‚¡å¸‚åœºç‰¹ç‚¹ï¼ˆT+1ã€æ¶¨è·Œåœé™åˆ¶ã€æƒ…ç»ªé©±åŠ¨ï¼‰
4. æä¾›å®Œæ•´çš„å®ç°ä»£ç 
5. ä¼°è®¡åˆç†çš„ICå€¼ï¼ˆé€šå¸¸0.05-0.15ï¼‰

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºå› å­åˆ—è¡¨ã€‚
"""
        return prompt
    
    def _parse_factors_from_response(self, content: str) -> List[Dict[str, Any]]:
        """ä»LLMå“åº”ä¸­è§£æå› å­"""
        factors = []
        
        try:
            # å°è¯•æå–JSON
            json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                data = json.loads(json_str)
                factors = data.get('factors', [])
            else:
                # å°è¯•ç›´æ¥è§£æ
                json_match = re.search(r'\{.*"factors".*\}', content, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group(0))
                    factors = data.get('factors', [])
        
        except json.JSONDecodeError as e:
            logger.warning(f"JSONè§£æå¤±è´¥: {e}")
            # å°è¯•é€ä¸ªæå–å› å­
            factors = self._parse_factors_fallback(content)
        
        return factors
    
    def _parse_factors_fallback(self, content: str) -> List[Dict[str, Any]]:
        """å¤‡ç”¨è§£ææ–¹æ³•"""
        factors = []
        
        # æŒ‰æ®µè½åˆ†å‰²
        sections = content.split('\n\n')
        
        current_factor = {}
        for section in sections:
            section = section.strip()
            
            # è¯†åˆ«å› å­åç§°
            if 'å› å­åç§°' in section or 'name' in section.lower():
                if current_factor:
                    factors.append(current_factor)
                    current_factor = {}
                
                name_match = re.search(r'[:ï¼š](.*?)(?:\n|$)', section)
                if name_match:
                    current_factor['name'] = name_match.group(1).strip()
            
            # è¯†åˆ«å…¶ä»–å­—æ®µ
            if 'expression' in section.lower() or 'è¡¨è¾¾å¼' in section:
                expr_match = re.search(r'[:ï¼š](.*?)(?:\n|$)', section)
                if expr_match:
                    current_factor['expression'] = expr_match.group(1).strip()
            
            if 'code' in section.lower() or 'ä»£ç ' in section:
                code_match = re.search(r'```python\s*(.*?)\s*```', section, re.DOTALL)
                if code_match:
                    current_factor['code'] = code_match.group(1).strip()
        
        if current_factor:
            factors.append(current_factor)
        
        return factors
    
    def _validate_factor(self, factor: Dict[str, Any]) -> bool:
        """éªŒè¯å› å­æœ‰æ•ˆæ€§ (P1-3: å¢å¼ºå®‰å…¨æ£€æŸ¥)"""
        required_fields = ['name', 'expression', 'code']
        
        for field in required_fields:
            if field not in factor or not factor[field]:
                logger.warning(f"å› å­ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        # P1-3: ä½¿ç”¨ä»£ç æ²™ç›‘è¿›è¡Œå®‰å…¨éªŒè¯
        # è¿™é‡Œåªæ˜¯éªŒè¯ï¼Œä¸æ‰§è¡Œï¼Œæ‰€ä»¥åªåšè¯­æ³•æ£€æŸ¥
        code = factor.get('code', '')
        
        try:
            # è¯­æ³•æ£€æŸ¥
            compile(code, '<string>', 'exec')
        except SyntaxError as e:
            logger.warning(f"å› å­ä»£ç è¯­æ³•é”™è¯¯: {e}")
            return False
        
        # åŸºç¡€å…³é”®å­—æ£€æŸ¥ï¼ˆä½œä¸ºé¢å¤–çš„å¿«é€Ÿæ£€æŸ¥ï¼‰
        dangerous_keywords = ['import os', 'import sys', 'import subprocess', 
                             'exec(', 'eval(', '__import__', 'open(']
        
        for keyword in dangerous_keywords:
            if keyword in code:
                logger.warning(f"å› å­ä»£ç åŒ…å«å±é™©å…³é”®å­—: {keyword}")
                return False
        
        return True
    
    async def evaluate_factor(
        self,
        factor: Dict[str, Any],
        sample_data: Optional[pd.DataFrame] = None
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°å› å­è´¨é‡
        
        Args:
            factor: å› å­å®šä¹‰
            sample_data: æ ·æœ¬æ•°æ®ç”¨äºæµ‹è¯•
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        logger.info(f"ğŸ“Š è¯„ä¼°å› å­: {factor['name']}")
        
        evaluation = {
            'factor_name': factor['name'],
            'syntax_valid': False,
            'computable': False,
            'estimated_ic': factor.get('expected_ic', 0),
            'issues': []
        }
        
        # 1. è¯­æ³•æ£€æŸ¥
        try:
            compile(factor['code'], '<string>', 'exec')
            evaluation['syntax_valid'] = True
        except SyntaxError as e:
            evaluation['issues'].append(f"è¯­æ³•é”™è¯¯: {e}")
            logger.warning(f"å› å­è¯­æ³•é”™è¯¯: {e}")
        
        # 2. å¯è®¡ç®—æ€§æµ‹è¯• (P1-3: ä½¿ç”¨ä»£ç æ²™ç›’)
        if sample_data is not None and evaluation['syntax_valid']:
            try:
                # P1-3: ä½¿ç”¨ä»£ç æ²™ç›’æ‰§è¡Œ
                context = {
                    'np': np,
                    'pd': pd
                }
                
                # æ·»åŠ æ•°æ®åˆ—åˆ°ä¸Šä¸‹æ–‡
                for col in sample_data.columns:
                    context[col] = sample_data[col]
                
                # å®‰å…¨æ‰§è¡Œä»£ç 
                execution_result = execute_safe(
                    code=factor['code'],
                    context=context,
                    timeout=10
                )
                
                if execution_result.success:
                    evaluation['computable'] = True
                else:
                    evaluation['issues'].append(f"è®¡ç®—é”™è¯¯: {execution_result.error}")
                    logger.warning(f"å› å­è®¡ç®—é”™è¯¯: {execution_result.error}")
                
            except Exception as e:
                evaluation['issues'].append(f"è®¡ç®—é”™è¯¯: {e}")
                logger.warning(f"å› å­è®¡ç®—é”™è¯¯: {e}")
        
        # 3. LLM è´¨é‡è¯„ä¼°
        if evaluation['syntax_valid']:
            quality_score = await self._llm_quality_assessment(factor)
            evaluation['quality_score'] = quality_score
        
        return evaluation
    
    async def _llm_quality_assessment(self, factor: Dict[str, Any]) -> float:
        """ä½¿ç”¨LLMè¯„ä¼°å› å­è´¨é‡"""
        prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹æ¶¨åœæ¿å› å­çš„è´¨é‡ï¼ˆ0-10åˆ†ï¼‰ï¼š

å› å­åç§°: {factor['name']}
è¡¨è¾¾å¼: {factor['expression']}
æŠ•èµ„é€»è¾‘: {factor.get('logic', 'N/A')}

è¯„ä¼°æ ‡å‡†ï¼š
1. æŠ•èµ„é€»è¾‘æ˜¯å¦åˆç†ï¼ˆ3åˆ†ï¼‰
2. å®ç°æ˜¯å¦æ¸…æ™°ï¼ˆ2åˆ†ï¼‰
3. åˆ›æ–°æ€§ï¼ˆ2åˆ†ï¼‰
4. å¯è®¡ç®—æ€§ï¼ˆ2åˆ†ï¼‰
5. å®ç”¨ä»·å€¼ï¼ˆ1åˆ†ï¼‰

è¯·åªè¿”å›ä¸€ä¸ª0-10çš„æ•°å­—åˆ†æ•°ã€‚
"""
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            content = response.choices[0].message.content.strip()
            score = float(re.search(r'\d+\.?\d*', content).group())
            return min(max(score, 0), 10)  # é™åˆ¶åœ¨0-10
            
        except Exception as e:
            logger.warning(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return 5.0  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    async def refine_factor(
        self,
        factor: Dict[str, Any],
        feedback: str
    ) -> Dict[str, Any]:
        """
        æ ¹æ®åé¦ˆæ”¹è¿›å› å­
        
        Args:
            factor: åŸå§‹å› å­
            feedback: æ”¹è¿›å»ºè®®
            
        Returns:
            æ”¹è¿›åçš„å› å­
        """
        logger.info(f"ğŸ”„ æ”¹è¿›å› å­: {factor['name']}")
        
        prompt = f"""
è¯·æ”¹è¿›ä»¥ä¸‹æ¶¨åœæ¿å› å­ï¼š

åŸå› å­ï¼š
- åç§°: {factor['name']}
- è¡¨è¾¾å¼: {factor['expression']}
- ä»£ç : {factor['code']}

åé¦ˆæ„è§ï¼š
{feedback}

è¯·æä¾›æ”¹è¿›åçš„å› å­ï¼Œä»¥JSONæ ¼å¼è¾“å‡ºã€‚
"""
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            refined_factors = self._parse_factors_from_response(content)
            
            if refined_factors:
                return refined_factors[0]
            else:
                return factor
                
        except Exception as e:
            logger.error(f"å› å­æ”¹è¿›å¤±è´¥: {e}")
            return factor
    
    def _save_generation_history(
        self,
        prompt: str,
        response: str,
        factors: List[Dict[str, Any]]
    ):
        """ä¿å­˜ç”Ÿæˆå†å²"""
        history_entry = {
            'timestamp': datetime.now().isoformat(),
            'prompt': prompt,
            'response': response,
            'factors_generated': len(factors),
            'factors': factors
        }
        
        self.generation_history.append(history_entry)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        history_file = self.cache_dir / f"generation_history_{datetime.now():%Y%m%d_%H%M%S}.json"
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history_entry, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ç”Ÿæˆå†å²å·²ä¿å­˜: {history_file}")
    
    def export_factors(
        self,
        factors: List[Dict[str, Any]],
        output_file: Optional[str] = None
    ) -> str:
        """
        å¯¼å‡ºå› å­
        
        Args:
            factors: å› å­åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            output_file = self.cache_dir / f"factors_export_{datetime.now():%Y%m%d_%H%M%S}.json"
        
        export_data = {
            'export_time': datetime.now().isoformat(),
            'total_factors': len(factors),
            'factors': factors
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“¤ å› å­å·²å¯¼å‡º: {output_file}")
        return str(output_file)


# æ¼”ç¤ºä½¿ç”¨
async def demo():
    """æ¼”ç¤ºLLMé©±åŠ¨çš„å› å­å‘ç°"""
    print("=" * 70)
    print("LLMé©±åŠ¨æ¶¨åœæ¿å› å­è‡ªåŠ¨å‘ç°æ¼”ç¤º")
    print("=" * 70)
    
    # åˆ›å»ºå‘ç°ç³»ç»Ÿ
    discovery = LLMFactorDiscovery()
    
    # 1. è‡ªåŠ¨å‘ç°å› å­
    print("\nğŸ¤– æ­¥éª¤1: è‡ªåŠ¨å‘ç°æ–°å› å­...")
    factors = await discovery.discover_new_factors(
        n_factors=3,
        focus_areas=["å°æ¿å¼ºåº¦", "è¿æ¿åŠ¨é‡", "é¢˜æå…±æŒ¯"],
        context="é‡ç‚¹å…³æ³¨çŸ­çº¿å¼ºåŠ¿ç‰¹å¾"
    )
    
    print(f"\nâœ… å‘ç° {len(factors)} ä¸ªæ–°å› å­:")
    for i, factor in enumerate(factors, 1):
        print(f"\n--- å› å­ {i} ---")
        print(f"åç§°: {factor['name']}")
        print(f"è¡¨è¾¾å¼: {factor['expression']}")
        print(f"é€»è¾‘: {factor.get('logic', 'N/A')[:100]}...")
        if 'expected_ic' in factor:
            print(f"é¢„æœŸIC: {factor['expected_ic']:.4f}")
    
    # 2. è¯„ä¼°å› å­
    if factors:
        print(f"\nğŸ“Š æ­¥éª¤2: è¯„ä¼°å› å­è´¨é‡...")
        for factor in factors[:2]:  # è¯„ä¼°å‰2ä¸ª
            evaluation = await discovery.evaluate_factor(factor)
            print(f"\nå› å­: {factor['name']}")
            print(f"  è¯­æ³•æ­£ç¡®: {evaluation['syntax_valid']}")
            print(f"  å¯è®¡ç®—: {evaluation['computable']}")
            if 'quality_score' in evaluation:
                print(f"  è´¨é‡åˆ†æ•°: {evaluation['quality_score']:.1f}/10")
            if evaluation['issues']:
                print(f"  é—®é¢˜: {', '.join(evaluation['issues'])}")
    
    # 3. å¯¼å‡ºå› å­
    if factors:
        print(f"\nğŸ’¾ æ­¥éª¤3: å¯¼å‡ºå› å­...")
        export_path = discovery.export_factors(factors)
        print(f"å·²å¯¼å‡ºåˆ°: {export_path}")


if __name__ == '__main__':
    asyncio.run(demo())
