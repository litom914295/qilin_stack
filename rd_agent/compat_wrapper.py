"""
RD-Agentå…¼å®¹å±‚åŒ…è£…å™¨

ä»»åŠ¡: P0-1.5 + P0-1.6
åŠŸèƒ½: ä¿æŒåŸæœ‰RDAgent API,å†…éƒ¨è°ƒç”¨å®˜æ–¹RD-Agentç»„ä»¶
é›†æˆ: official_integration.py + research_agent.py (æ•°æ®ç±»å‹)
"""

import os
import sys
import logging
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import pandas as pd

# å¯¼å…¥å®˜æ–¹é›†æˆç®¡ç†å™¨
from .official_integration import (
    OfficialRDAgentManager,
    create_official_manager,
    OfficialIntegrationError,
    ConfigValidationError
)

# å¯¼å…¥è‡ªç ”æ•°æ®ç±»å‹(ä¿æŒå…¼å®¹)
from .research_agent import (
    ResearchHypothesis,
    FactorDefinition,
    StrategyTemplate
)

logger = logging.getLogger(__name__)


class ResultConversionError(Exception):
    """ç»“æœè½¬æ¢é”™è¯¯"""
    pass


class DataNotFoundError(Exception):
    """æ•°æ®æœªæ‰¾åˆ°é”™è¯¯"""
    pass


class _ConfigAdapter:
    """
    é…ç½®é€‚é…å™¨: Dict â†’ å®˜æ–¹é…ç½®
    
    èŒè´£: å°†è‡ªç ”çš„Dicté…ç½®è½¬æ¢ä¸ºå®˜æ–¹RD-Agentéœ€è¦çš„æ ¼å¼
    """
    
    @staticmethod
    def to_official_config(config: Dict[str, Any]) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºå®˜æ–¹é…ç½®æ ¼å¼
        
        Args:
            config: è‡ªç ”é…ç½®å­—å…¸
            
        Returns:
            å®˜æ–¹é…ç½®å­—å…¸
        """
        official_config = {}
        
        # LLMé…ç½®æ˜ å°„
        if "llm_model" in config:
            official_config["llm_model"] = config["llm_model"]
        elif "model" in config:
            official_config["llm_model"] = config["model"]
        
        if "llm_api_key" in config:
            official_config["llm_api_key"] = config["llm_api_key"]
        elif "api_key" in config:
            official_config["llm_api_key"] = config["api_key"]
        
        if "llm_provider" in config:
            official_config["llm_provider"] = config["llm_provider"]
        else:
            # æ ¹æ®modelæ¨æ–­provider
            model = official_config.get("llm_model", "")
            if "gpt" in model.lower():
                official_config["llm_provider"] = "openai"
            elif "claude" in model.lower():
                official_config["llm_provider"] = "anthropic"
        
        if "llm_base_url" in config:
            official_config["llm_base_url"] = config["llm_base_url"]
        
        if "llm_temperature" in config:
            official_config["llm_temperature"] = config["llm_temperature"]
        elif "temperature" in config:
            official_config["llm_temperature"] = config["temperature"]
        
        # æ‰§è¡Œé…ç½®æ˜ å°„
        if "max_iterations" in config:
            official_config["max_iterations"] = config["max_iterations"]
        
        # è·¯å¾„é…ç½®æ˜ å°„
        if "qlib_data_path" in config:
            official_config["qlib_data_path"] = config["qlib_data_path"]
        
        if "storage_path" in config:
            official_config["storage_path"] = config["storage_path"]
        
        return official_config
    
    @staticmethod
    def apply_to_environment(config: Dict[str, Any]):
        """
        åº”ç”¨é…ç½®åˆ°ç¯å¢ƒå˜é‡(å®˜æ–¹RD-Agentä»ç¯å¢ƒå˜é‡è¯»å–)
        
        Args:
            config: é…ç½®å­—å…¸
        """
        # LLMé…ç½®
        if "llm_provider" in config:
            os.environ["LLM_PROVIDER"] = config["llm_provider"]
        
        if "llm_model" in config:
            os.environ["LLM_MODEL"] = config["llm_model"]
        
        if "llm_api_key" in config:
            provider = config.get("llm_provider", "openai").lower()
            if provider == "openai":
                os.environ["OPENAI_API_KEY"] = config["llm_api_key"]
            elif provider == "anthropic":
                os.environ["ANTHROPIC_API_KEY"] = config["llm_api_key"]
        
        if "llm_base_url" in config:
            os.environ["OPENAI_BASE_URL"] = config["llm_base_url"]
        
        if "llm_temperature" in config:
            os.environ["LLM_TEMPERATURE"] = str(config["llm_temperature"])


class _ResultAdapter:
    """
    ç»“æœé€‚é…å™¨: å®˜æ–¹æ ¼å¼ â†’ è‡ªç ”æ ¼å¼
    
    èŒè´£: å°†å®˜æ–¹RD-Agentçš„Trace/Experimentè½¬æ¢ä¸ºè‡ªç ”çš„Dict/FactorDefinition
    """
    
    @staticmethod
    def trace_to_results_dict(trace, topic: str) -> Dict[str, Any]:
        """
        Trace â†’ research_pipelineè¿”å›çš„Dict
        
        Args:
            trace: å®˜æ–¹Traceå¯¹è±¡
            topic: ç ”ç©¶ä¸»é¢˜
            
        Returns:
            è‡ªç ”æ ¼å¼çš„ç»“æœå­—å…¸
        """
        results = {
            "topic": topic,
            "hypotheses": [],
            "factors": [],
            "strategies": [],
            "models": [],
            "best_solution": None
        }
        
        try:
            # è½¬æ¢æ‰€æœ‰å†å²å®éªŒ
            for exp, feedback in trace.hist:
                # è½¬æ¢ä¸ºResearchHypothesis
                hypo = ResearchHypothesis(
                    id=f"hypo_{id(exp)}",
                    title=str(exp.hypothesis.hypothesis)[:50] if hasattr(exp.hypothesis, 'hypothesis') else "Unknown",
                    description=str(exp.hypothesis.hypothesis) if hasattr(exp.hypothesis, 'hypothesis') else "",
                    category="factor",
                    confidence=0.8 if feedback.decision else 0.3,
                    created_at=datetime.now(),
                    status="validated" if feedback.decision else "rejected",
                    results={"decision": feedback.decision}
                )
                results["hypotheses"].append(hypo)
                
                # å¦‚æœå®éªŒæˆåŠŸ,è½¬æ¢ä¸ºFactor
                if feedback.decision and hasattr(exp, 'result') and exp.result is not None:
                    try:
                        factor = _ResultAdapter.exp_to_factor(exp)
                        results["factors"].append(factor)
                    except Exception as e:
                        logger.warning(f"Failed to convert experiment to factor: {e}")
            
            # é€‰æ‹©æœ€ä½³è§£å†³æ–¹æ¡ˆ
            if results["factors"]:
                best_factor = results["factors"][-1]  # SOTAæ˜¯æœ€åä¸€ä¸ª
                results["best_solution"] = {
                    "type": "factor",
                    "solution": best_factor,
                    "performance": best_factor.performance
                }
            
        except Exception as e:
            raise ResultConversionError(
                f"Failed to convert Trace to results dict: {e}"
            ) from e
        
        return results
    
    @staticmethod
    def exp_to_factor(exp) -> FactorDefinition:
        """
        Experiment â†’ FactorDefinition (å¢å¼ºé²æ£’æ€§ç‰ˆæœ¬)
        
        âœ… P0-4 ä¿®å¤:
        - é²æ£’åœ°è·å– workspace (å¤šè·¯å¾„å°è¯•)
        - å¤šæ–‡ä»¶åå€™é€‰ (factor.py/code.py/main.py/implementation.py)
        - å¤šæŒ‡æ ‡é”®åå°è¯• (IC/ic/information_coefficient)
        - å®Œæ•´çš„é”™è¯¯æ—¥å¿—
        
        Args:
            exp: å®˜æ–¹Experimentå¯¹è±¡
            
        Returns:
            è‡ªç ”FactorDefinitionå¯¹è±¡
        
        Raises:
            ResultConversionError: æ— æ³•æå–å¿…éœ€ä¿¡æ¯æ—¶
        """
        try:
            # ========== 1. é²æ£’åœ°è·å– workspace ==========
            workspace = None
            code_file_name = None
            
            # å°è¯•è·¯å¾„ 1: sub_workspace_list[0]
            if hasattr(exp, 'sub_workspace_list') and exp.sub_workspace_list:
                workspace = exp.sub_workspace_list[0]
                logger.debug("Workspace found via sub_workspace_list[0]")
            # å°è¯•è·¯å¾„ 2: workspace
            elif hasattr(exp, 'workspace') and exp.workspace is not None:
                workspace = exp.workspace
                logger.debug("Workspace found via workspace")
            # å°è¯•è·¯å¾„ 3: sub_workspace (å•æ•°å½¢å¼)
            elif hasattr(exp, 'sub_workspace') and exp.sub_workspace is not None:
                workspace = exp.sub_workspace
                logger.debug("Workspace found via sub_workspace")
            else:
                raise ResultConversionError(
                    "No workspace found in experiment. "
                    f"Available attributes: {dir(exp)}"
                )
            
            # ========== 2. å¤šæ–‡ä»¶åå€™é€‰æå–ä»£ç  ==========
            factor_code = ""
            file_candidates = ['factor.py', 'code.py', 'main.py', 'implementation.py', 'factor_code.py']
            
            file_dict = {}
            if hasattr(workspace, 'file_dict'):
                file_dict = workspace.file_dict
            elif hasattr(workspace, 'files'):
                file_dict = workspace.files
            elif isinstance(workspace, dict):
                file_dict = workspace.get('file_dict', workspace.get('files', {}))
            
            # å°è¯•æ¯ä¸ªå€™é€‰æ–‡ä»¶å
            for filename in file_candidates:
                if filename in file_dict:
                    factor_code = file_dict[filename]
                    code_file_name = filename
                    logger.debug(f"Factor code found in: {filename}")
                    break
            
            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°,å°è¯•è·å–ç¬¬ä¸€ä¸ª.pyæ–‡ä»¶
            if not factor_code:
                py_files = {k: v for k, v in file_dict.items() if k.endswith('.py')}
                if py_files:
                    code_file_name = list(py_files.keys())[0]
                    factor_code = py_files[code_file_name]
                    logger.warning(
                        f"Standard factor files not found. Using first .py file: {code_file_name}"
                    )
                else:
                    logger.error(
                        f"No factor code found. Available files: {list(file_dict.keys())}"
                    )
                    # ä¸æŠ›å‡ºå¼‚å¸¸,ä½¿ç”¨ç©ºä»£ç 
                    factor_code = "# Factor code not available"
                    code_file_name = "unknown.py"
            
            # ========== 3. å¤šæŒ‡æ ‡é”®åå°è¯•æå–æ€§èƒ½ ==========
            performance = {}
            
            if hasattr(exp, 'result') and exp.result is not None:
                result_data = exp.result
                
                # å¤„ç† DataFrame æ ¼å¼
                if isinstance(result_data, pd.DataFrame):
                    # æå– IC (å¤šé”®åå€™é€‰)
                    ic_keys = ['IC', 'ic', 'information_coefficient', 'IC_mean', 'ic_mean']
                    for key in ic_keys:
                        if key in result_data.index:
                            try:
                                performance["ic"] = float(result_data.loc[key].iloc[0])
                                logger.debug(f"IC found via key: {key}")
                                break
                            except (IndexError, ValueError, TypeError) as e:
                                logger.warning(f"Failed to extract IC from key '{key}': {e}")
                                continue
                    
                    # æå– IR (æ–°å¢)
                    ir_keys = ['IR', 'ir', 'information_ratio', 'IC_IR', 'ic_ir']
                    for key in ir_keys:
                        if key in result_data.index:
                            try:
                                performance["ir"] = float(result_data.loc[key].iloc[0])
                                logger.debug(f"IR found via key: {key}")
                                break
                            except (IndexError, ValueError, TypeError) as e:
                                logger.warning(f"Failed to extract IR from key '{key}': {e}")
                                continue
                    
                    # æå–å¹´åŒ–æ”¶ç›Š (å¤šé”®åå€™é€‰)
                    annual_return_keys = [
                        "1day.excess_return_with_cost.annualized_return",
                        "annualized_return",
                        "annual_return",
                        "excess_return_with_cost.annualized_return"
                    ]
                    for key in annual_return_keys:
                        if key in result_data.index:
                            try:
                                performance["annual_return"] = float(result_data.loc[key].iloc[0])
                                logger.debug(f"Annual return found via key: {key}")
                                break
                            except (IndexError, ValueError, TypeError) as e:
                                logger.warning(f"Failed to extract annual_return from key '{key}': {e}")
                                continue
                    
                    # æå–æœ€å¤§å›æ’¤ (å¤šé”®åå€™é€‰)
                    max_dd_keys = [
                        "1day.excess_return_with_cost.max_drawdown",
                        "max_drawdown",
                        "maximum_drawdown",
                        "excess_return_with_cost.max_drawdown"
                    ]
                    for key in max_dd_keys:
                        if key in result_data.index:
                            try:
                                performance["max_drawdown"] = float(result_data.loc[key].iloc[0])
                                logger.debug(f"Max drawdown found via key: {key}")
                                break
                            except (IndexError, ValueError, TypeError) as e:
                                logger.warning(f"Failed to extract max_drawdown from key '{key}': {e}")
                                continue
                    
                    # æ—¥å¿—æœªæ‰¾åˆ°çš„æŒ‡æ ‡
                    if not performance.get('ic'):
                        logger.warning(
                            f"IC not found. Available metrics: {list(result_data.index)}"
                        )
                
                # å¤„ç† dict æ ¼å¼
                elif isinstance(result_data, dict):
                    # ç›´æ¥å°è¯•ä» dict æå–
                    ic_keys = ['IC', 'ic', 'information_coefficient']
                    for key in ic_keys:
                        if key in result_data:
                            try:
                                performance["ic"] = float(result_data[key])
                                break
                            except (ValueError, TypeError):
                                continue
                    
                    ir_keys = ['IR', 'ir', 'information_ratio']
                    for key in ir_keys:
                        if key in result_data:
                            try:
                                performance["ir"] = float(result_data[key])
                                break
                            except (ValueError, TypeError):
                                continue
                    
                    if not performance.get('ic'):
                        logger.warning(
                            f"IC not found in dict. Available keys: {list(result_data.keys())}"
                        )
            
            # ========== 4. æå–å…ƒæ•°æ® ==========
            factor_name = f"factor_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            description = ""
            
            # å¤šè·¯å¾„å°è¯•æå– hypothesis
            if hasattr(exp, 'hypothesis'):
                hypo = exp.hypothesis
                if hasattr(hypo, 'hypothesis'):
                    description = str(hypo.hypothesis)
                elif hasattr(hypo, 'description'):
                    description = str(hypo.description)
                elif isinstance(hypo, str):
                    description = hypo
            
            # æå–ç‰ˆæœ¬ä¿¡æ¯ (æ–°å¢)
            version = "unknown"
            if hasattr(workspace, 'version'):
                version = str(workspace.version)
            elif isinstance(workspace, dict) and 'version' in workspace:
                version = str(workspace['version'])
            
            # ========== 5. åˆ›å»º FactorDefinition ==========
            factor = FactorDefinition(
                name=factor_name,
                expression=factor_code,
                description=description,
                category="auto_generated",
                parameters={
                    'code_file': code_file_name,
                    'version': version
                },
                performance=performance
            )
            
            logger.info(
                f"Successfully converted experiment to factor: {factor_name} "
                f"(IC={performance.get('ic', 'N/A')}, file={code_file_name})"
            )
            
            return factor
            
        except ResultConversionError:
            # ç›´æ¥é‡æ–°æŠ›å‡ºå·²çŸ¥é”™è¯¯
            raise
        except Exception as e:
            raise ResultConversionError(
                f"Failed to convert Experiment to FactorDefinition: {e}. "
                f"Experiment attributes: {dir(exp)}"
            ) from e
    
    @staticmethod
    def experiments_to_factors(trace, n_factors: int = 10) -> List[FactorDefinition]:
        """
        æå–å‰Nä¸ªæœ‰æ•ˆå› å­
        
        Args:
            trace: å®˜æ–¹Traceå¯¹è±¡
            n_factors: è¦æå–çš„å› å­æ•°é‡
            
        Returns:
            FactorDefinitionåˆ—è¡¨
        """
        factors = []
        
        try:
            for exp, feedback in trace.hist:
                if feedback.decision and hasattr(exp, 'result') and exp.result is not None:
                    try:
                        factor = _ResultAdapter.exp_to_factor(exp)
                        factors.append(factor)
                        if len(factors) >= n_factors:
                            break
                    except Exception as e:
                        logger.warning(f"Failed to convert experiment to factor: {e}")
                        continue
        except Exception as e:
            raise ResultConversionError(
                f"Failed to extract factors from experiments: {e}"
            ) from e
        
        return factors


class RDAgentWrapper:
    """
    RD-Agentå…¼å®¹å±‚åŒ…è£…å™¨
    
    èŒè´£:
    1. ä¿æŒåŸæœ‰RDAgentçš„APIä¸å˜
    2. å†…éƒ¨è°ƒç”¨å®˜æ–¹RD-Agentç»„ä»¶
    3. è½¬æ¢é…ç½®å’Œç»“æœæ ¼å¼
    4. æä¾›ä¸è‡ªç ”ç‰ˆæœ¬ç›¸åŒçš„è¡Œä¸º
    
    ä½¿ç”¨ç¤ºä¾‹:
        # åˆ›å»ºWrapper (ä¸åŸRDAgentç›¸åŒçš„API)
        config = {
            "llm_model": "gpt-4-turbo",
            "llm_api_key": "sk-xxx",
            "max_iterations": 10
        }
        agent = RDAgentWrapper(config)
        
        # ä½¿ç”¨åŸæœ‰API
        results = await agent.research_pipeline(
            research_topic="Aè‚¡åŠ¨é‡å› å­ç ”ç©¶",
            data=df,
            max_iterations=5
        )
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–RD-AgentåŒ…è£…å™¨
        
        Args:
            config: é…ç½®å­—å…¸ (ä¸åŸRDAgentç›¸åŒçš„æ ¼å¼)
        """
        self.config = config
        
        # è½¬æ¢é…ç½®
        official_config = _ConfigAdapter.to_official_config(config)
        
        # åº”ç”¨ç¯å¢ƒå˜é‡
        _ConfigAdapter.apply_to_environment(official_config)
        
        # åˆ›å»ºå®˜æ–¹ç®¡ç†å™¨
        try:
            self._official_manager = create_official_manager(official_config)
            logger.info("RDAgentWrapper initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize RDAgentWrapper: {e}")
            raise
        
        # Phase 1.1: åˆå§‹åŒ– FileStorage æ—¥å¿— (æ–°å¢)
        workspace_path = config.get('workspace_path', './logs/rdagent')
        try:
            from rd_agent.logging_integration import QilinRDAgentLogger
            self.qilin_logger = QilinRDAgentLogger(workspace_path)
            logger.info(f"âœ… FileStorage logging enabled at {workspace_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ FileStorage logging unavailable: {e}")
            self.qilin_logger = None
        
        # ä¿å­˜ç ”ç©¶å†å² (å…¼å®¹åŸAPI)
        self.research_history = []
    
    async def research_pipeline(self,
                               research_topic: str,
                               data: pd.DataFrame,
                               max_iterations: int = 10) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ç ”ç©¶æµç¨‹ (ä¿æŒåŸæœ‰APIç­¾å)
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            data: å†å²æ•°æ® (æš‚æœªä½¿ç”¨,å› ä¸ºå®˜æ–¹RD-Agentä½¿ç”¨Qlibæ•°æ®)
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Returns:
            ç ”ç©¶ç»“æœå­—å…¸ (ä¸åŸRDAgentç›¸åŒçš„æ ¼å¼)
        """
        logger.info(f"Starting research pipeline: {research_topic}")
        
        try:
            # 1. è·å–å®˜æ–¹FactorLoop
            factor_loop = self._official_manager.get_factor_loop()
            
            # 2. è¿è¡Œå®˜æ–¹å¾ªç¯
            logger.info(f"Running FactorRDLoop for {max_iterations} iterations...")
            await factor_loop.run(loop_n=max_iterations)
            
            # 3. è½¬æ¢ç»“æœæ ¼å¼
            results = _ResultAdapter.trace_to_results_dict(
                factor_loop.trace,
                topic=research_topic
            )
            
            # Phase 1.1: è®°å½•å®éªŒåˆ° FileStorage (æ–°å¢)
            if self.qilin_logger:
                try:
                    for exp, feedback in factor_loop.trace.hist:
                        if feedback.decision:  # åªè®°å½•è¢«é‡‡çº³çš„å®éªŒ
                            self.qilin_logger.log_experiment(exp, tag='limitup.factor')
                    
                    # è®°å½•æ±‡æ€»æŒ‡æ ‡
                    summary_metrics = {
                        'topic': research_topic,
                        'total_experiments': len(factor_loop.trace.hist),
                        'successful_factors': len(results['factors']),
                        'max_iterations': max_iterations
                    }
                    self.qilin_logger.log_metrics(summary_metrics, tag='limitup.summary')
                    logger.info("âœ… Logged experiments to FileStorage")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to log to FileStorage: {e}")
            
            # ä¿å­˜åˆ°å†å²
            self.research_history.append(results)
            
            logger.info(f"Research pipeline completed. Found {len(results['factors'])} factors.")
            return results
            
        except Exception as e:
            logger.error(f"Research pipeline failed: {e}")
            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸(ä¿æŒå…¼å®¹)
            return {
                "topic": research_topic,
                "hypotheses": [],
                "factors": [],
                "strategies": [],
                "models": [],
                "best_solution": None,
                "error": str(e)
            }
    
    async def discover_factors(self,
                              data: pd.DataFrame,
                              target: str = "returns",
                              n_factors: int = 10) -> List[FactorDefinition]:
        """
        è‡ªåŠ¨å‘ç°å› å­ (ä¿æŒåŸæœ‰APIç­¾å)
        
        Args:
            data: å†å²æ•°æ® (æš‚æœªä½¿ç”¨)
            target: ç›®æ ‡å˜é‡
            n_factors: è¦å‘ç°çš„å› å­æ•°é‡
            
        Returns:
            FactorDefinitionåˆ—è¡¨
        """
        logger.info(f"Discovering {n_factors} factors...")
        
        try:
            # 1. è·å–å®˜æ–¹FactorLoop
            factor_loop = self._official_manager.get_factor_loop()
            
            # 2. è¿è¡Œ1-2è½®å‘ç°æ–°å› å­
            await factor_loop.run(loop_n=2)
            
            # 3. æå–å› å­
            factors = _ResultAdapter.experiments_to_factors(
                factor_loop.trace,
                n_factors=n_factors
            )
            
            logger.info(f"Discovered {len(factors)} factors")
            return factors
            
        except Exception as e:
            logger.error(f"Factor discovery failed: {e}")
            return []
    
    async def optimize_strategy(self,
                               strategy: StrategyTemplate,
                               data: pd.DataFrame,
                               n_trials: int = 100) -> StrategyTemplate:
        """
        ä¼˜åŒ–ç­–ç•¥å‚æ•° (ä¿æŒåŸæœ‰APIç­¾å)
        
        æ³¨æ„: æš‚æ—¶ä¿ç•™è‡ªç ”å®ç°,å› ä¸ºå®˜æ–¹ModelLoopä¸»è¦ç”¨äºæ¨¡å‹ä¼˜åŒ–
        
        Args:
            strategy: ç­–ç•¥æ¨¡æ¿
            data: å†å²æ•°æ®
            n_trials: ä¼˜åŒ–è¯•éªŒæ¬¡æ•°
            
        Returns:
            ä¼˜åŒ–åçš„ç­–ç•¥
        """
        logger.warning(
            "optimize_strategy is not yet migrated to official RD-Agent. "
            "Consider using ModelRDLoop for model optimization."
        )
        
        # TODO: ç ”ç©¶å®˜æ–¹æ˜¯å¦æ”¯æŒç­–ç•¥ä¼˜åŒ–
        # æš‚æ—¶è¿”å›åŸç­–ç•¥
        return strategy
    
    def get_trace(self):
        """
        è·å–å®˜æ–¹Traceå¯¹è±¡ (æ–°å¢API,ç”¨äºé«˜çº§ç”¨æ³•)
        
        Returns:
            Traceå¯¹è±¡
        """
        return self._official_manager.get_trace()
    
    # Phase 1.2: ç¦»çº¿è¯»å–åŠŸèƒ½ (æ–°å¢)
    def load_historical_factors(self, workspace_path: str = None, n_factors: int = 10) -> List[FactorDefinition]:
        """
        ä»å†å²å®éªŒæ—¥å¿—åŠ è½½å› å­ (ç¦»çº¿æ¨¡å¼)
        
        Args:
            workspace_path: å·¥ä½œç›®å½•è·¯å¾„ (å¦‚æœä¸æä¾›,ä½¿ç”¨åˆå§‹åŒ–æ—¶çš„è·¯å¾„)
            n_factors: è¦åŠ è½½çš„å› å­æ•°é‡
            
        Returns:
            FactorDefinitionåˆ—è¡¨
            
        Example:
            # åŠ è½½å†å²å› å­
            factors = agent.load_historical_factors('./logs/rdagent', n_factors=10)
            for factor in factors:
                print(f'{factor.name}: IC={factor.performance["ic"]}')
        """
        if workspace_path is None:
            workspace_path = self.config.get('workspace_path', './logs/rdagent')
        
        logger.info(f"ğŸ“‚ Loading historical factors from {workspace_path}...")
        
        try:
            from rd_agent.logging_integration import QilinRDAgentLogger
            
            # åˆ›å»º logger
            hist_logger = QilinRDAgentLogger(workspace_path)
            factors = []
            
            # è¯»å–å†å²å®éªŒ
            for exp in hist_logger.iter_experiments(tag='limitup.factor'):
                try:
                    factor = _ResultAdapter.exp_to_factor(exp)
                    factors.append(factor)
                    if len(factors) >= n_factors:
                        break
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to convert experiment: {e}")
                    continue
            
            logger.info(f"âœ… Loaded {len(factors)} factors from FileStorage")
            return factors
            
        except Exception as e:
            logger.error(f"âŒ Failed to load from FileStorage: {e}")
            return []
    
    def load_historical_metrics(self, workspace_path: str = None) -> List[Dict[str, Any]]:
        """
        ä»å†å²æ—¥å¿—åŠ è½½æŒ‡æ ‡ (ç¦»çº¿æ¨¡å¼)
        
        Args:
            workspace_path: å·¥ä½œç›®å½•è·¯å¾„
            
        Returns:
            æŒ‡æ ‡åˆ—è¡¨
        """
        if workspace_path is None:
            workspace_path = self.config.get('workspace_path', './logs/rdagent')
        
        try:
            from rd_agent.logging_integration import QilinRDAgentLogger
            
            hist_logger = QilinRDAgentLogger(workspace_path)
            metrics_list = list(hist_logger.iter_metrics(tag='limitup.summary'))
            
            logger.info(f"âœ… Loaded {len(metrics_list)} metrics from FileStorage")
            return metrics_list
            
        except Exception as e:
            logger.error(f"âŒ Failed to load metrics: {e}")
            return []
    
    def load_factors_with_fallback(self, workspace_path: str = None, n_factors: int = 10) -> List[FactorDefinition]:
        """
        å¤šçº§å…œåº•çš„å› å­åŠ è½½
        
        å…œåº•ç­–ç•¥:
        1. FileStorage (pkl) - æœ€ä¼˜
        2. è¿è¡Œæ—¶ trace - å¤‡ç”¨
        3. trace.json - å…œåº•
        4. é”™è¯¯è¯Šæ–­ - å¤±è´¥å¤„ç†
        
        Args:
            workspace_path: å·¥ä½œç›®å½•è·¯å¾„
            n_factors: è¦åŠ è½½çš„å› å­æ•°é‡
            
        Returns:
            FactorDefinitionåˆ—è¡¨
            
        Raises:
            DataNotFoundError: æ‰€æœ‰æ•°æ®æºéƒ½ä¸å¯ç”¨æ—¶
            
        Example:
            # è‡ªåŠ¨å°è¯•å¤šç§æ•°æ®æº
            try:
                factors = agent.load_factors_with_fallback()
            except DataNotFoundError as e:
                print(f'æ— æ³•åŠ è½½å› å­: {e}')
        """
        if workspace_path is None:
            workspace_path = self.config.get('workspace_path', './logs/rdagent')
        
        logger.info(f"ğŸ”„ Loading factors with fallback strategy...")
        
        # 1. å°è¯•ä» FileStorage è¯»å– (æœ€ä¼˜)
        try:
            factors = self.load_historical_factors(workspace_path, n_factors)
            if factors:
                logger.info(f"âœ… Level 1: Loaded {len(factors)} factors from FileStorage")
                return factors
        except Exception as e:
            logger.warning(f"âš ï¸ Level 1 (FileStorage) unavailable: {e}")
        
        # 2. å°è¯•ä»è¿è¡Œæ—¶ trace è¯»å– (å¤‡ç”¨)
        try:
            trace = self._official_manager.get_trace()
            if trace and hasattr(trace, 'hist'):
                factors = _ResultAdapter.experiments_to_factors(trace, n_factors)
                if factors:
                    logger.info(f"âœ… Level 2: Loaded {len(factors)} factors from runtime trace")
                    return factors
        except Exception as e:
            logger.warning(f"âš ï¸ Level 2 (Runtime trace) unavailable: {e}")
        
        # 3. å°è¯•ä» trace.json è¯»å– (å…œåº•)
        try:
            from pathlib import Path
            import json
            
            trace_file = Path(workspace_path) / 'trace.json'
            if trace_file.exists():
                with open(trace_file, 'r') as f:
                    trace_data = json.load(f)
                
                # TODO: è§£æ trace.json æ ¼å¼
                logger.warning("âš ï¸ trace.json parsing not yet implemented")
        except Exception as e:
            logger.warning(f"âš ï¸ Level 3 (trace.json) unavailable: {e}")
        
        # 4. å¤±è´¥å¤„ç† + è¯Šæ–­å»ºè®®
        from pathlib import Path
        diagnostics = []
        diagnostics.append(f"Cannot load factors from {workspace_path}")
        diagnostics.append("\nDiagnostics:")
        
        # æ£€æŸ¥ FileStorage
        pkl_files = list(Path(workspace_path).glob('**/*.pkl'))
        diagnostics.append(f"- FileStorage: {len(pkl_files)} pkl files found")
        
        # æ£€æŸ¥è¿è¡Œæ—¶ trace
        trace = self._official_manager.get_trace()
        if trace and hasattr(trace, 'hist'):
            diagnostics.append(f"- Runtime trace: {len(trace.hist)} experiments found")
        else:
            diagnostics.append("- Runtime trace: Not available")
        
        # æ£€æŸ¥ trace.json
        trace_file = Path(workspace_path) / 'trace.json'
        diagnostics.append(f"- trace.json: {'Found' if trace_file.exists() else 'Not found'}")
        
        diagnostics.append("\nSuggestions:")
        diagnostics.append("1. Run a factor discovery experiment first")
        diagnostics.append("2. Check workspace_path is correct")
        diagnostics.append("3. Ensure experiments were logged to FileStorage")
        
        error_msg = "\n".join(diagnostics)
        logger.error(error_msg)
        
        raise DataNotFoundError(error_msg)
    
    def reset(self):
        """é‡ç½®æ‰€æœ‰çŠ¶æ€"""
        self._official_manager.reset()
        self.research_history = []
        logger.info("RDAgentWrapper reset")


# ä¸ºäº†å‘åå…¼å®¹,æä¾›åˆ«å
RDAgent = RDAgentWrapper


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    """
    æµ‹è¯•å…¼å®¹å±‚åŒ…è£…å™¨
    
    è¿è¡Œæ–¹å¼:
        python rd_agent/compat_wrapper.py
    """
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 60)
    print("æµ‹è¯•RD-Agentå…¼å®¹å±‚åŒ…è£…å™¨")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½® (ä½¿ç”¨åŸRDAgentçš„é…ç½®æ ¼å¼)
    test_config = {
        "llm_model": "gpt-4-turbo",
        # "llm_api_key": "sk-xxx",  # ä»ç¯å¢ƒå˜é‡è¯»å–
        "max_iterations": 2,
    }
    
    try:
        # 1. åˆ›å»ºWrapper
        print("\n1. åˆ›å»ºRDAgentWrapper...")
        agent = RDAgentWrapper(test_config)
        print("   âœ… æˆåŠŸ")
        
        # 2. æµ‹è¯•é…ç½®è½¬æ¢
        print("\n2. æµ‹è¯•é…ç½®è½¬æ¢...")
        official_config = _ConfigAdapter.to_official_config(test_config)
        print(f"   åŸé…ç½®: {test_config}")
        print(f"   å®˜æ–¹é…ç½®: {official_config}")
        print("   âœ… æˆåŠŸ")
        
        # 3. æµ‹è¯•è·å–Trace
        print("\n3. æµ‹è¯•è·å–Trace...")
        trace = agent.get_trace()
        print(f"   Trace: {trace}")
        print("   âœ… æˆåŠŸ")
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 60)
        print("\næ³¨æ„: å®Œæ•´æµ‹è¯•éœ€è¦åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡Œresearch_pipeline()")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
