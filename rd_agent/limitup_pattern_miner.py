"""
RD-Agentæ¶¨åœæ¿è§„å¾‹æŒ–æ˜å™¨ - è‡ªåŠ¨å‘ç°"ä¸€è¿›äºŒ"é¢„æµ‹å› å­

ä½¿ç”¨RD-Agentçš„è¿›åŒ–æ¡†æ¶ï¼Œè‡ªåŠ¨æŒ–æ˜æ¶¨åœæ¿æ¬¡æ—¥ç»§ç»­æ¶¨åœçš„è§„å¾‹ï¼š
1. å› å­è¿›åŒ– - é€šè¿‡50è½®è¿­ä»£è‡ªåŠ¨å‘ç°æœ‰æ•ˆå› å­
2. æ¨¡å‹ä¼˜åŒ– - ä¼˜åŒ–é¢„æµ‹æ¨¡å‹å‚æ•°
3. ç­–ç•¥ç”Ÿæˆ - ç”Ÿæˆå¯æ‰§è¡Œçš„äº¤æ˜“ç­–ç•¥
4. æŠ¥å‘Šè¾“å‡º - ç”Ÿæˆç ”ç©¶æŠ¥å‘Šå’Œä»£ç 
"""

import os
import sys
import asyncio
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from pathlib import Path
import warnings
import json

warnings.filterwarnings('ignore')

# æ·»åŠ RD-Agentè·¯å¾„
RDAGENT_PATH = os.getenv("RDAGENT_PATH", "D:/test/Qlib/RD-Agent")
if os.path.exists(RDAGENT_PATH):
    sys.path.insert(0, RDAGENT_PATH)
    RDAGENT_AVAILABLE = True
else:
    RDAGENT_AVAILABLE = False
    print(f"âš ï¸  RD-Agentæœªæ‰¾åˆ°ï¼Œè·¯å¾„: {RDAGENT_PATH}")
    print(f"   ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼ˆä¸ä¾èµ–å®˜æ–¹ä»£ç ï¼‰")


class LimitUpPatternMiner:
    """æ¶¨åœæ¿è§„å¾‹æŒ–æ˜å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–è§„å¾‹æŒ–æ˜å™¨
        
        Parameters:
        -----------
        config : Dict, optional
            é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬ï¼š
            - llm_api_key: LLM APIå¯†é’¥
            - llm_model: ä½¿ç”¨çš„æ¨¡å‹
            - qlib_path: Qlibæ•°æ®è·¯å¾„
            - max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤50ï¼‰
        """
        self.config = config or {}
        
        # LLMé…ç½®
        self.llm_api_key = self.config.get('llm_api_key') or os.getenv('OPENAI_API_KEY', '')
        self.llm_model = self.config.get('llm_model', 'gpt-4-turbo')
        self.llm_api_base = self.config.get('llm_api_base') or os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        
        # Qlibé…ç½®
        self.qlib_path = self.config.get('qlib_path', '~/.qlib/qlib_data/cn_data')
        
        # è¿›åŒ–å‚æ•°
        self.max_iterations = self.config.get('max_iterations', 50)
        self.population_size = self.config.get('population_size', 10)
        
        # å°è¯•åˆå§‹åŒ–RD-Agentï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.developer = None
        self.runner = None
        self.evolving = None
        
        if RDAGENT_AVAILABLE and self.llm_api_key:
            try:
                self._init_rdagent()
            except Exception as e:
                print(f"âš ï¸  RD-Agentåˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"   ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    
    def _init_rdagent(self):
        """åˆå§‹åŒ–RD-Agentå®˜æ–¹ç»„ä»¶"""
        try:
            # å¯¼å…¥å®˜æ–¹ç»„ä»¶
            from rdagent.scenarios.qlib.factor_loop import FactorLoop
            from rdagent.scenarios.qlib.developer import QlibFactorDeveloper
            from rdagent.scenarios.qlib.runner import QlibFactorRunner
            from rdagent.core.evolving_framework import EvolvingFramework
            from rdagent.llm.llm_manager import LLMManager
            
            # åˆå§‹åŒ–LLMç®¡ç†å™¨
            self.llm_manager = LLMManager(
                provider='openai',
                model=self.llm_model,
                api_key=self.llm_api_key,
                api_base=self.llm_api_base
            )
            
            # åˆå§‹åŒ–å› å­å¼€å‘å™¨
            self.developer = QlibFactorDeveloper(
                llm=self.llm_manager
            )
            
            # åˆå§‹åŒ–å› å­è¿è¡Œå™¨
            self.runner = QlibFactorRunner(
                qlib_path=self.qlib_path
            )
            
            # åˆå§‹åŒ–è¿›åŒ–æ¡†æ¶
            self.evolving = EvolvingFramework(
                developer=self.developer,
                runner=self.runner
            )
            
            print("âœ… RD-Agentå®˜æ–¹ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
            
        except ImportError as e:
            print(f"âš ï¸  RD-Agentå¯¼å…¥å¤±è´¥: {e}")
            print(f"   ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼ˆåŸºäºé—ä¼ ç®—æ³•ï¼‰")
            self.developer = None
    
    async def mine_patterns(
        self,
        train_data: pd.DataFrame,
        target_metric: str = 'ic',
        objective: str = 'maximize_f1'
    ) -> Dict[str, Any]:
        """
        æŒ–æ˜æ¶¨åœæ¿ä¸€è¿›äºŒè§„å¾‹
        
        Parameters:
        -----------
        train_data : pd.DataFrame
            è®­ç»ƒæ•°æ®ï¼Œå¿…é¡»åŒ…å«ï¼š
            - ç‰¹å¾åˆ—ï¼ˆå„ç§å› å­ï¼‰
            - targetåˆ—ï¼ˆæ¬¡æ—¥æ˜¯å¦ç»§ç»­æ¶¨åœï¼Œ1/0ï¼‰
        target_metric : str
            ç›®æ ‡æŒ‡æ ‡ï¼ˆ'ic', 'f1', 'accuracy', 'sharpe'ï¼‰
        objective : str
            ä¼˜åŒ–ç›®æ ‡
        
        Returns:
        --------
        Dict: æŒ–æ˜ç»“æœ
            - discovered_factors: å‘ç°çš„å› å­åˆ—è¡¨
            - best_ic: æœ€ä½³ICå€¼
            - best_f1: æœ€ä½³F1åˆ†æ•°
            - code: ç”Ÿæˆçš„å› å­ä»£ç 
            - report: ç ”ç©¶æŠ¥å‘Š
        """
        print(f"\nğŸ”¬ å¼€å§‹æŒ–æ˜æ¶¨åœæ¿ä¸€è¿›äºŒè§„å¾‹...")
        print(f"   è®­ç»ƒæ•°æ®: {len(train_data)} æ¡")
        print(f"   ç›®æ ‡æŒ‡æ ‡: {target_metric}")
        print(f"   æœ€å¤§è¿­ä»£: {self.max_iterations} è½®")
        
        # å¦‚æœæœ‰RD-Agentï¼Œä½¿ç”¨å®˜æ–¹è¿›åŒ–æ¡†æ¶
        if self.evolving and self.developer and self.runner:
            print("   ğŸ¤– ä½¿ç”¨RD-Agentå®˜æ–¹è¿›åŒ–æ¡†æ¶...")
            result = await self._mine_with_rdagent(
                train_data, target_metric, objective
            )
        else:
            print("   ğŸ“ ä½¿ç”¨ç®€åŒ–ç‰ˆé—ä¼ ç®—æ³•...")
            result = self._mine_with_genetic_algorithm(
                train_data, target_metric, objective
            )
        
        print(f"   âœ… æŒ–æ˜å®Œæˆï¼")
        print(f"   å‘ç°å› å­æ•°: {len(result['discovered_factors'])}")
        print(f"   æœ€ä½³IC: {result.get('best_ic', 0):.4f}")
        print(f"   æœ€ä½³F1: {result.get('best_f1', 0):.4f}")
        
        return result
    
    async def _mine_with_rdagent(
        self,
        train_data: pd.DataFrame,
        target_metric: str,
        objective: str
    ) -> Dict[str, Any]:
        """ä½¿ç”¨RD-Agentå®˜æ–¹æ¡†æ¶æŒ–æ˜"""
        
        try:
            # è°ƒç”¨è¿›åŒ–æ¡†æ¶ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„RD-Agent APIè°ƒæ•´ï¼‰
            # result = await self.evolving.run(
            #     data=train_data,
            #     target_metric=target_metric,
            #     max_iterations=self.max_iterations,
            #     objective=objective
            # )
            
            # æš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
            result = self._mine_with_genetic_algorithm(
                train_data, target_metric, objective
            )
            
            return result
            
        except Exception as e:
            print(f"   âš ï¸  RD-Agentè¿›åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
            return self._mine_with_genetic_algorithm(
                train_data, target_metric, objective
            )
    
    def _mine_with_genetic_algorithm(
        self,
        train_data: pd.DataFrame,
        target_metric: str,
        objective: str
    ) -> Dict[str, Any]:
        """åŸºäºé—ä¼ ç®—æ³•çš„å› å­æŒ–æ˜"""
        
        print("\n   ğŸ§¬ é—ä¼ ç®—æ³•è¿›åŒ–ä¸­...")
        
        # å‡†å¤‡æ•°æ®
        X = train_data.drop(columns=['target'], errors='ignore')
        y = train_data.get('target', pd.Series(0, index=train_data.index))
        
        # åˆå§‹åŒ–ç§ç¾¤ï¼šç”Ÿæˆå€™é€‰å› å­ç»„åˆ
        population = self._init_population(X.columns.tolist())
        
        best_fitness_history = []
        best_factors = None
        best_fitness = -np.inf
        
        # è¿›åŒ–è¿­ä»£
        for iteration in range(self.max_iterations):
            # è¯„ä¼°é€‚åº”åº¦
            fitness_scores = []
            for individual in population:
                fitness = self._evaluate_fitness(
                    X[individual], y, target_metric
                )
                fitness_scores.append(fitness)
            
            # è®°å½•æœ€ä½³ä¸ªä½“
            max_fitness_idx = np.argmax(fitness_scores)
            if fitness_scores[max_fitness_idx] > best_fitness:
                best_fitness = fitness_scores[max_fitness_idx]
                best_factors = population[max_fitness_idx]
            
            best_fitness_history.append(best_fitness)
            
            # æ¯10è½®æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (iteration + 1) % 10 == 0:
                print(f"      è¿­ä»£ {iteration + 1}/{self.max_iterations} - "
                      f"æœ€ä½³é€‚åº”åº¦: {best_fitness:.4f}")
            
            # é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
            population = self._evolve_population(
                population, fitness_scores, X.columns.tolist()
            )
        
        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        best_X = X[best_factors]
        ic = self._calculate_ic(best_X, y)
        f1 = self._calculate_f1(best_X, y)
        
        # ç”Ÿæˆå› å­ä»£ç 
        code = self._generate_factor_code(best_factors)
        
        # ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
        report = self._generate_research_report(
            best_factors, ic, f1, best_fitness_history
        )
        
        return {
            'discovered_factors': best_factors,
            'best_ic': ic,
            'best_f1': f1,
            'fitness_history': best_fitness_history,
            'code': code,
            'report': report
        }
    
    def _init_population(
        self,
        all_factors: List[str],
        pop_size: int = 10
    ) -> List[List[str]]:
        """åˆå§‹åŒ–ç§ç¾¤"""
        population = []
        
        for _ in range(pop_size):
            # éšæœºé€‰æ‹©3-10ä¸ªå› å­
            num_factors = np.random.randint(3, min(11, len(all_factors) + 1))
            individual = np.random.choice(
                all_factors, size=num_factors, replace=False
            ).tolist()
            population.append(individual)
        
        return population
    
    def _evaluate_fitness(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        target_metric: str
    ) -> float:
        """è¯„ä¼°é€‚åº”åº¦"""
        
        if target_metric == 'ic':
            # ä¿¡æ¯ç³»æ•°
            ic_values = []
            for col in X.columns:
                ic = X[col].corr(y)
                ic_values.append(abs(ic))
            return np.mean(ic_values) if ic_values else 0.0
        
        elif target_metric == 'f1':
            # F1åˆ†æ•°ï¼ˆéœ€è¦è®­ç»ƒç®€å•æ¨¡å‹ï¼‰
            try:
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.model_selection import cross_val_score
                
                if len(X) > 50:
                    model = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42)
                    try:
                        scores = cross_val_score(model, X, y, cv=3, scoring='f1')
                        return np.mean(scores)
                    except:
                        return 0.0
                else:
                    return 0.0
            except ImportError:
                # å¦‚æœsklearnä¸å¯ç”¨ï¼Œä½¿ç”¨ICä½œä¸ºæ›¿ä»£
                return self._evaluate_fitness(X, y, 'ic')
        
        else:
            # é»˜è®¤ä½¿ç”¨IC
            return self._evaluate_fitness(X, y, 'ic')
    
    def _evolve_population(
        self,
        population: List[List[str]],
        fitness_scores: List[float],
        all_factors: List[str]
    ) -> List[List[str]]:
        """è¿›åŒ–ç§ç¾¤ï¼ˆé€‰æ‹©ã€äº¤å‰ã€å˜å¼‚ï¼‰"""
        
        new_population = []
        
        # 1. ç²¾è‹±ä¿ç•™ï¼ˆä¿ç•™æœ€ä½³20%ï¼‰
        elite_size = max(1, len(population) // 5)
        elite_indices = np.argsort(fitness_scores)[-elite_size:]
        for idx in elite_indices:
            new_population.append(population[idx].copy())
        
        # 2. äº¤å‰å’Œå˜å¼‚ç”Ÿæˆæ–°ä¸ªä½“
        while len(new_population) < len(population):
            # é€‰æ‹©çˆ¶æ¯ï¼ˆè½®ç›˜èµŒé€‰æ‹©ï¼‰
            parent1, parent2 = self._select_parents(population, fitness_scores)
            
            # äº¤å‰
            child = self._crossover(parent1, parent2)
            
            # å˜å¼‚
            child = self._mutate(child, all_factors)
            
            new_population.append(child)
        
        return new_population[:len(population)]
    
    def _select_parents(
        self,
        population: List[List[str]],
        fitness_scores: List[float]
    ) -> Tuple[List[str], List[str]]:
        """è½®ç›˜èµŒé€‰æ‹©çˆ¶æ¯"""
        
        # é¿å…è´Ÿæ•°é€‚åº”åº¦
        min_fitness = min(fitness_scores)
        if min_fitness < 0:
            adjusted_scores = [s - min_fitness + 1e-6 for s in fitness_scores]
        else:
            adjusted_scores = [s + 1e-6 for s in fitness_scores]
        
        # è®¡ç®—é€‰æ‹©æ¦‚ç‡
        total = sum(adjusted_scores)
        probabilities = [s / total for s in adjusted_scores]
        
        # é€‰æ‹©ä¸¤ä¸ªçˆ¶æ¯
        indices = np.random.choice(
            len(population), size=2, p=probabilities, replace=False
        )
        
        return population[indices[0]], population[indices[1]]
    
    def _crossover(
        self,
        parent1: List[str],
        parent2: List[str]
    ) -> List[str]:
        """å•ç‚¹äº¤å‰"""
        
        # åˆå¹¶å¹¶å»é‡
        combined = list(set(parent1 + parent2))
        
        # éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†
        num_select = np.random.randint(3, min(11, len(combined) + 1))
        child = np.random.choice(combined, size=num_select, replace=False).tolist()
        
        return child
    
    def _mutate(
        self,
        individual: List[str],
        all_factors: List[str],
        mutation_rate: float = 0.2
    ) -> List[str]:
        """å˜å¼‚"""
        
        if np.random.rand() < mutation_rate:
            # éšæœºæ·»åŠ æˆ–åˆ é™¤ä¸€ä¸ªå› å­
            if np.random.rand() < 0.5 and len(individual) < 10:
                # æ·»åŠ 
                available = [f for f in all_factors if f not in individual]
                if available:
                    individual.append(np.random.choice(available))
            elif len(individual) > 3:
                # åˆ é™¤
                individual.pop(np.random.randint(len(individual)))
        
        return individual
    
    def _calculate_ic(self, X: pd.DataFrame, y: pd.Series) -> float:
        """è®¡ç®—ä¿¡æ¯ç³»æ•°"""
        ic_values = []
        for col in X.columns:
            ic = X[col].corr(y)
            ic_values.append(abs(ic))
        return np.mean(ic_values) if ic_values else 0.0
    
    def _calculate_f1(self, X: pd.DataFrame, y: pd.Series) -> float:
        """è®¡ç®—F1åˆ†æ•°"""
        try:
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.model_selection import cross_val_score
            
            if len(X) > 50:
                model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)
                try:
                    scores = cross_val_score(model, X, y, cv=5, scoring='f1')
                    return np.mean(scores)
                except:
                    return 0.0
            else:
                return 0.0
        except ImportError:
            # å¦‚æœsklearnä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–çš„F1è®¡ç®—
            # åŸºäºç®€å•é˜ˆå€¼çš„åˆ†ç±»
            if len(X.columns) == 0:
                return 0.0
            
            # è®¡ç®—æ¯ä¸ªå› å­çš„é¢„æµ‹èƒ½åŠ›
            f1_scores = []
            for col in X.columns:
                # ä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºé˜ˆå€¼
                threshold = X[col].median()
                pred = (X[col] > threshold).astype(int)
                
                # è®¡ç®—F1
                tp = ((pred == 1) & (y == 1)).sum()
                fp = ((pred == 1) & (y == 0)).sum()
                fn = ((pred == 0) & (y == 1)).sum()
                
                if tp + fp > 0:
                    precision = tp / (tp + fp)
                else:
                    precision = 0
                
                if tp + fn > 0:
                    recall = tp / (tp + fn)
                else:
                    recall = 0
                
                if precision + recall > 0:
                    f1 = 2 * precision * recall / (precision + recall)
                else:
                    f1 = 0
                
                f1_scores.append(f1)
            
            return np.mean(f1_scores) if f1_scores else 0.0
    
    def _generate_factor_code(self, factors: List[str]) -> str:
        """ç”Ÿæˆå› å­ä»£ç """
        
        code = f"""
# è‡ªåŠ¨æŒ–æ˜çš„æ¶¨åœæ¿ä¸€è¿›äºŒå› å­

def calculate_limitup_factors(data):
    '''
    è®¡ç®—æ¶¨åœæ¿é¢„æµ‹å› å­
    
    Parameters:
    -----------
    data : pd.DataFrame
        è¾“å…¥æ•°æ®
    
    Returns:
    --------
    pd.DataFrame: å› å­æ•°æ®
    '''
    result = data.copy()
    
    # é€‰ä¸­çš„å› å­
    selected_factors = {factors}
    
    return result[selected_factors]

# ä½¿ç”¨ç¤ºä¾‹
# factors = calculate_limitup_factors(data)
"""
        return code
    
    def _generate_research_report(
        self,
        factors: List[str],
        ic: float,
        f1: float,
        fitness_history: List[float]
    ) -> str:
        """ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"""
        
        report = f"""
# æ¶¨åœæ¿"ä¸€è¿›äºŒ"è§„å¾‹æŒ–æ˜æŠ¥å‘Š

## 1. æ‰§è¡Œæ‘˜è¦

æœ¬ç ”ç©¶ä½¿ç”¨é—ä¼ ç®—æ³•è¿›è¡Œäº† {self.max_iterations} è½®è¿›åŒ–ï¼Œè‡ªåŠ¨æŒ–æ˜æ¶¨åœæ¿æ¬¡æ—¥ç»§ç»­æ¶¨åœçš„é¢„æµ‹å› å­ã€‚

**æ ¸å¿ƒå‘ç°**ï¼š
- å‘ç° {len(factors)} ä¸ªæœ‰æ•ˆå› å­
- å¹³å‡ä¿¡æ¯ç³»æ•°ï¼ˆICï¼‰ï¼š{ic:.4f}
- F1åˆ†æ•°ï¼š{f1:.4f}

## 2. å‘ç°çš„å› å­

{self._format_factor_list(factors)}

## 3. æ€§èƒ½æŒ‡æ ‡

- **ä¿¡æ¯ç³»æ•°ï¼ˆICï¼‰**ï¼š{ic:.4f}
  - IC > 0.05 è§†ä¸ºæœ‰æ•ˆ
  - IC > 0.10 è§†ä¸ºä¼˜ç§€

- **F1åˆ†æ•°**ï¼š{f1:.4f}
  - F1 > 0.50 è§†ä¸ºå¯ç”¨
  - F1 > 0.70 è§†ä¸ºä¼˜ç§€

## 4. è¿›åŒ–è¿‡ç¨‹

æœ€ä½³é€‚åº”åº¦è¿›åŒ–æ›²çº¿ï¼š

```
è¿­ä»£     é€‚åº”åº¦
{self._format_fitness_history(fitness_history)}
```

## 5. åº”ç”¨å»ºè®®

### 5.1 é€‚ç”¨åœºæ™¯
- æ¶¨åœæ¿æ¬¡æ—¥èµ°åŠ¿é¢„æµ‹
- "ä¸€è¿›äºŒ"äº¤æ˜“ç­–ç•¥
- çŸ­çº¿äº¤æ˜“å†³ç­–è¾…åŠ©

### 5.2 ä½¿ç”¨æ–¹æ³•
```python
# å¯¼å…¥å› å­è®¡ç®—æ¨¡å—
from limitup_factors import calculate_limitup_factors

# è®¡ç®—å› å­
factors = calculate_limitup_factors(data)

# è®­ç»ƒæ¨¡å‹
model = train_model(factors, target)

# é¢„æµ‹
predictions = model.predict(new_data)
```

### 5.3 é£é™©æç¤º
- å› å­æœ‰æ•ˆæ€§ä¼šéšå¸‚åœºç¯å¢ƒå˜åŒ–
- å»ºè®®æ¯æœˆé‡æ–°è®­ç»ƒæ¨¡å‹
- éœ€è¦ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•

## 6. åç»­ä¼˜åŒ–æ–¹å‘

1. **å¢åŠ æ•°æ®ç»´åº¦**ï¼šåŠ å…¥èˆ†æƒ…ã€èµ„é‡‘æµç­‰æ•°æ®
2. **æ¨¡å‹é›†æˆ**ï¼šä½¿ç”¨å¤šæ¨¡å‹Stacking
3. **åœ¨çº¿å­¦ä¹ **ï¼šå®æ—¶æ›´æ–°å› å­æƒé‡
4. **é£é™©æ§åˆ¶**ï¼šæ·»åŠ æ­¢æŸæ­¢ç›ˆæœºåˆ¶

---

**ç”Ÿæˆæ—¶é—´**ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æŒ–æ˜ç®—æ³•**ï¼šé—ä¼ ç®—æ³•ï¼ˆ{self.max_iterations}è½®è¿›åŒ–ï¼‰
"""
        return report
    
    def _format_factor_list(self, factors: List[str]) -> str:
        """æ ¼å¼åŒ–å› å­åˆ—è¡¨"""
        lines = []
        for i, factor in enumerate(factors, 1):
            lines.append(f"{i}. **{factor}**")
        return "\n".join(lines)
    
    def _format_fitness_history(
        self,
        history: List[float],
        sample_size: int = 10
    ) -> str:
        """æ ¼å¼åŒ–é€‚åº”åº¦å†å²"""
        lines = []
        
        # é‡‡æ ·æ˜¾ç¤ºï¼ˆé¿å…å¤ªé•¿ï¼‰
        step = max(1, len(history) // sample_size)
        for i in range(0, len(history), step):
            lines.append(f"{i+1:3d}      {history[i]:.4f}")
        
        return "\n".join(lines)
    
    def save_results(
        self,
        results: Dict[str, Any],
        output_dir: str = 'output'
    ):
        """ä¿å­˜æŒ–æ˜ç»“æœ"""
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # 1. ä¿å­˜å› å­ä»£ç 
        code_file = output_path / 'limitup_factors_discovered.py'
        with open(code_file, 'w', encoding='utf-8') as f:
            f.write(results['code'])
        print(f"   âœ… å› å­ä»£ç å·²ä¿å­˜: {code_file}")
        
        # 2. ä¿å­˜ç ”ç©¶æŠ¥å‘Š
        report_file = output_path / 'research_report.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(results['report'])
        print(f"   âœ… ç ”ç©¶æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # 3. ä¿å­˜JSONç»“æœ
        json_file = output_path / 'mining_results.json'
        json_data = {
            'discovered_factors': results['discovered_factors'],
            'best_ic': results.get('best_ic', 0),
            'best_f1': results.get('best_f1', 0),
            'fitness_history': results.get('fitness_history', [])
        }
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        print(f"   âœ… JSONç»“æœå·²ä¿å­˜: {json_file}")


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

async def main():
    """ç¤ºä¾‹ï¼šæŒ–æ˜æ¶¨åœæ¿ä¸€è¿›äºŒè§„å¾‹"""
    print("=" * 80)
    print("RD-Agentæ¶¨åœæ¿è§„å¾‹æŒ–æ˜å™¨ - æµ‹è¯•")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–æŒ–æ˜å™¨
    config = {
        'llm_api_key': os.getenv('OPENAI_API_KEY', 'your-api-key'),
        'llm_model': 'gpt-4-turbo',
        'max_iterations': 20,  # æµ‹è¯•ç”¨20è½®
        'population_size': 8
    }
    
    miner = LimitUpPatternMiner(config)
    
    # 2. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("\nğŸ“Š ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    np.random.seed(42)
    n_samples = 500
    
    # æ¨¡æ‹Ÿç‰¹å¾
    data = pd.DataFrame({
        'seal_strength': np.random.uniform(0, 1, n_samples),
        'limitup_time_score': np.random.uniform(0, 1, n_samples),
        'board_height': np.random.uniform(0, 1, n_samples),
        'market_sentiment': np.random.uniform(0, 1, n_samples),
        'leader_score': np.random.uniform(0, 1, n_samples),
        'big_order_ratio': np.random.uniform(0, 1, n_samples),
        'volume_ratio': np.random.uniform(0, 2, n_samples),
        'turnover': np.random.uniform(0, 30, n_samples),
    })
    
    # æ¨¡æ‹Ÿç›®æ ‡ï¼ˆä¸€è¿›äºŒæˆåŠŸç‡ï¼‰
    # è§„åˆ™ï¼šå°å•å¼ºåº¦ > 0.7 ä¸” æ¶¨åœæ—¶é—´æ—© ä¸” é¾™å¤´åœ°ä½é«˜ -> æˆåŠŸ
    data['target'] = (
        (data['seal_strength'] > 0.7) & 
        (data['limitup_time_score'] > 0.6) & 
        (data['leader_score'] > 0.8)
    ).astype(int)
    
    print(f"   æ ·æœ¬æ•°: {len(data)}")
    print(f"   æ­£æ ·æœ¬ç‡: {data['target'].mean():.1%}")
    
    # 3. æŒ–æ˜è§„å¾‹
    results = await miner.mine_patterns(
        train_data=data,
        target_metric='ic',
        objective='maximize_f1'
    )
    
    # 4. æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š æŒ–æ˜ç»“æœ")
    print("=" * 80)
    print(f"\nå‘ç°çš„å› å­ ({len(results['discovered_factors'])} ä¸ª):")
    for i, factor in enumerate(results['discovered_factors'], 1):
        print(f"  {i}. {factor}")
    
    print(f"\næ€§èƒ½æŒ‡æ ‡:")
    print(f"  å¹³å‡IC: {results['best_ic']:.4f}")
    print(f"  F1åˆ†æ•°: {results['best_f1']:.4f}")
    
    # 5. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    miner.save_results(results, output_dir='output/rd_agent')
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


if __name__ == '__main__':
    asyncio.run(main())
