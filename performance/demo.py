"""
æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º - å±•ç¤ºå¹¶å‘å’Œç¼“å­˜çš„æ•ˆæœ
"""
import asyncio
import time
import sys
import os
import logging

logger = logging.getLogger(__name__)

sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from performance.concurrency import get_optimizer, parallel_task
from performance.cache import get_cache, cached


# ============================================================================
# æ¼”ç¤º1: å¹¶å‘ä¼˜åŒ–
# ============================================================================

async def demo_concurrency():
    """æ¼”ç¤ºå¹¶å‘ä¼˜åŒ–"""
    logger.info("=" * 70)
    logger.info("ğŸš€ æ¼”ç¤º1: å¹¶å‘ä¼˜åŒ–")
    logger.info("=" * 70)
    
    optimizer = get_optimizer()
    
    # æ¨¡æ‹Ÿè€—æ—¶ä»»åŠ¡
    async def slow_task(n: int):
        await asyncio.sleep(0.1)  # æ¨¡æ‹ŸIO
        return f"ä»»åŠ¡{n}å®Œæˆ"
    
    # æµ‹è¯•æ•°æ®
    num_tasks = 10
    
    # 1. ä¸²è¡Œæ‰§è¡Œ
    logger.info(f"ğŸ“Š ä¸²è¡Œæ‰§è¡Œ {num_tasks} ä¸ªä»»åŠ¡:")
    start = time.time()
    results_seq = []
    for i in range(num_tasks):
        result = await slow_task(i)
        results_seq.append(result)
    time_seq = time.time() - start
    logger.info(f"  è€—æ—¶: {time_seq:.3f}ç§’")
    
    # 2. å¹¶è¡Œæ‰§è¡Œ
    logger.info(f"ğŸ“Š å¹¶è¡Œæ‰§è¡Œ {num_tasks} ä¸ªä»»åŠ¡:")
    start = time.time()
    tasks = [slow_task(i) for i in range(num_tasks)]
    results_par = await optimizer.gather_parallel(*tasks)
    time_par = time.time() - start
    logger.info(f"  è€—æ—¶: {time_par:.3f}ç§’")
    
    # å¯¹æ¯”
    speedup = time_seq / time_par
    logger.info(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    logger.info(f"â±ï¸  èŠ‚çœæ—¶é—´: {(time_seq - time_par):.3f}ç§’")
    
    # æ¸…ç†
    optimizer.cleanup()


# ============================================================================
# æ¼”ç¤º2: ç¼“å­˜ä¼˜åŒ–
# ============================================================================

async def demo_cache():
    """æ¼”ç¤ºç¼“å­˜ä¼˜åŒ–"""
    logger.info("=" * 70)
    logger.info("ğŸ’¾ æ¼”ç¤º2: ç¼“å­˜ä¼˜åŒ–")
    logger.info("=" * 70)
    
    cache = get_cache()
    
    # æ¨¡æ‹Ÿæ˜‚è´µè®¡ç®—
    call_count = {'count': 0}
    
    async def expensive_calculation(x: int) -> int:
        """æ¨¡æ‹Ÿæ˜‚è´µè®¡ç®—"""
        call_count['count'] += 1
        await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿè®¡ç®—
        return x * x
    
    # æµ‹è¯•ç›¸åŒè¾“å…¥
    test_value = 42
    
    # 1. æ— ç¼“å­˜ - å¤šæ¬¡è°ƒç”¨
    logger.info("ğŸ“Š æ— ç¼“å­˜ - è°ƒç”¨3æ¬¡:")
    call_count['count'] = 0
    start = time.time()
    for _ in range(3):
        result = await expensive_calculation(test_value)
    time_no_cache = time.time() - start
    logger.info(f"  è€—æ—¶: {time_no_cache:.3f}ç§’")
    logger.info(f"  å®é™…è®¡ç®—æ¬¡æ•°: {call_count['count']}")
    
    # 2. æœ‰ç¼“å­˜ - å¤šæ¬¡è°ƒç”¨
    logger.info("ğŸ“Š æœ‰ç¼“å­˜ - è°ƒç”¨3æ¬¡:")
    
    # ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨
    @cached(ttl=300, key_prefix="expensive")
    async def expensive_calculation_cached(x: int) -> int:
        call_count['count'] += 1
        await asyncio.sleep(0.2)
        return x * x
    
    call_count['count'] = 0
    start = time.time()
    for _ in range(3):
        result = await expensive_calculation_cached(test_value)
    time_with_cache = time.time() - start
    logger.info(f"  è€—æ—¶: {time_with_cache:.3f}ç§’")
    logger.info(f"  å®é™…è®¡ç®—æ¬¡æ•°: {call_count['count']}")
    
    # å¯¹æ¯”
    speedup = time_no_cache / time_with_cache
    logger.info(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    logger.info(f"â±ï¸  èŠ‚çœæ—¶é—´: {(time_no_cache - time_with_cache):.3f}ç§’")
    
    # ç¼“å­˜å‘½ä¸­ç‡
    hit_rate = (3 - call_count['count']) / 3 * 100
    logger.info(f"ğŸ“Š ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.0f}%")


# ============================================================================
# æ¼”ç¤º3: ç»¼åˆä¼˜åŒ–
# ============================================================================

async def demo_combined():
    """æ¼”ç¤ºå¹¶å‘+ç¼“å­˜ç»„åˆä¼˜åŒ–"""
    logger.info("=" * 70)
    logger.info("ğŸ¯ æ¼”ç¤º3: å¹¶å‘ + ç¼“å­˜ç»„åˆä¼˜åŒ–")
    logger.info("=" * 70)
    
    optimizer = get_optimizer()
    
    # æ¨¡æ‹Ÿæ•°æ®è·å–
    @cached(ttl=300, key_prefix="data")
    async def fetch_data(symbol: str) -> dict:
        """è·å–æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œIO
        return {
            'symbol': symbol,
            'price': 100.0,
            'volume': 10000
        }
    
    symbols = ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000001.SZ']
    
    # 1. ä¸²è¡Œ + æ— ç¼“å­˜
    logger.info("ğŸ“Š ä¸²è¡Œæ¨¡å¼ï¼ˆæ— ç¼“å­˜ï¼‰ï¼š")
    # æ¸…ç©ºç¼“å­˜
    from performance.cache import get_cache
    get_cache().clear_all()
    
    start = time.time()
    results = []
    for symbol in symbols:
        result = await fetch_data(symbol)
        results.append(result)
    time_seq_no_cache = time.time() - start
    logger.info(f"  è€—æ—¶: {time_seq_no_cache:.3f}ç§’")
    
    # 2. å¹¶è¡Œ + ç¼“å­˜ï¼ˆç¬¬äºŒæ¬¡è¿è¡Œï¼Œæœ‰ç¼“å­˜ï¼‰
    logger.info("ğŸ“Š å¹¶è¡Œæ¨¡å¼ï¼ˆæœ‰ç¼“å­˜ï¼‰ï¼š")
    start = time.time()
    tasks = [fetch_data(symbol) for symbol in symbols]
    results = await optimizer.gather_parallel(*tasks)
    time_par_cache = time.time() - start
    logger.info(f"  è€—æ—¶: {time_par_cache:.3f}ç§’")
    
    # å¯¹æ¯”
    speedup = time_seq_no_cache / time_par_cache
    logger.info(f"âš¡ æ€»åŠ é€Ÿæ¯”: {speedup:.2f}x")
    logger.info(f"â±ï¸  æ€»èŠ‚çœæ—¶é—´: {(time_seq_no_cache - time_par_cache):.3f}ç§’")
    
    # æ¸…ç†
    optimizer.cleanup()


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

async def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    logger.info("ğŸ¬ " * 17)
    logger.info("Qilin Stack æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º")
    logger.info("ğŸ¬ " * 17)
    
    await demo_concurrency()
    await demo_cache()
    await demo_combined()
    
    logger.info("=" * 70)
    logger.info("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ")
    logger.info("=" * 70)


if __name__ == '__main__':
    asyncio.run(main())
