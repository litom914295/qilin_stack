# Qlib Model Zoo 快速使用指南

**版本**: Phase 5.1  
**更新日期**: 2024年

---

## 📚 目录

1. [简介](#简介)
2. [访问Model Zoo](#访问model-zoo)
3. [模型选择](#模型选择)
4. [参数配置](#参数配置)
5. [开始训练](#开始训练)
6. [结果解读](#结果解读)
7. [常见问题](#常见问题)

---

## 简介

Qlib Model Zoo提供了12个量化模型的统一训练界面，涵盖GBDT、神经网络、高级模型和集成学习四大类别。通过可视化的配置向导，您可以轻松训练和评估各种量化模型。

### 支持的模型

| 类别 | 模型 | 数量 |
|------|------|------|
| 🌲 GBDT | LightGBM, XGBoost, CatBoost | 3 |
| 🧠 神经网络 | MLP, LSTM, GRU, ALSTM | 4 |
| 🚀 高级模型 | Transformer, TRA, TCN, HIST | 4 |
| 🎯 集成学习 | DoubleEnsemble | 1 |

---

## 访问Model Zoo

### 步骤1: 启动Web界面

```bash
cd G:/test/qilin_stack
streamlit run web/unified_dashboard.py
```

### 步骤2: 导航到Model Zoo

1. 点击顶部导航栏的 **"📦 Qlib"**
2. 选择 **"📈 模型训练"** 标签
3. 点击 **"🗂️ 模型库"** 子标签

你将看到Model Zoo主界面，包含：
- 📊 顶部统计面板（显示12个模型概况）
- 🗂️ 左侧模型导航树（按类别组织）
- ⚙️ 右侧配置面板（参数配置和训练控制）

---

## 模型选择

### 左侧导航树

模型按4个类别组织，点击类别名称可展开/折叠：

```
📂 GBDT
  ├─ LightGBM ✅ [existing]
  ├─ XGBoost 🆕 [new]
  └─ CatBoost 🆕 [new]

📂 Neural Networks
  ├─ MLP 🆕 [new]
  ├─ LSTM 🆕 [new]
  ├─ GRU 🆕 [new]
  └─ ALSTM 🆕 [new]

📂 Advanced
  ├─ Transformer 🆕 [new]
  ├─ TRA 🆕 [new]
  ├─ TCN 🆕 [new]
  └─ HIST 🆕 [new]

📂 Ensemble
  └─ DoubleEnsemble 🆕 [new]
```

### 选择模型

点击任意模型名称，右侧配置面板将显示该模型的详细信息和参数配置。

**推荐首次使用：LightGBM** ✅
- 完整实现，训练稳定
- 速度快，资源占用低
- 适合初学者

---

## 参数配置

右侧配置面板分为三个部分：

### 1️⃣ 模型参数配置

根据选择的模型，界面会自动生成参数表单。

#### LightGBM参数示例

| 参数 | 类型 | 默认值 | 范围 | 说明 |
|------|------|--------|------|------|
| `learning_rate` | 数值 | 0.1 | 0.001-0.3 | 学习率，控制模型更新步长 |
| `n_estimators` | 数值 | 100 | 50-500 | 树的数量 |
| `max_depth` | 数值 | 6 | 3-15 | 树的最大深度 |
| `num_leaves` | 数值 | 31 | 10-100 | 叶子节点数量 |
| `min_child_samples` | 数值 | 20 | 5-100 | 叶子节点最小样本数 |

**参数调优建议**:
- **learning_rate**: 越小训练越慢但可能效果更好，建议0.05-0.1
- **n_estimators**: 与learning_rate配合，lr小则trees多
- **max_depth**: 过大容易过拟合，建议6-10
- **num_leaves**: 控制模型复杂度，建议31-63
- **min_child_samples**: 防止过拟合，建议20-50

### 2️⃣ 数据集配置

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| **训练开始日期** | 2018-01-01 | 训练集起始日期 |
| **训练结束日期** | 2020-12-31 | 训练集结束日期 |
| **测试开始日期** | 2021-01-01 | 验证集起始日期 |
| **测试结束日期** | 2021-12-31 | 验证集结束日期 |
| **股票池** | csi300 | 可选: csi300, csi500, all |

**数据集划分建议**:
- 训练集: 2-3年数据 (如2018-2020)
- 验证集: 6-12个月数据 (如2021)
- 避免使用过近的历史数据作为训练集

### 3️⃣ 训练配置

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| **保存模型** | ✅ 勾选 | 是否保存训练好的模型 |
| **模型名称** | LightGBM_20241215 | 自定义模型保存名称 |
| **使用GPU** | ❌ 未勾选 | GPU加速（当前暂未启用） |
| **并行任务数** | 4 | CPU并行数，建议4-8 |

---

## 开始训练

### 步骤1: 检查配置

确认所有参数配置正确：
- ✅ 模型参数在合理范围
- ✅ 数据集日期范围有效
- ✅ 训练配置符合需求

### 步骤2: 点击训练按钮

点击蓝色的 **"🚀 开始训练"** 按钮

### 步骤3: 观察训练进度

界面将显示实时训练进度：

```
📈 训练进度
━━━━━━━━━━━━━━━━━━━━━━━━━━ 45% 

当前状态: 正在训练模型...

📋 训练日志 [展开]
✅ 开始训练 LightGBM 模型...
{
  "模型": "LightGBM",
  "参数": {...},
  "配置": {...}
}
📝 正在初始化训练器...
📝 正在准备数据集...
📝 数据集准备完成，开始训练...
📝 数据加载完成，训练集: 156832, 验证集: 52443
📝 模型实例创建成功: LightGBM
📝 正在训练模型...
```

### 步骤4: 等待训练完成

- **快速模式** (小数据集): 30秒 - 2分钟
- **标准模式** (CSI300): 2-5分钟
- **完整模式** (CSI500/All): 5-15分钟

训练完成后将显示 **"✅ LightGBM 训练完成!"** 并播放庆祝动画 🎈

---

## 结果解读

训练完成后，界面会显示详细的评估结果：

### 📊 主要指标 (4列)

| 指标 | 含义 | 优秀范围 | 示例值 |
|------|------|----------|--------|
| **IC** | Information Coefficient, 预测值与真实值的相关系数 | > 0.05 | 0.0523 |
| **Rank IC** | Spearman秩相关系数 | > 0.05 | 0.0614 |
| **ICIR** | IC信息比率, IC的稳定性指标 | > 0.5 | 0.7234 |
| **训练时长** | 模型训练耗时 | - | 132.5秒 |

#### 指标解读

**IC (Information Coefficient)**
- **> 0.05**: 优秀，模型有显著预测能力
- **0.03 - 0.05**: 良好，可以考虑使用
- **0.01 - 0.03**: 一般，需要优化
- **< 0.01**: 较差，建议重新设计特征或更换模型

**Rank IC**
- 类似IC，但更关注排序能力
- 通常Rank IC > IC表示模型善于抓住相对强弱

**ICIR**
- IC的稳定性指标
- **> 1.0**: 非常稳定
- **0.5 - 1.0**: 较稳定
- **< 0.5**: 不稳定，可能存在过拟合

### 📈 详细指标 (2列)

| 指标 | 含义 | 说明 |
|------|------|------|
| **MSE** | 均方误差 | 越小越好，衡量预测误差 |
| **MAE** | 平均绝对误差 | 越小越好，对异常值不敏感 |
| **训练样本数** | 训练集样本数 | 如: 156,832 |
| **验证样本数** | 验证集样本数 | 如: 52,443 |

### 💾 模型保存信息

如果勾选了"保存模型"，界面会显示：

```
💾 模型已保存至: `G:\test\qilin_stack\outputs\model_zoo\LightGBM_20241215_143052.pkl`
```

模型文件包括：
- **模型文件**: `LightGBM_20241215_143052.pkl` (Pickle格式)
- **元数据文件**: `LightGBM_20241215_143052_meta.json` (包含配置和指标)

---

## 常见问题

### Q1: 为什么选择非LightGBM模型时出现警告？

**A**: 当前Phase 5.1仅完整实现了LightGBM模型。其他11个模型会使用LightGBM作为placeholder，并显示警告信息。这些模型将在后续版本中逐步实现。

**建议**: 使用LightGBM进行训练，效果稳定可靠。

---

### Q2: IC值为负数是否正常？

**A**: 不正常。负IC表示模型预测方向与实际相反，可能原因：
1. 特征工程问题（标签定义错误）
2. 数据泄露（使用了未来数据）
3. 模型参数设置不当

**解决方案**:
- 检查数据集配置
- 调整模型参数（降低学习率，增加正则化）
- 使用默认参数重新训练

---

### Q3: 训练时间过长怎么办？

**A**: 训练时间取决于数据规模和模型复杂度。

**优化方法**:
1. 减少训练集时间范围（如1-2年）
2. 使用较小的股票池（csi300代替csi500）
3. 减少树的数量（n_estimators = 50-100）
4. 降低树的深度（max_depth = 4-6）
5. 增加并行任务数（n_jobs = 8）

---

### Q4: 如何加载已保存的模型？

**A**: 当前版本暂不支持直接从界面加载模型。可以通过Python代码加载：

```python
import pickle

# 加载模型
with open('outputs/model_zoo/LightGBM_20241215_143052.pkl', 'rb') as f:
    model = pickle.load(f)

# 使用模型预测
predictions = model.predict(test_data)
```

模型加载功能将在Phase 6中添加到界面。

---

### Q5: 如何比较多个模型的性能？

**A**: 当前版本支持单模型训练。多模型对比功能计划在Phase 6.4实现。

**临时方案**:
1. 分别训练多个模型
2. 记录每个模型的IC、Rank IC、ICIR指标
3. 手动对比性能

---

### Q6: GPU加速何时可用？

**A**: GPU加速功能计划在Phase 7实现，需要：
- 安装PyTorch和CUDA
- 实现深度学习模型（MLP, LSTM, GRU等）

当前GBDT模型（LightGBM, XGBoost, CatBoost）主要依赖CPU计算，GPU加速效果有限。

---

### Q7: 如何自定义特征？

**A**: 当前使用Qlib Alpha158默认特征（158个技术指标）。自定义特征功能计划在Phase 6.1实现。

**临时方案**:
修改 `qlib_enhanced/model_zoo/model_trainer.py` 中的 `prepare_dataset` 方法，自定义features列表。

---

### Q8: 训练失败如何排查？

**A**: 点击"📋 训练日志"查看详细错误信息。

**常见错误**:
1. **Qlib数据未初始化**: 运行 `python scripts/qlib_init.py` 初始化数据
2. **日期范围无效**: 确保训练日期在数据范围内
3. **内存不足**: 减少数据规模或增加系统内存
4. **依赖缺失**: 安装所需依赖 `pip install -r requirements.txt`

---

## 💡 最佳实践

### 1. 参数调优流程

```
1. 使用默认参数快速训练 → 获得基线IC
2. 单参数调优 (如learning_rate) → 观察IC变化
3. 组合调优 (如learning_rate + n_estimators) → 寻找最优组合
4. 交叉验证 (改变训练/测试时间段) → 验证稳定性
```

### 2. 数据集划分建议

```
# 标准划分（适合中期策略）
训练: 2018-01-01 ~ 2020-12-31 (3年)
验证: 2021-01-01 ~ 2021-12-31 (1年)

# 滚动窗口（适合频繁更新）
训练: 最近2年
验证: 最近6个月

# 多时期验证（验证稳定性）
训练: 2017-01-01 ~ 2019-12-31
验证1: 2020-01-01 ~ 2020-12-31
验证2: 2021-01-01 ~ 2021-12-31
验证3: 2022-01-01 ~ 2022-12-31
```

### 3. 模型选择指南

| 场景 | 推荐模型 | 原因 |
|------|----------|------|
| 快速验证 | LightGBM | 速度快，资源占用低 |
| 追求极致性能 | DoubleEnsemble | 集成多个模型，稳定性高 |
| 捕捉时序特征 | LSTM/GRU | 适合时间序列预测 |
| 大规模数据 | LightGBM/XGBoost | 分布式训练支持 |
| 类别特征多 | CatBoost | 自动处理类别特征 |

---

## 📞 获取帮助

- **文档**: 查看 `docs/PHASE_5_1_COMPLETION_REPORT.md`
- **源码**: 浏览 `qlib_enhanced/model_zoo/`
- **问题反馈**: 提交Issue到项目仓库

---

## 🎯 下一步

完成Model Zoo训练后，您可以：

1. **Phase 5.2**: 使用订单执行引擎模拟真实交易
2. **Phase 5.3**: 查看IC分析报告，深入理解模型预测能力
3. **Phase 6**: 使用高频交易模块和策略对比工具

---

**祝您训练顺利！** 🚀
