# RD-Agent é›†æˆæ•…éšœæ’æŸ¥æŒ‡å—

**ç‰ˆæœ¬**: 1.0  
**æ›´æ–°æ—¶é—´**: 2024-11-08  
**é€‚ç”¨èŒƒå›´**: RD-Agent å…¼å®¹å±‚

---

## ğŸ“‹ ç›®å½•

1. [å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ](#1-å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ)
2. [æ—¥å¿—åˆ†ææŒ‡å—](#2-æ—¥å¿—åˆ†ææŒ‡å—)
3. [æ€§èƒ½è°ƒä¼˜](#3-æ€§èƒ½è°ƒä¼˜)
4. [é…ç½®æœ€ä½³å®è·µ](#4-é…ç½®æœ€ä½³å®è·µ)
5. [è¯Šæ–­æ¸…å•](#5-è¯Šæ–­æ¸…å•)

---

## 1. å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### 1.1 å®˜æ–¹ç»„ä»¶åˆå§‹åŒ–å¤±è´¥

**ç—‡çŠ¶**:
```
OfficialIntegrationError: Failed to initialize official RD-Agent manager
```

**å¯èƒ½åŸå› **:
- ç¼ºå°‘å¿…è¦é…ç½® (llm_api_key)
- ç¯å¢ƒå˜é‡æœªè®¾ç½®
- LLM provider é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:

```python
import os

# æ–¹æ¡ˆ1: æ£€æŸ¥é…ç½®å®Œæ•´æ€§
config = {
    'llm_model': 'gpt-4',
    'llm_api_key': os.getenv('OPENAI_API_KEY'),  # ç¡®ä¿è®¾ç½®
    'llm_provider': 'openai',
    'max_iterations': 10
}

# éªŒè¯å¿…è¦é…ç½®
assert config['llm_api_key'], "âŒ éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡"

# æ–¹æ¡ˆ2: ä½¿ç”¨ç¯å¢ƒå˜é‡
# Linux/Mac:
# export OPENAI_API_KEY="sk-xxx"

# Windows:
# $env:OPENAI_API_KEY="sk-xxx"

# æ–¹æ¡ˆ3: ä»é…ç½®æ–‡ä»¶åŠ è½½
import yaml
with open('config.yaml') as f:
    config = yaml.safe_load(f)
```

---

### 1.2 Factor Loop è¶…æ—¶

**ç—‡çŠ¶**:
```
TimeoutError: Factor loop execution timeout
```
æˆ–é•¿æ—¶é—´æ— å“åº” (>5åˆ†é’Ÿ)

**å¯èƒ½åŸå› **:
- `max_iterations` è®¾ç½®è¿‡å¤§
- LLM API å“åº”æ…¢/ç½‘ç»œé—®é¢˜
- Qlib æ•°æ®åŠ è½½ç¼“æ…¢

**è§£å†³æ–¹æ¡ˆ**:

```python
# 1. å‡å°è¿­ä»£æ¬¡æ•°
config['max_iterations'] = 5  # æ¨è 3-10, ä¸è¦è¶…è¿‡20

# 2. å¢åŠ è¶…æ—¶æ—¶é—´
config['timeout'] = 300  # 5åˆ†é’Ÿ

# 3. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
config['llm_model'] = 'gpt-3.5-turbo'  # è€Œä¸æ˜¯ gpt-4

# 4. æ£€æŸ¥ç½‘ç»œè¿æ¥
import requests
try:
    requests.get('https://api.openai.com', timeout=5)
    print("âœ… ç½‘ç»œè¿æ¥æ­£å¸¸")
except:
    print("âŒ ç½‘ç»œè¿æ¥å¤±è´¥,è¯·æ£€æŸ¥ä»£ç†è®¾ç½®")

# 5. ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (æ¨èç”Ÿäº§ç¯å¢ƒ)
config['llm_base_url'] = 'http://localhost:8000/v1'  # vllm
config['llm_provider'] = 'openai'  # å…¼å®¹ API
```

---

### 1.3 FileStorage è®°å½•å¤±è´¥

**ç—‡çŠ¶**:
```
Can't pickle <class 'Mock'>: it's not the same object as unittest.mock.Mock
```

**å¯èƒ½åŸå› **:
- å¯¹è±¡åŒ…å«ä¸å¯åºåˆ—åŒ–çš„æ•°æ® (Mock, Lambda, Thread)
- ç£ç›˜ç©ºé—´ä¸è¶³
- æƒé™é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:

```python
from rd_agent.logging_integration import QilinRDAgentLogger

logger = QilinRDAgentLogger('./logs')

# æ–¹æ¡ˆ1: åªè®°å½•å¯åºåˆ—åŒ–çš„æ•°æ®
try:
    logger.log_experiment(exp, tag='factor')
except Exception as e:
    logger.warning(f"âš ï¸ æ—¥å¿—è®°å½•å¤±è´¥: {e}")
    # ç»§ç»­æ‰§è¡Œ,ä¸ä¸­æ–­ä¸»æµç¨‹

# æ–¹æ¡ˆ2: æ¸…ç†å¯¹è±¡
import copy
clean_exp = copy.deepcopy(exp)
# ç§»é™¤ä¸å¯åºåˆ—åŒ–çš„å±æ€§
if hasattr(clean_exp, '_mock_data'):
    delattr(clean_exp, '_mock_data')

logger.log_experiment(clean_exp)

# æ–¹æ¡ˆ3: ä½¿ç”¨ JSON æ ¼å¼ (ç‰ºç‰²å®Œæ•´æ€§æ¢å–å¯é æ€§)
logger.log_metrics({
    'hypothesis': str(exp.hypothesis),
    'ic': exp.result['IC'],
    'timestamp': datetime.now().isoformat()
}, tag='factor.metrics')
```

---

### 1.4 æ•°æ®åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
DataNotFoundError: Cannot load factors from workspace
```

**å¯èƒ½åŸå› **:
- å·¥ä½œç©ºé—´è·¯å¾„é”™è¯¯
- æ²¡æœ‰è¿è¡Œè¿‡å®éªŒ
- æ•°æ®æ–‡ä»¶æŸå

**è§£å†³æ–¹æ¡ˆ**:

```python
from rd_agent.compat_wrapper import RDAgentWrapper, DataNotFoundError

agent = RDAgentWrapper(config)

# æ–¹æ¡ˆ1: ä½¿ç”¨å¤šçº§å…œåº•
try:
    factors = agent.load_factors_with_fallback(
        workspace_path='./logs/rdagent',
        n_factors=10
    )
    print(f"âœ… åŠ è½½äº† {len(factors)} ä¸ªå› å­")
except DataNotFoundError as e:
    print(f"âŒ {e}")
    # æŸ¥çœ‹è¯Šæ–­ä¿¡æ¯
    
# æ–¹æ¡ˆ2: æ£€æŸ¥å·¥ä½œç©ºé—´
from pathlib import Path
workspace = Path('./logs/rdagent')
if not workspace.exists():
    print("âŒ å·¥ä½œç©ºé—´ä¸å­˜åœ¨,æ­£åœ¨åˆ›å»º...")
    workspace.mkdir(parents=True)

# æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
pkl_files = list(workspace.glob('**/*.pkl'))
json_files = list(workspace.glob('**/*.json'))
print(f"æ‰¾åˆ° {len(pkl_files)} ä¸ª pkl æ–‡ä»¶")
print(f"æ‰¾åˆ° {len(json_files)} ä¸ª json æ–‡ä»¶")

# æ–¹æ¡ˆ3: å…ˆè¿è¡Œä¸€æ¬¡å®éªŒ
if not pkl_files:
    print("ğŸ”„ æ­£åœ¨è¿è¡Œé¦–æ¬¡å®éªŒ...")
    result = await agent.research_pipeline(
        "æµ‹è¯•å®éªŒ",
        pd.DataFrame({'close': [100, 101, 102]}),
        max_iterations=2
    )
```

---

### 1.5 ä»£ç æ²™ç›’æ‰§è¡Œå¤±è´¥

**ç—‡çŠ¶**:
```
Code validation failed: Unsafe import: os
```

**å¯èƒ½åŸå› **:
- ä»£ç åŒ…å«å±é™©æ“ä½œ
- å®‰å…¨çº§åˆ«è®¾ç½®è¿‡ä¸¥

**è§£å†³æ–¹æ¡ˆ**:

```python
from rd_agent.code_sandbox import CodeSandbox, SecurityLevel

# æ–¹æ¡ˆ1: è°ƒæ•´å®‰å…¨çº§åˆ« (è°¨æ…!)
sandbox = CodeSandbox(
    security_level=SecurityLevel.MODERATE,  # è€Œä¸æ˜¯ STRICT
    timeout=10
)

# æ–¹æ¡ˆ2: æ·»åŠ å…è®¸çš„æ¨¡å—
result = sandbox.execute(
    code="import custom_lib",
    context={},
    allowed_modules=['custom_lib']
)

# æ–¹æ¡ˆ3: é¢„å…ˆå¯¼å…¥éœ€è¦çš„æ¨¡å—åˆ° context
import numpy as np
import pandas as pd

result = sandbox.execute(
    code="result = np.mean([1,2,3])",
    context={'np': np, 'pd': pd}
)
```

---

## 2. æ—¥å¿—åˆ†ææŒ‡å—

### 2.1 è®¾ç½®æ—¥å¿—çº§åˆ«

```python
import logging

# å¼€å‘ç¯å¢ƒ - è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
)

# ç”Ÿäº§ç¯å¢ƒ - æ­£å¸¸æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)

# åªçœ‹é”™è¯¯
logging.basicConfig(level=logging.ERROR)

# è¾“å‡ºåˆ°æ–‡ä»¶
logging.basicConfig(
    level=logging.INFO,
    filename='rdagent.log',
    format='%(asctime)s [%(levelname)s] %(message)s'
)
```

### 2.2 å…³é”®æ—¥å¿—æ ‡è®°

| æ ‡è®° | å«ä¹‰ | è¯´æ˜ |
|------|------|------|
| âœ… | æˆåŠŸ | æ“ä½œæˆåŠŸå®Œæˆ |
| âš ï¸ | è­¦å‘Š | ä¸å½±å“ä¸»æµç¨‹,ä½†éœ€å…³æ³¨ |
| âŒ | é”™è¯¯ | æ“ä½œå¤±è´¥,éœ€è¦å¤„ç† |
| ğŸ”„ | å¤„ç†ä¸­ | æ­£åœ¨æ‰§è¡Œè€—æ—¶æ“ä½œ |
| ğŸ“Š | ç»Ÿè®¡ | æ€§èƒ½/ç»Ÿè®¡ä¿¡æ¯ |
| ğŸ” | è°ƒè¯• | è°ƒè¯•ä¿¡æ¯ (DEBUG) |

### 2.3 æ—¥å¿—åˆ†æç¤ºä¾‹

**æ­£å¸¸è¿è¡Œæ—¥å¿—**:
```
2024-11-08 10:00:00 [INFO] RDAgentWrapper initialized successfully
2024-11-08 10:00:01 [INFO] Starting research pipeline: Aè‚¡åŠ¨é‡å› å­ç ”ç©¶
2024-11-08 10:00:02 [INFO] ğŸ”„ Running FactorRDLoop for 10 iterations...
2024-11-08 10:02:30 [INFO] âœ… FileStorage logging enabled at ./logs
2024-11-08 10:05:00 [INFO] âœ… Logged experiments to FileStorage
2024-11-08 10:05:01 [INFO] Research pipeline completed. Found 5 factors.
```

**å¼‚å¸¸æ—¥å¿—**:
```
2024-11-08 10:00:00 [ERROR] âŒ Failed to initialize: No API key provided
2024-11-08 10:00:01 [WARNING] âš ï¸ FileStorage logging unavailable: ImportError
2024-11-08 10:00:02 [ERROR] âŒ Research pipeline failed: Connection timeout
```

---

## 3. æ€§èƒ½è°ƒä¼˜

### 3.1 æå‡é€Ÿåº¦

```python
import asyncio

# 1. å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡
tasks = [
    agent.discover_factors(data, n_factors=5),
    agent.discover_factors(data, n_factors=5),
    agent.discover_factors(data, n_factors=5)
]
results = await asyncio.gather(*tasks)
# 3x é€Ÿåº¦æå‡

# 2. å‡å°‘è¿­ä»£æ¬¡æ•°
config['max_iterations'] = 5  # è€Œä¸æ˜¯ 20
# 4x é€Ÿåº¦æå‡

# 3. ä½¿ç”¨ç¼“å­˜
factors = agent.load_factors_with_fallback()  # ä»ç¼“å­˜åŠ è½½
# å³æ—¶è¿”å›

# 4. é™åˆ¶æ•°æ®é‡
df = df.tail(10000)  # åªç”¨æœ€è¿‘1ä¸‡æ¡
# 2-3x é€Ÿåº¦æå‡

# 5. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
config['llm_model'] = 'gpt-3.5-turbo'
# 2x é€Ÿåº¦,1/10 æˆæœ¬
```

### 3.2 å†…å­˜ä¼˜åŒ–

```python
import gc
import pandas as pd

# 1. åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡
large_df = pd.read_csv('huge_data.csv')
result = process(large_df)
del large_df  # ç«‹å³é‡Šæ”¾
gc.collect()

# 2. ä½¿ç”¨æ•°æ®ç±»å‹ä¼˜åŒ–
df['volume'] = df['volume'].astype('int32')  # è€Œä¸æ˜¯ int64
df['close'] = df['close'].astype('float32')  # è€Œä¸æ˜¯ float64
# å†…å­˜å‡åŠ

# 3. åˆ†å—å¤„ç†
for chunk in pd.read_csv('data.csv', chunksize=10000):
    process_chunk(chunk)
# æ’å®šå†…å­˜ä½¿ç”¨

# 4. æ¸…ç†æ—¥å¿—æ–‡ä»¶
from rd_agent.logging_integration import QilinRDAgentLogger
logger = QilinRDAgentLogger('./logs')
logger.clear_logs(tag='old_experiments')  # æ¸…ç†æ—§æ•°æ®
```

### 3.3 æ€§èƒ½ç›‘æ§

```python
import time
import psutil

def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        # CPU/å†…å­˜åŸºçº¿
        process = psutil.Process()
        cpu_before = process.cpu_percent()
        mem_before = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œ
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        
        # CPU/å†…å­˜ä½¿ç”¨
        cpu_after = process.cpu_percent()
        mem_after = process.memory_info().rss / 1024 / 1024
        
        print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   - è€—æ—¶: {elapsed:.2f}s")
        print(f"   - CPU: {cpu_after:.1f}%")
        print(f"   - å†…å­˜: {mem_after:.1f}MB (+{mem_after-mem_before:.1f}MB)")
        
        return result
    return wrapper

@monitor_performance
async def run_research():
    return await agent.research_pipeline("test", data, max_iterations=5)
```

---

## 4. é…ç½®æœ€ä½³å®è·µ

### 4.1 å¼€å‘ç¯å¢ƒé…ç½®

```python
# config_dev.yaml
dev_config = {
    # ä½¿ç”¨æ›´å¿«æ›´ä¾¿å®œçš„æ¨¡å‹
    'llm_model': 'gpt-3.5-turbo',
    'llm_api_key': os.getenv('OPENAI_API_KEY'),
    'llm_provider': 'openai',
    
    # è¾ƒå°‘çš„è¿­ä»£
    'max_iterations': 3,
    
    # è¾ƒé«˜çš„æ¸©åº¦ (æ›´å¤šæ ·æ€§)
    'llm_temperature': 0.7,
    
    # æœ¬åœ°å·¥ä½œç©ºé—´
    'workspace_path': './dev_logs',
    'qlib_data_path': './dev_data',
    
    # å¯ç”¨è¯¦ç»†æ—¥å¿—
    'log_level': 'DEBUG'
}
```

### 4.2 ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# config_prod.yaml
prod_config = {
    # ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹
    'llm_model': 'gpt-4-turbo',
    'llm_api_key': os.getenv('OPENAI_API_KEY'),
    'llm_provider': 'openai',
    
    # æ ‡å‡†è¿­ä»£æ¬¡æ•°
    'max_iterations': 10,
    
    # è¾ƒä½çš„æ¸©åº¦ (æ›´ç¡®å®šæ€§)
    'llm_temperature': 0.5,
    
    # ç”Ÿäº§è·¯å¾„
    'workspace_path': '/var/logs/rdagent',
    'qlib_data_path': '/data/qlib',
    
    # æ­£å¸¸æ—¥å¿—çº§åˆ«
    'log_level': 'INFO',
    
    # å¯ç”¨æ‰€æœ‰åŠŸèƒ½
    'enable_filestorage': True,
    'enable_caching': True
}
```

### 4.3 æœ¬åœ°æ¨¡å‹é…ç½® (æ¨è)

```python
# ä½¿ç”¨ vllm éƒ¨ç½²æœ¬åœ°æ¨¡å‹
local_config = {
    'llm_model': 'Qwen/Qwen-14B-Chat',
    'llm_provider': 'openai',  # vllm å…¼å®¹ OpenAI API
    'llm_base_url': 'http://localhost:8000/v1',
    'llm_api_key': 'EMPTY',  # æœ¬åœ°ä¸éœ€è¦
    
    'max_iterations': 10,
    'llm_temperature': 0.6
}

# ä¼˜åŠ¿:
# - æ— ç½‘ç»œå»¶è¿Ÿ
# - æ— æˆæœ¬
# - æ•°æ®éšç§
# - å¯å®šåˆ¶
```

---

## 5. è¯Šæ–­æ¸…å•

### 5.1 å¯åŠ¨å‰æ£€æŸ¥

**ç¯å¢ƒæ£€æŸ¥**:
```bash
# 1. æ£€æŸ¥ Python ç‰ˆæœ¬
python --version  # åº”è¯¥ >= 3.8

# 2. æ£€æŸ¥ä¾èµ–
pip list | grep -E "rdagent|pandas|numpy"

# 3. æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY  # Linux/Mac
echo $env:OPENAI_API_KEY  # Windows
```

**é…ç½®æ£€æŸ¥**:
- [ ] ç¯å¢ƒå˜é‡å·²è®¾ç½® (OPENAI_API_KEY)
- [ ] Qlib æ•°æ®å·²åˆå§‹åŒ–
- [ ] å·¥ä½œç©ºé—´è·¯å¾„å­˜åœ¨ä¸”å¯å†™
- [ ] æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…

```python
# è‡ªåŠ¨åŒ–æ£€æŸ¥è„šæœ¬
import os
from pathlib import Path

def pre_flight_check():
    """å¯åŠ¨å‰æ£€æŸ¥"""
    checks = []
    
    # 1. API Key
    if os.getenv('OPENAI_API_KEY'):
        checks.append("âœ… API Key å·²è®¾ç½®")
    else:
        checks.append("âŒ API Key æœªè®¾ç½®")
    
    # 2. å·¥ä½œç©ºé—´
    workspace = Path('./logs/rdagent')
    if workspace.exists() and workspace.is_dir():
        checks.append("âœ… å·¥ä½œç©ºé—´å­˜åœ¨")
    else:
        checks.append("âš ï¸ å·¥ä½œç©ºé—´ä¸å­˜åœ¨,å°†è‡ªåŠ¨åˆ›å»º")
        workspace.mkdir(parents=True, exist_ok=True)
    
    # 3. ä¾èµ–åŒ…
    try:
        import pandas
        import numpy
        checks.append("âœ… ä¾èµ–åŒ…å·²å®‰è£…")
    except ImportError as e:
        checks.append(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    
    # è¾“å‡ºç»“æœ
    for check in checks:
        print(check)
    
    return all('âœ…' in c for c in checks)

if __name__ == '__main__':
    if pre_flight_check():
        print("\nğŸš€ æ‰€æœ‰æ£€æŸ¥é€šè¿‡,å¯ä»¥å¯åŠ¨!")
    else:
        print("\nâš ï¸ å­˜åœ¨é—®é¢˜,è¯·å…ˆè§£å†³")
```

### 5.2 è¿è¡Œæ—¶æ£€æŸ¥

**æ€§èƒ½ç›‘æ§**:
- [ ] CPU ä½¿ç”¨ç‡ < 80%
- [ ] å†…å­˜ä½¿ç”¨ < 8GB
- [ ] ç£ç›˜ç©ºé—´ > 10GB
- [ ] ç½‘ç»œè¿æ¥æ­£å¸¸

```python
import psutil

def runtime_check():
    """è¿è¡Œæ—¶æ£€æŸ¥"""
    # CPU
    cpu = psutil.cpu_percent(interval=1)
    print(f"CPU: {cpu}% {'âœ…' if cpu < 80 else 'âš ï¸'}")
    
    # å†…å­˜
    mem = psutil.virtual_memory()
    mem_gb = mem.used / 1024 / 1024 / 1024
    print(f"å†…å­˜: {mem_gb:.1f}GB / {mem.total/1024/1024/1024:.1f}GB "
          f"({'âœ…' if mem_gb < 8 else 'âš ï¸'})")
    
    # ç£ç›˜
    disk = psutil.disk_usage('/')
    disk_gb = disk.free / 1024 / 1024 / 1024
    print(f"ç£ç›˜: {disk_gb:.1f}GB å¯ç”¨ "
          f"({'âœ…' if disk_gb > 10 else 'âš ï¸'})")
```

### 5.3 ç»“æœéªŒè¯

**è¾“å‡ºæ£€æŸ¥**:
- [ ] å› å­æ•°é‡ > 0
- [ ] æ€§èƒ½æŒ‡æ ‡åˆç† (IC > 0.02, IR > 0.5)
- [ ] FileStorage æœ‰è®°å½•
- [ ] æ— å¼‚å¸¸é”™è¯¯

```python
def validate_results(results):
    """éªŒè¯ç ”ç©¶ç»“æœ"""
    issues = []
    
    # 1. å› å­æ•°é‡
    if len(results['factors']) == 0:
        issues.append("âŒ æœªå‘ç°ä»»ä½•å› å­")
    else:
        print(f"âœ… å‘ç° {len(results['factors'])} ä¸ªå› å­")
    
    # 2. æ€§èƒ½æŒ‡æ ‡
    for factor in results['factors']:
        ic = factor.performance.get('ic', 0)
        if ic < 0.02:
            issues.append(f"âš ï¸ å› å­ {factor.name} ICè¿‡ä½: {ic:.4f}")
        else:
            print(f"âœ… å› å­ {factor.name} ICæ­£å¸¸: {ic:.4f}")
    
    # 3. æœ€ä½³æ–¹æ¡ˆ
    if results.get('best_solution'):
        print("âœ… æ‰¾åˆ°æœ€ä½³æ–¹æ¡ˆ")
    else:
        issues.append("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ–¹æ¡ˆ")
    
    return len(issues) == 0, issues
```

---

## 6. å¸¸è§é—®é¢˜ FAQ

### Q1: å¦‚ä½•åŠ é€Ÿå› å­å‘ç°?
**A**: 
1. å‡å°‘ `max_iterations` (3-5å³å¯)
2. ä½¿ç”¨ `gpt-3.5-turbo` è€Œé `gpt-4`
3. å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡
4. ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (vllm)

### Q2: FileStorage æ—¥å¿—åœ¨å“ªé‡Œ?
**A**: é»˜è®¤åœ¨ `workspace_path` ç›®å½•ä¸‹:
```
./logs/rdagent/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ exp_001.pkl
â”‚   â””â”€â”€ exp_002.pkl
â””â”€â”€ metrics/
    â””â”€â”€ summary_001.json
```

### Q3: å¦‚ä½•ä»å†å²æ¢å¤?
**A**: ä½¿ç”¨å¤šçº§å…œåº•:
```python
factors = agent.load_factors_with_fallback(
    workspace_path='./logs/rdagent',
    n_factors=10
)
```

### Q4: Windows ä¸Šè¶…æ—¶ä¸ç”Ÿæ•ˆ?
**A**: Phase 3.1 å°†æ·»åŠ  Windows è¶…æ—¶æ”¯æŒã€‚å½“å‰è¯·:
1. ä½¿ç”¨ Linux/Mac (æ¨è)
2. æ‰‹åŠ¨ç›‘æ§å¹¶ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„è¿›ç¨‹
3. å‡å° `max_iterations`

### Q5: å¦‚ä½•è°ƒè¯•ä»£ç æ²™ç›’é—®é¢˜?
**A**: å¯ç”¨è¯¦ç»†æ—¥å¿—:
```python
import logging
logging.getLogger('rd_agent.code_sandbox').setLevel(logging.DEBUG)
```

---

## 7. è·å–å¸®åŠ©

### æ—¥å¿—æ”¶é›†

å‡ºç°é—®é¢˜æ—¶,è¯·æ”¶é›†ä»¥ä¸‹ä¿¡æ¯:

```python
# collect_debug_info.py
import sys
import platform
import os

print("=== ç³»ç»Ÿä¿¡æ¯ ===")
print(f"Python: {sys.version}")
print(f"å¹³å°: {platform.platform()}")
print(f"å·¥ä½œç›®å½•: {os.getcwd()}")

print("\n=== ç¯å¢ƒå˜é‡ ===")
print(f"OPENAI_API_KEY: {'å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªè®¾ç½®'}")

print("\n=== ä¾èµ–ç‰ˆæœ¬ ===")
import pandas
import numpy
print(f"pandas: {pandas.__version__}")
print(f"numpy: {numpy.__version__}")

print("\n=== é…ç½®ä¿¡æ¯ ===")
print(f"Workspace: {config.get('workspace_path')}")
print(f"Model: {config.get('llm_model')}")
print(f"Max iterations: {config.get('max_iterations')}")
```

### è”ç³»æ”¯æŒ

- ğŸ“§ Email: support@example.com
- ğŸ’¬ Issues: https://github.com/example/rdagent/issues
- ğŸ“– æ–‡æ¡£: https://rdagent.readthedocs.io

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2024-11-08  
**ç»´æŠ¤è€…**: AI Agent Team
