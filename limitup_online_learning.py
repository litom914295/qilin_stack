"""
æ¶¨åœæ¿é¢„æµ‹ç³»ç»Ÿ - åœ¨çº¿å­¦ä¹ ä¼˜åŒ–æ¨¡å—
æ”¯æŒå¢é‡å­¦ä¹ å’Œæ¨¡å‹è‡ªé€‚åº”æ›´æ–°
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from pathlib import Path
import json
from datetime import datetime
import pickle
from collections import deque

from sklearn.metrics import f1_score, precision_score, recall_score
import lightgbm as lgb


class OnlineLearningModel:
    """åœ¨çº¿å­¦ä¹ æ¨¡å‹ï¼ˆå¢é‡æ›´æ–°ï¼‰"""
    
    def __init__(
        self,
        window_size: int = 1000,
        update_threshold: float = 0.05,
        min_samples: int = 100,
        save_dir: str = './online_models'
    ):
        """
        åˆå§‹åŒ–åœ¨çº¿å­¦ä¹ æ¨¡å‹
        
        Args:
            window_size: æ»‘åŠ¨çª—å£å¤§å°ï¼ˆç”¨äºä¿ç•™æœ€è¿‘æ•°æ®ï¼‰
            update_threshold: æ€§èƒ½ä¸‹é™é˜ˆå€¼ï¼ˆè§¦å‘é‡è®­ç»ƒï¼‰
            min_samples: æœ€å°æ ·æœ¬æ•°ï¼ˆè§¦å‘æ›´æ–°ï¼‰
            save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        self.window_size = window_size
        self.update_threshold = update_threshold
        self.min_samples = min_samples
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # åŸºç¡€æ¨¡å‹
        self.model = None
        self.base_score = 0.0
        
        # å¢é‡æ•°æ®ç¼“å­˜
        self.X_buffer = deque(maxlen=window_size)
        self.y_buffer = deque(maxlen=window_size)
        
        # æ€§èƒ½ç›‘æ§
        self.performance_history = []
        self.update_count = 0
        
        print(f"ğŸ”„ åœ¨çº¿å­¦ä¹ æ¨¡å‹åˆå§‹åŒ–")
        print(f"   æ»‘åŠ¨çª—å£: {window_size}")
        print(f"   æ›´æ–°é˜ˆå€¼: {update_threshold}")
        print(f"   æœ€å°æ ·æœ¬: {min_samples}")
    
    def initial_train(self, X: pd.DataFrame, y: pd.Series, **model_params):
        """åˆå§‹è®­ç»ƒï¼ˆå†·å¯åŠ¨ï¼‰"""
        print(f"\nğŸš€ å¼€å§‹åˆå§‹è®­ç»ƒ...")
        print(f"è®­ç»ƒé›†å¤§å°: {X.shape}")
        
        # åˆ›å»ºLightGBMæ¨¡å‹ï¼ˆæ”¯æŒå¢é‡å­¦ä¹ ï¼‰
        self.model = lgb.LGBMClassifier(
            n_estimators=model_params.get('n_estimators', 100),
            max_depth=model_params.get('max_depth', 6),
            learning_rate=model_params.get('learning_rate', 0.1),
            random_state=42,
            verbose=-1
        )
        
        # è®­ç»ƒ
        self.model.fit(X, y)
        
        # è¯„ä¼°åŸºçº¿æ€§èƒ½
        y_pred = self.model.predict(X)
        self.base_score = f1_score(y, y_pred, average='weighted')
        
        print(f"âœ… åˆå§‹è®­ç»ƒå®Œæˆ")
        print(f"   åŸºçº¿F1åˆ†æ•°: {self.base_score:.4f}")
        
        # è®°å½•æ€§èƒ½
        self._record_performance(self.base_score, 'initial')
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """é¢„æµ‹"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        return self.model.predict(X)
    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """é¢„æµ‹æ¦‚ç‡"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        return self.model.predict_proba(X)
    
    def update(
        self,
        X_new: pd.DataFrame,
        y_new: pd.Series,
        force: bool = False
    ) -> Dict[str, Any]:
        """
        å¢é‡æ›´æ–°æ¨¡å‹
        
        Args:
            X_new: æ–°æ•°æ®ç‰¹å¾
            y_new: æ–°æ•°æ®æ ‡ç­¾
            force: å¼ºåˆ¶æ›´æ–°ï¼ˆå¿½ç•¥é˜ˆå€¼æ£€æŸ¥ï¼‰
            
        Returns:
            æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initial_train()")
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        for i in range(len(X_new)):
            self.X_buffer.append(X_new.iloc[i])
            self.y_buffer.append(y_new.iloc[i])
        
        buffer_size = len(self.X_buffer)
        print(f"\nğŸ“Š ç¼“å†²åŒºå¤§å°: {buffer_size}/{self.window_size}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        should_update = force or buffer_size >= self.min_samples
        
        if not should_update:
            return {
                'updated': False,
                'reason': f'æ ·æœ¬ä¸è¶³ ({buffer_size}/{self.min_samples})'
            }
        
        # è¯„ä¼°å½“å‰æ€§èƒ½
        X_buffer_df = pd.DataFrame(list(self.X_buffer))
        y_buffer_series = pd.Series(list(self.y_buffer))
        
        y_pred = self.model.predict(X_buffer_df)
        current_score = f1_score(y_buffer_series, y_pred, average='weighted')
        
        performance_drop = self.base_score - current_score
        
        print(f"å½“å‰F1åˆ†æ•°: {current_score:.4f}")
        print(f"æ€§èƒ½ä¸‹é™: {performance_drop:.4f}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è®­ç»ƒ
        need_retrain = force or performance_drop > self.update_threshold
        
        if not need_retrain:
            return {
                'updated': False,
                'reason': f'æ€§èƒ½ä¸‹é™ä¸è¶³ ({performance_drop:.4f} < {self.update_threshold})',
                'current_score': current_score
            }
        
        # æ‰§è¡Œå¢é‡è®­ç»ƒ
        print(f"\nğŸ”„ å¼€å§‹å¢é‡è®­ç»ƒ...")
        
        # ä½¿ç”¨ç¼“å†²åŒºæ•°æ®é‡è®­ç»ƒ
        self.model.fit(
            X_buffer_df,
            y_buffer_series,
            init_model=self.model  # LightGBMæ”¯æŒå¢é‡è®­ç»ƒ
        )
        
        # é‡æ–°è¯„ä¼°
        y_pred_new = self.model.predict(X_buffer_df)
        new_score = f1_score(y_buffer_series, y_pred_new, average='weighted')
        
        # æ›´æ–°åŸºçº¿
        self.base_score = new_score
        self.update_count += 1
        
        print(f"âœ… å¢é‡è®­ç»ƒå®Œæˆ")
        print(f"   æ–°F1åˆ†æ•°: {new_score:.4f}")
        print(f"   æ€»æ›´æ–°æ¬¡æ•°: {self.update_count}")
        
        # è®°å½•æ€§èƒ½
        self._record_performance(new_score, 'incremental')
        
        # è‡ªåŠ¨ä¿å­˜
        self.save(f'online_model_v{self.update_count}.pkl')
        
        return {
            'updated': True,
            'old_score': current_score,
            'new_score': new_score,
            'improvement': new_score - current_score,
            'update_count': self.update_count
        }
    
    def _record_performance(self, score: float, update_type: str):
        """è®°å½•æ€§èƒ½å†å²"""
        self.performance_history.append({
            'timestamp': datetime.now().isoformat(),
            'score': score,
            'update_type': update_type,
            'update_count': self.update_count
        })
    
    def get_performance_history(self) -> pd.DataFrame:
        """è·å–æ€§èƒ½å†å²"""
        return pd.DataFrame(self.performance_history)
    
    def save(self, filename: str):
        """ä¿å­˜æ¨¡å‹"""
        filepath = self.save_dir / filename
        
        # ä¿å­˜æ¨¡å‹
        with open(filepath, 'wb') as f:
            pickle.dump({
                'model': self.model,
                'base_score': self.base_score,
                'update_count': self.update_count,
                'performance_history': self.performance_history
            }, f)
        
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load(self, filename: str):
        """åŠ è½½æ¨¡å‹"""
        filepath = self.save_dir / filename
        
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
        
        self.model = data['model']
        self.base_score = data['base_score']
        self.update_count = data['update_count']
        self.performance_history = data['performance_history']
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {filepath}")
        print(f"   F1åˆ†æ•°: {self.base_score:.4f}")
        print(f"   æ›´æ–°æ¬¡æ•°: {self.update_count}")


class AdaptiveLearningPipeline:
    """è‡ªé€‚åº”å­¦ä¹ Pipelineï¼ˆå®Œæ•´å·¥ä½œæµï¼‰"""
    
    def __init__(
        self,
        window_size: int = 1000,
        update_interval: int = 100,
        update_threshold: float = 0.05,
        save_dir: str = './adaptive_models'
    ):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”å­¦ä¹ Pipeline
        
        Args:
            window_size: æ»‘åŠ¨çª—å£å¤§å°
            update_interval: æ›´æ–°é—´éš”ï¼ˆæ ·æœ¬æ•°ï¼‰
            update_threshold: æ€§èƒ½é˜ˆå€¼
            save_dir: ä¿å­˜ç›®å½•
        """
        self.window_size = window_size
        self.update_interval = update_interval
        self.update_threshold = update_threshold
        self.save_dir = save_dir
        
        self.model = OnlineLearningModel(
            window_size=window_size,
            update_threshold=update_threshold,
            min_samples=update_interval,
            save_dir=save_dir
        )
        
        self.samples_since_update = 0
        
        print(f"\n{'='*60}")
        print(f"ğŸ¯ è‡ªé€‚åº”å­¦ä¹ Pipelineåˆå§‹åŒ–")
        print(f"{'='*60}")
        print(f"æ»‘åŠ¨çª—å£: {window_size}")
        print(f"æ›´æ–°é—´éš”: {update_interval}")
        print(f"{'='*60}\n")
    
    def fit(self, X: pd.DataFrame, y: pd.Series):
        """åˆå§‹è®­ç»ƒ"""
        self.model.initial_train(X, y)
    
    def predict_and_learn(
        self,
        X: pd.DataFrame,
        y_true: Optional[pd.Series] = None
    ) -> np.ndarray:
        """
        é¢„æµ‹å¹¶å­¦ä¹ ï¼ˆåœ¨çº¿æ¨¡å¼ï¼‰
        
        Args:
            X: è¾“å…¥ç‰¹å¾
            y_true: çœŸå®æ ‡ç­¾ï¼ˆå¦‚æœå¯ç”¨ï¼Œç”¨äºå¢é‡å­¦ä¹ ï¼‰
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        # é¢„æµ‹
        predictions = self.model.predict(X)
        
        # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œè§¦å‘å¢é‡å­¦ä¹ 
        if y_true is not None:
            self.samples_since_update += len(X)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ›´æ–°é—´éš”
            if self.samples_since_update >= self.update_interval:
                print(f"\nğŸ”” è§¦å‘å¢é‡æ›´æ–° ({self.samples_since_update}æ ·æœ¬)")
                update_result = self.model.update(X, y_true)
                
                if update_result['updated']:
                    self.samples_since_update = 0
                    print(f"âœ… æ¨¡å‹å·²æ›´æ–°")
                else:
                    print(f"â­ï¸  {update_result['reason']}")
        
        return predictions
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'update_count': self.model.update_count,
            'base_score': self.model.base_score,
            'samples_since_update': self.samples_since_update,
            'buffer_size': len(self.model.X_buffer),
            'performance_history': self.model.performance_history
        }
    
    def plot_performance(self):
        """ç»˜åˆ¶æ€§èƒ½æ›²çº¿"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            plt.rcParams['font.sans-serif'] = ['SimHei']
            plt.rcParams['axes.unicode_minus'] = False
            
            df = self.model.get_performance_history()
            
            if len(df) == 0:
                print("âš ï¸ æš‚æ— æ€§èƒ½å†å²")
                return
            
            fig, ax = plt.subplots(figsize=(12, 6))
            
            ax.plot(range(len(df)), df['score'], marker='o', linewidth=2)
            ax.set_xlabel('æ›´æ–°æ¬¡æ•°')
            ax.set_ylabel('F1åˆ†æ•°')
            ax.set_title('åœ¨çº¿å­¦ä¹ æ€§èƒ½å˜åŒ–')
            ax.grid(True, alpha=0.3)
            
            # æ ‡æ³¨æ›´æ–°ç±»å‹
            for i, row in df.iterrows():
                if row['update_type'] == 'incremental':
                    ax.axvline(i, color='red', linestyle='--', alpha=0.3)
            
            filepath = Path(self.save_dir) / 'performance_history.png'
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ æ€§èƒ½æ›²çº¿å·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            print(f"âš ï¸ ç»˜å›¾å¤±è´¥: {e}")


if __name__ == '__main__':
    print("="*60)
    print("æ¶¨åœæ¿é¢„æµ‹ç³»ç»Ÿ - åœ¨çº¿å­¦ä¹ ä¼˜åŒ–æ¨¡å—")
    print("="*60)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    
    # åˆå§‹è®­ç»ƒæ•°æ®
    n_train = 2000
    X_train = pd.DataFrame(
        np.random.randn(n_train, 50),
        columns=[f'feature_{i}' for i in range(50)]
    )
    y_train = pd.Series(np.random.choice([0, 1], size=n_train, p=[0.7, 0.3]))
    
    print(f"\nè®­ç»ƒé›†å¤§å°: {X_train.shape}")
    
    # åˆ›å»ºè‡ªé€‚åº”Pipeline
    pipeline = AdaptiveLearningPipeline(
        window_size=500,
        update_interval=100,
        update_threshold=0.05
    )
    
    # åˆå§‹è®­ç»ƒ
    pipeline.fit(X_train, y_train)
    
    # æ¨¡æ‹Ÿåœ¨çº¿å­¦ä¹ ï¼ˆæµå¼æ•°æ®ï¼‰
    print(f"\n{'='*60}")
    print("ğŸŒŠ æ¨¡æ‹Ÿæµå¼æ•°æ®å¢é‡å­¦ä¹ ")
    print(f"{'='*60}\n")
    
    n_streams = 5
    for i in range(n_streams):
        print(f"\n--- æ•°æ®æµ {i+1}/{n_streams} ---")
        
        # ç”Ÿæˆæ–°æ•°æ®
        X_new = pd.DataFrame(
            np.random.randn(150, 50),
            columns=[f'feature_{i}' for i in range(50)]
        )
        y_new = pd.Series(np.random.choice([0, 1], size=150, p=[0.7, 0.3]))
        
        # é¢„æµ‹å¹¶å­¦ä¹ 
        predictions = pipeline.predict_and_learn(X_new, y_new)
        print(f"é¢„æµ‹å®Œæˆ: {len(predictions)}ä¸ªæ ·æœ¬")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
    print(f"{'='*60}")
    
    stats = pipeline.get_stats()
    print(f"æ€»æ›´æ–°æ¬¡æ•°: {stats['update_count']}")
    print(f"å½“å‰F1åˆ†æ•°: {stats['base_score']:.4f}")
    print(f"ç¼“å†²åŒºå¤§å°: {stats['buffer_size']}")
    
    # ç»˜åˆ¶æ€§èƒ½æ›²çº¿
    pipeline.plot_performance()
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
