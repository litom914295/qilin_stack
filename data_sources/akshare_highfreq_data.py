"""
AKShareé«˜é¢‘æ•°æ®æ¥å£
æ”¯æŒ1åˆ†é’Ÿ/5åˆ†é’Ÿçº§åˆ«çš„Aè‚¡é«˜é¢‘æ•°æ®è·å–
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple
import logging
import os
from pathlib import Path
import pickle
import time

logger = logging.getLogger(__name__)

# æ•°æ®ç¼“å­˜ç›®å½•
CACHE_DIR = Path("data/cache/highfreq")
CACHE_DIR.mkdir(parents=True, exist_ok=True)


class AKShareHighFreqData:
    """AKShareé«˜é¢‘æ•°æ®æ¥å£"""
    
    def __init__(self, freq: str = "1min"):
        """
        åˆå§‹åŒ–
        
        Args:
            freq: æ•°æ®é¢‘ç‡ï¼Œæ”¯æŒ "1min", "5min", "15min", "30min", "60min"
        """
        self.freq = freq
        self.freq_map = {
            "1min": "1",
            "5min": "5",
            "15min": "15",
            "30min": "30",
            "60min": "60"
        }
        
        if freq not in self.freq_map:
            raise ValueError(f"ä¸æ”¯æŒçš„é¢‘ç‡: {freq}ï¼Œæ”¯æŒçš„é¢‘ç‡: {list(self.freq_map.keys())}")
        
        # å°è¯•å¯¼å…¥akshare
        try:
            import akshare as ak
            self.ak = ak
            self.available = True
            logger.info(f"âœ… AKShareé«˜é¢‘æ•°æ®æ¥å£åˆå§‹åŒ–æˆåŠŸ (é¢‘ç‡: {freq})")
        except ImportError:
            self.ak = None
            self.available = False
            logger.warning("âš ï¸ AKShareæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    
    def get_intraday_data(
        self, 
        symbol: str, 
        trade_date: str,
        use_cache: bool = True
    ) -> Optional[pd.DataFrame]:
        """
        è·å–è‚¡ç¥¨æ—¥å†…åˆ†æ—¶æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001" æˆ– "000001.SZ"
            trade_date: äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼ "YYYY-MM-DD"
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            DataFrame with columns: time, open, high, low, close, volume, amount
        """
        try:
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
            symbol_clean = symbol.replace(".SZ", "").replace(".SH", "")
            
            # æ£€æŸ¥ç¼“å­˜
            if use_cache:
                cached_data = self._load_cache(symbol_clean, trade_date)
                if cached_data is not None:
                    logger.info(f"ğŸ“¦ ä»ç¼“å­˜åŠ è½½: {symbol_clean} {trade_date}")
                    return cached_data
            
            # ä»AKShareè·å–
            if not self.available:
                logger.warning("AKShareä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®")
                return self._generate_mock_data(trade_date)
            
            logger.info(f"ğŸŒ ä»AKShareè·å–: {symbol_clean} {trade_date} (freq={self.freq})")
            
            # è°ƒç”¨AKShareæ¥å£
            try:
                # ä½¿ç”¨å®æ—¶è¡Œæƒ…æ¥å£è·å–åˆ†æ—¶æ•°æ®
                df = self.ak.stock_zh_a_hist_min_em(
                    symbol=symbol_clean,
                    period=self.freq_map[self.freq],
                    adjust="",  # ä¸å¤æƒ
                    start_date=trade_date.replace("-", "") + " 09:30:00",
                    end_date=trade_date.replace("-", "") + " 15:00:00"
                )
                
                if df is None or df.empty:
                    logger.warning(f"âš ï¸ æœªè·å–åˆ°æ•°æ®: {symbol_clean} {trade_date}")
                    return None
                
                # æ•°æ®æ ‡å‡†åŒ–
                df = self._standardize_data(df)
                
                # ä¿å­˜ç¼“å­˜
                if use_cache:
                    self._save_cache(symbol_clean, trade_date, df)
                
                logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
                return df
                
            except Exception as e:
                logger.error(f"âŒ AKShareæ¥å£è°ƒç”¨å¤±è´¥: {e}")
                # è¿”å›æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
                return self._generate_mock_data(trade_date)
        
        except Exception as e:
            logger.error(f"è·å–é«˜é¢‘æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None
    
    def get_multiple_days(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        use_cache: bool = True
    ) -> Optional[pd.DataFrame]:
        """
        è·å–å¤šå¤©çš„é«˜é¢‘æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ "YYYY-MM-DD"
            end_date: ç»“æŸæ—¥æœŸ "YYYY-MM-DD"
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            åˆå¹¶çš„DataFrame
        """
        try:
            date_range = pd.date_range(start=start_date, end=end_date, freq='B')  # B = å·¥ä½œæ—¥
            
            all_data = []
            for date in date_range:
                date_str = date.strftime('%Y-%m-%d')
                logger.info(f"è·å– {symbol} {date_str} çš„æ•°æ®...")
                
                df = self.get_intraday_data(symbol, date_str, use_cache)
                if df is not None and not df.empty:
                    all_data.append(df)
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
            
            if not all_data:
                logger.warning(f"æœªè·å–åˆ°ä»»ä½•æ•°æ®: {symbol} {start_date} ~ {end_date}")
                return None
            
            # åˆå¹¶æ•°æ®
            result = pd.concat(all_data, ignore_index=True)
            result = result.sort_values('time').reset_index(drop=True)
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(all_data)} å¤©æ•°æ®ï¼Œå…± {len(result)} æ¡è®°å½•")
            return result
            
        except Exception as e:
            logger.error(f"è·å–å¤šæ—¥æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None
    
    def get_limit_up_stocks(self, trade_date: str) -> List[str]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ¶¨åœè‚¡ç¥¨åˆ—è¡¨
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ "YYYY-MM-DD"
            
        Returns:
            æ¶¨åœè‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            if not self.available:
                logger.warning("AKShareä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿæ¶¨åœåˆ—è¡¨")
                return ["000001", "600519", "000858"]
            
            logger.info(f"è·å– {trade_date} æ¶¨åœè‚¡ç¥¨åˆ—è¡¨...")
            
            # è°ƒç”¨AKShareæ¶¨åœè‚¡ç¥¨æ¥å£
            df = self.ak.stock_zt_pool_em(date=trade_date.replace("-", ""))
            
            if df is None or df.empty:
                logger.warning(f"æœªè·å–åˆ°æ¶¨åœæ•°æ®: {trade_date}")
                return []
            
            # æå–è‚¡ç¥¨ä»£ç 
            stocks = df['ä»£ç '].tolist() if 'ä»£ç ' in df.columns else []
            
            logger.info(f"âœ… è·å–åˆ° {len(stocks)} åªæ¶¨åœè‚¡ç¥¨")
            return stocks
            
        except Exception as e:
            logger.error(f"è·å–æ¶¨åœåˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
            return []
    
    def get_realtime_data(self, symbol: str) -> Optional[Dict]:
        """
        è·å–å®æ—¶è¡Œæƒ…æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å®æ—¶è¡Œæƒ…å­—å…¸
        """
        try:
            if not self.available:
                return None
            
            symbol_clean = symbol.replace(".SZ", "").replace(".SH", "")
            
            # è·å–å®æ—¶è¡Œæƒ…
            df = self.ak.stock_zh_a_spot_em()
            
            if df is None or df.empty:
                return None
            
            # æŸ¥æ‰¾ç›®æ ‡è‚¡ç¥¨
            stock_data = df[df['ä»£ç '] == symbol_clean]
            
            if stock_data.empty:
                return None
            
            # è½¬æ¢ä¸ºå­—å…¸
            result = {
                'symbol': symbol_clean,
                'name': stock_data['åç§°'].values[0],
                'price': stock_data['æœ€æ–°ä»·'].values[0],
                'change_pct': stock_data['æ¶¨è·Œå¹…'].values[0],
                'volume': stock_data['æˆäº¤é‡'].values[0],
                'amount': stock_data['æˆäº¤é¢'].values[0],
                'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return result
            
        except Exception as e:
            logger.error(f"è·å–å®æ—¶æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _standardize_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–æ•°æ®æ ¼å¼"""
        # é‡å‘½ååˆ—
        column_mapping = {
            'æ—¶é—´': 'time',
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount'
        }
        
        df = df.rename(columns=column_mapping)
        
        # ç¡®ä¿æ—¶é—´åˆ—
        if 'time' in df.columns:
            df['time'] = pd.to_datetime(df['time'])
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        required_cols = ['time', 'open', 'high', 'low', 'close', 'volume', 'amount']
        available_cols = [col for col in required_cols if col in df.columns]
        df = df[available_cols]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # åˆ é™¤ç¼ºå¤±å€¼
        df = df.dropna()
        
        return df
    
    def _generate_mock_data(self, trade_date: str) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        logger.info(f"ğŸ“ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {trade_date}")
        
        # ç”Ÿæˆäº¤æ˜“æ—¶é—´
        times = []
        
        # ä¸Šåˆ 9:30-11:30
        morning_times = pd.date_range(
            start=f"{trade_date} 09:30:00",
            end=f"{trade_date} 11:30:00",
            freq=self.freq
        )
        times.extend(morning_times)
        
        # ä¸‹åˆ 13:00-15:00
        afternoon_times = pd.date_range(
            start=f"{trade_date} 13:00:00",
            end=f"{trade_date} 15:00:00",
            freq=self.freq
        )
        times.extend(afternoon_times)
        
        n = len(times)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼ï¼ˆéšæœºæ¸¸èµ°ï¼‰
        base_price = 10.0
        returns = np.random.normal(0, 0.001, n)
        prices = base_price * np.exp(np.cumsum(returns))
        
        # ç”ŸæˆOHLC
        df = pd.DataFrame({
            'time': times,
            'open': prices * (1 + np.random.uniform(-0.002, 0.002, n)),
            'high': prices * (1 + np.random.uniform(0, 0.005, n)),
            'low': prices * (1 - np.random.uniform(0, 0.005, n)),
            'close': prices,
            'volume': np.random.randint(1000, 10000, n),
            'amount': np.random.randint(10000, 100000, n)
        })
        
        return df
    
    def _load_cache(self, symbol: str, trade_date: str) -> Optional[pd.DataFrame]:
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        try:
            cache_file = CACHE_DIR / f"{symbol}_{trade_date}_{self.freq}.pkl"
            
            if cache_file.exists():
                with open(cache_file, 'rb') as f:
                    data = pickle.load(f)
                return data
            
            return None
            
        except Exception as e:
            logger.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def _save_cache(self, symbol: str, trade_date: str, data: pd.DataFrame):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        try:
            cache_file = CACHE_DIR / f"{symbol}_{trade_date}_{self.freq}.pkl"
            
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
            
            logger.debug(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {cache_file}")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def clear_cache(self, symbol: Optional[str] = None):
        """æ¸…é™¤ç¼“å­˜"""
        try:
            if symbol:
                # æ¸…é™¤ç‰¹å®šè‚¡ç¥¨çš„ç¼“å­˜
                pattern = f"{symbol}_*_{self.freq}.pkl"
                for cache_file in CACHE_DIR.glob(pattern):
                    cache_file.unlink()
                    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤ç¼“å­˜: {cache_file}")
            else:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                for cache_file in CACHE_DIR.glob(f"*_{self.freq}.pkl"):
                    cache_file.unlink()
                logger.info("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
                
        except Exception as e:
            logger.error(f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")


class HighFreqDataManager:
    """é«˜é¢‘æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.data_sources = {
            '1min': AKShareHighFreqData('1min'),
            '5min': AKShareHighFreqData('5min'),
            '15min': AKShareHighFreqData('15min'),
            '30min': AKShareHighFreqData('30min'),
            '60min': AKShareHighFreqData('60min')
        }
    
    def get_data(
        self,
        symbol: str,
        freq: str,
        start_date: str,
        end_date: Optional[str] = None,
        use_cache: bool = True
    ) -> Optional[pd.DataFrame]:
        """
        è·å–é«˜é¢‘æ•°æ®çš„ç»Ÿä¸€æ¥å£
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            freq: æ•°æ®é¢‘ç‡
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºstart_dateï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            é«˜é¢‘æ•°æ®DataFrame
        """
        if freq not in self.data_sources:
            raise ValueError(f"ä¸æ”¯æŒçš„é¢‘ç‡: {freq}")
        
        data_source = self.data_sources[freq]
        
        if end_date is None or start_date == end_date:
            # å•æ—¥æ•°æ®
            return data_source.get_intraday_data(symbol, start_date, use_cache)
        else:
            # å¤šæ—¥æ•°æ®
            return data_source.get_multiple_days(symbol, start_date, end_date, use_cache)
    
    def get_cache_info(self) -> Dict[str, int]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        info = {}
        for freq in self.data_sources.keys():
            pattern = f"*_{freq}.pkl"
            count = len(list(CACHE_DIR.glob(pattern)))
            info[freq] = count
        return info
    
    def clear_all_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        for data_source in self.data_sources.values():
            data_source.clear_cache()


# å…¨å±€å®ä¾‹
highfreq_manager = HighFreqDataManager()


# ================== æ–°å¢åŠŸèƒ½: ç¼ è®ºç³»ç»Ÿæ•°æ®æ¥å£ ==================

def get_stock_hist_data(
    codes: List[str],
    start_date: str,
    end_date: str,
    period: str = "daily"
) -> Dict[str, pd.DataFrame]:
    """
    è·å–è‚¡ç¥¨å†å²æ•°æ®ï¼ˆç”¨äºç¼ è®ºç³»ç»Ÿï¼‰
    
    Args:
        codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆæ”¯æŒå¸¦åç¼€æˆ–çº¯æ•°å­—ï¼Œå¦‚ "000001" æˆ– "000001.SZ"ï¼‰
        start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD æ ¼å¼
        end_date: ç»“æŸæ—¥æœŸ YYYYMMDD æ ¼å¼
        period: æ•°æ®å‘¨æœŸ "daily"/"weekly"/"monthly"
    
    Returns:
        Dict[è‚¡ç¥¨ä»£ç , DataFrame] åŒ…å« datetime, open, high, low, close, volume, macd, macd_signal, rsi
    """
    import akshare as ak
    
    result = {}
    
    logger.info(f"å¼€å§‹è·å– {len(codes)} åªè‚¡ç¥¨çš„å†å²æ•°æ® ({start_date} è‡³ {end_date})")
    
    for idx, code in enumerate(codes, 1):
        try:
            # è½¬æ¢ä»£ç æ ¼å¼ï¼šç§»é™¤åç¼€å¾—åˆ°çº¯æ•°å­—
            clean_code = code.split('.')[0] if '.' in code else code
            
            logger.info(f"[{idx}/{len(codes)}] è·å– {clean_code} æ•°æ®...")
            
            # è°ƒç”¨ AKShare æ¥å£
            df = ak.stock_zh_a_hist(
                symbol=clean_code,
                period=period,
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"  # å‰å¤æƒ
            )
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {code} æœªè·å–åˆ°æ•°æ®")
                continue
            
            # è½¬æ¢ä¸ºç³»ç»Ÿæ ¼å¼
            df_formatted = convert_akshare_to_system_format(df, code)
            
            if df_formatted is None or df_formatted.empty:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {code} æ ¼å¼è½¬æ¢å¤±è´¥")
                continue
            
            # ç¡®å®šå®Œæ•´ä»£ç ï¼ˆå¸¦åç¼€ï¼‰
            if '.' in code:
                full_code = code
            else:
                # 6å¼€å¤´æ˜¯ä¸Šæµ·ï¼Œå¦åˆ™æ˜¯æ·±åœ³
                full_code = f"{code}.SH" if code.startswith('6') else f"{code}.SZ"
            
            result[full_code] = df_formatted
            logger.info(f"âœ… {full_code} æ•°æ®è·å–æˆåŠŸ: {len(df_formatted)} æ¡")
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.3)
            
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨ {code} æ•°æ®å¤±è´¥: {e}")
            continue
    
    logger.info(f"âœ… æ•°æ®è·å–å®Œæˆ: {len(result)}/{len(codes)} åªè‚¡ç¥¨æˆåŠŸ")
    return result


def convert_akshare_to_system_format(df: pd.DataFrame, code: str) -> Optional[pd.DataFrame]:
    """
    å°† AKShare è¿”å›çš„æ•°æ®æ ¼å¼è½¬æ¢ä¸ºç³»ç»Ÿéœ€è¦çš„æ ¼å¼
    
    Args:
        df: AKShare è¿”å›çš„åŸå§‹ DataFrame
        code: è‚¡ç¥¨ä»£ç 
    
    Returns:
        æ ¼å¼åŒ–åçš„ DataFrameï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡
    """
    try:
        # é‡å‘½ååˆ—ï¼ˆAKShare è¿”å›çš„æ˜¯ä¸­æ–‡åˆ—åï¼‰
        df = df.rename(columns={
            'æ—¥æœŸ': 'datetime',
            'å¼€ç›˜': 'open',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æ”¶ç›˜': 'close',
            'æˆäº¤é‡': 'volume'
        })
        
        # ç¡®ä¿å¿…éœ€åˆ—å­˜åœ¨
        required_cols = ['datetime', 'open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            logger.error(f"æ•°æ®ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
            return None
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        df['datetime'] = pd.to_datetime(df['datetime'])
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ­£ç¡®ç±»å‹
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        df = df.dropna(subset=['open', 'high', 'low', 'close'])
        
        if len(df) < 30:
            logger.warning(f"æ•°æ®ç‚¹å¤ªå°‘ ({len(df)} æ¡)ï¼Œå¯èƒ½æ— æ³•è®¡ç®—æŒ‡æ ‡")
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        try:
            # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ pandas_ta
            import pandas_ta as ta
            df.ta.macd(append=True)  # æ·»åŠ  MACD_12_26_9, MACDh_12_26_9, MACDs_12_26_9
            df.ta.rsi(length=14, append=True)  # æ·»åŠ  RSI_14
            
            # é‡å‘½åæŠ€æœ¯æŒ‡æ ‡åˆ—
            df = df.rename(columns={
                'MACD_12_26_9': 'macd',
                'MACDs_12_26_9': 'macd_signal',
                'RSI_14': 'rsi'
            })
            
        except ImportError:
            logger.warning("pandas_ta æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
            # æ–¹æ³•2ï¼šæ‰‹åŠ¨è®¡ç®—ç®€åŒ–ç‰ˆæŠ€æœ¯æŒ‡æ ‡
            df = calculate_indicators_manual(df)
        except Exception as e:
            logger.warning(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•")
            df = calculate_indicators_manual(df)
        
        # é€‰æ‹©æœ€ç»ˆéœ€è¦çš„åˆ—
        final_cols = ['datetime', 'open', 'high', 'low', 'close', 'volume', 'macd', 'macd_signal', 'rsi']
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨ï¼ˆä¸å­˜åœ¨çš„å¡«å……NaNï¼‰
        for col in final_cols:
            if col not in df.columns:
                df[col] = np.nan
        
        df = df[final_cols]
        
        # åˆ é™¤æ‰€æœ‰æ•°æ®éƒ½æ˜¯NaNçš„è¡Œ
        df = df.dropna(how='all')
        
        return df
        
    except Exception as e:
        logger.error(f"æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥ ({code}): {e}", exc_info=True)
        return None


def calculate_indicators_manual(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ‰‹åŠ¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä¾èµ– pandas_taï¼‰
    """
    try:
        # è®¡ç®— MACD (12, 26, 9)
        ema12 = df['close'].ewm(span=12, adjust=False).mean()
        ema26 = df['close'].ewm(span=26, adjust=False).mean()
        df['macd'] = ema12 - ema26
        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
        
        # è®¡ç®— RSI (14)
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        return df
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨è®¡ç®—æŒ‡æ ‡å¤±è´¥: {e}")
        # å¡«å……é»˜è®¤å€¼
        df['macd'] = 0.0
        df['macd_signal'] = 0.0
        df['rsi'] = 50.0
        return df


def get_limit_up_stocks_list(date: Optional[str] = None) -> List[str]:
    """
    è·å–æ¶¨åœæ¿è‚¡ç¥¨åˆ—è¡¨ï¼ˆç”¨äºç¼ è®ºç³»ç»Ÿï¼‰
    
    Args:
        date: æ—¥æœŸ YYYYMMDD æ ¼å¼ï¼Œé»˜è®¤ä¸ºä»Šå¤©
    
    Returns:
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¸¦åç¼€ï¼Œå¦‚ ["000001.SZ", "600519.SH"]ï¼‰
    """
    try:
        import akshare as ak
        
        target_date = date or datetime.now().strftime("%Y%m%d")
        logger.info(f"è·å– {target_date} çš„æ¶¨åœæ¿è‚¡ç¥¨...")
        
        df = ak.stock_zt_pool_em(date=target_date)
        
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {target_date} æ— æ¶¨åœæ¿æ•°æ®")
            return []
        
        # æå–è‚¡ç¥¨ä»£ç 
        if 'ä»£ç ' not in df.columns:
            logger.error("æ¶¨åœæ¿æ•°æ®æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘'ä»£ç 'åˆ—")
            return []
        
        codes = df['ä»£ç '].astype(str).tolist()
        
        # æ·»åŠ åç¼€
        full_codes = []
        for code in codes:
            if code.startswith('6'):
                full_codes.append(f"{code}.SH")
            elif code.startswith(('0', '3')):
                full_codes.append(f"{code}.SZ")
            else:
                logger.warning(f"æœªçŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼: {code}")
        
        logger.info(f"âœ… è·å–åˆ° {len(full_codes)} åªæ¶¨åœè‚¡ç¥¨")
        return full_codes
        
    except Exception as e:
        logger.error(f"è·å–æ¶¨åœæ¿è‚¡ç¥¨å¤±è´¥: {e}", exc_info=True)
        return []


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•å•æ—¥æ•°æ®è·å–
    data_source = AKShareHighFreqData(freq="1min")
    
    # æµ‹è¯•æ—¥æœŸ
    test_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    print(f"\næµ‹è¯•è·å– 000001 {test_date} çš„1åˆ†é’Ÿæ•°æ®:")
    df = data_source.get_intraday_data("000001", test_date)
    
    if df is not None:
        print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
        print(df.head())
        print(df.tail())
    else:
        print("âŒ è·å–å¤±è´¥")
    
    # æµ‹è¯•æ¶¨åœåˆ—è¡¨
    print(f"\næµ‹è¯•è·å– {test_date} æ¶¨åœè‚¡ç¥¨:")
    limit_up_stocks = data_source.get_limit_up_stocks(test_date)
    print(f"âœ… æ¶¨åœè‚¡ç¥¨: {limit_up_stocks[:10]}")
