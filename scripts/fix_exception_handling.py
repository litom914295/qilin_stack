"""
å¼‚å¸¸å¤„ç†è§„èŒƒåŒ–è„šæœ¬
è‡ªåŠ¨ä¿®å¤è£¸éœ²çš„exceptè¯­å¥
"""

import os
import re
import logging
from pathlib import Path
from typing import List, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExceptionHandlingFixer:
    """å¼‚å¸¸å¤„ç†ä¿®å¤å™¨"""
    
    def __init__(self, target_dirs: List[str]):
        self.target_dirs = target_dirs
        self.fixes_count = 0
        self.files_processed = 0
        
    def process_files(self):
        """å¤„ç†æ‰€æœ‰Pythonæ–‡ä»¶"""
        for target_dir in self.target_dirs:
            for py_file in Path(target_dir).rglob("*.py"):
                if self._should_skip_file(py_file):
                    continue
                    
                try:
                    self._process_file(py_file)
                    self.files_processed += 1
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {py_file}: {e}")
        
        logger.info(f"\nâœ… å®Œæˆï¼å¤„ç†äº† {self.files_processed} ä¸ªæ–‡ä»¶ï¼Œä¿®å¤äº† {self.fixes_count} å¤„å¼‚å¸¸å¤„ç†")
    
    def _should_skip_file(self, filepath: Path) -> bool:
        """æ˜¯å¦åº”è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            '.qilin',
            '__pycache__',
            '.git',
            'venv',
            'node_modules',
            'build',
            'dist',
            '.pytest_cache'
        ]
        
        return any(pattern in str(filepath) for pattern in skip_patterns)
    
    def _process_file(self, filepath: Path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤æ¨¡å¼1: except: pass
        content, count1 = self._fix_bare_except_pass(content)
        
        # ä¿®å¤æ¨¡å¼2: except Exception: pass  
        content, count2 = self._fix_exception_pass(content)
        
        # ä¿®å¤æ¨¡å¼3: except: åé¢æ²¡æœ‰å…·ä½“å¤„ç†
        content, count3 = self._fix_bare_except(content)
        
        total_fixes = count1 + count2 + count3
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.fixes_count += total_fixes
            logger.info(f"âœ… {filepath.name}: ä¿®å¤ {total_fixes} å¤„")
    
    def _fix_bare_except_pass(self, content: str) -> Tuple[str, int]:
        """ä¿®å¤ except: pass æ¨¡å¼"""
        pattern = r'(\s+)except:\s*\n\s+pass'
        
        def replacer(match):
            indent = match.group(1)
            return f'''{indent}except Exception as e:
{indent}    logger.warning(f"æ“ä½œå¤±è´¥: {{e}}")'''
        
        new_content, count = re.subn(pattern, replacer, content)
        return new_content, count
    
    def _fix_exception_pass(self, content: str) -> Tuple[str, int]:
        """ä¿®å¤ except Exception: pass æ¨¡å¼"""
        pattern = r'(\s+)except Exception:\s*\n\s+pass'
        
        def replacer(match):
            indent = match.group(1)
            return f'''{indent}except Exception as e:
{indent}    logger.warning(f"æ“ä½œå¤±è´¥: {{e}}")'''
        
        new_content, count = re.subn(pattern, replacer, content)
        return new_content, count
    
    def _fix_bare_except(self, content: str) -> Tuple[str, int]:
        """ä¿®å¤è£¸éœ²çš„ except: æ¨¡å¼ï¼ˆåé¢æœ‰å†…å®¹çš„ï¼‰"""
        # è¿™ä¸ªæ¯”è¾ƒå¤æ‚ï¼Œåªå¤„ç†ç®€å•æƒ…å†µ
        pattern = r'(\s+)except:\s*\n(\s+)([^#\n])'
        
        def replacer(match):
            indent1 = match.group(1)
            indent2 = match.group(2)
            first_char = match.group(3)
            return f'{indent1}except Exception as e:\n{indent2}{first_char}'
        
        new_content, count = re.subn(pattern, replacer, content)
        return new_content, count


def fix_specific_files():
    """ä¿®å¤ç‰¹å®šå·²çŸ¥æœ‰é—®é¢˜çš„æ–‡ä»¶"""
    fixes = {
        'app/core/cache_manager.py': [
            (89, 90, '''                except (IOError, pickle.PickleError) as e:
                    logger.debug(f"è¯»å–ç£ç›˜ç¼“å­˜å¤±è´¥: {e}")'''),
            (131, 132, '''            except (IOError, pickle.PickleError) as e:
                logger.debug(f"ä¿å­˜ç£ç›˜ç¼“å­˜å¤±è´¥: {e}")'''),
            (182, 183, '''            except (IOError, pickle.PickleError) as e:
                logger.debug(f"æ¸…ç†ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")'''),
        ]
    }
    
    for filepath, line_fixes in fixes.items():
        full_path = Path('G:/test/qilin_stack') / filepath
        if not full_path.exists():
            logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            continue
        
        with open(full_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # æŒ‰è¡Œå·å€’åºå¤„ç†ï¼Œé¿å…è¡Œå·åç§»
        for start_line, end_line, new_code in sorted(line_fixes, reverse=True):
            # åˆ é™¤æ—§çš„exceptå—
            del lines[start_line-1:end_line-1]
            # æ’å…¥æ–°ä»£ç 
            lines.insert(start_line-1, new_code + '\n')
        
        with open(full_path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        
        logger.info(f"âœ… æ‰‹åŠ¨ä¿®å¤: {filepath}")


if __name__ == "__main__":
    print("=" * 60)
    print("å¼‚å¸¸å¤„ç†è§„èŒƒåŒ–å·¥å…·")
    print("=" * 60)
    
    # é¦–å…ˆä¿®å¤ç‰¹å®šæ–‡ä»¶
    print("\nğŸ“ ä¿®å¤å·²çŸ¥é—®é¢˜æ–‡ä»¶...")
    fix_specific_files()
    
    # ç„¶åæ‰¹é‡å¤„ç†
    print("\nğŸ” æ‰¹é‡æ‰«æä¿®å¤...")
    target_directories = [
        'G:/test/qilin_stack/app',
        'G:/test/qilin_stack/layer2_qlib',
        'G:/test/qilin_stack/qilin_stack',
        'G:/test/qilin_stack/tradingagents_integration',
    ]
    
    fixer = ExceptionHandlingFixer(target_directories)
    fixer.process_files()
    
    print("\n" + "=" * 60)
    print("âœ… å¼‚å¸¸å¤„ç†è§„èŒƒåŒ–å®Œæˆï¼")
    print("=" * 60)
    print("\nå»ºè®®:")
    print("1. è¿è¡Œæµ‹è¯•ç¡®ä¿æ²¡æœ‰ç ´ååŠŸèƒ½")
    print("2. Reviewä¿®æ”¹çš„æ–‡ä»¶")
    print("3. æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å¼‚å¸¸ç±»å‹")
