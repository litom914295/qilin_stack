"""
æ•°æ®è´¨é‡å®¡è®¡è„šæœ¬

æ ¹æ® docs/IMPROVEMENT_ROADMAP.md é˜¶æ®µä¸€ä»»åŠ¡1.1
ç›®æ ‡ï¼šè¯†åˆ«æ•°æ®æºè´¨é‡é—®é¢˜ï¼Œä¸ºåç»­ç‰¹å¾æ¸…ç†æä¾›ä¾æ®

åŠŸèƒ½ï¼š
1. ç»Ÿè®¡å„æ•°æ®æºï¼ˆQlib/AKShare/Tushareï¼‰çš„è¦†ç›–ç‡
2. æ£€æµ‹ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼æ¯”ä¾‹
3. å¯¹æ¯”ä¸åŒæ•°æ®æºçš„ä¸€è‡´æ€§
4. è¯†åˆ«"é«˜é¢‘ç‰¹å¾"çš„çœŸå®æ•°æ®ç²’åº¦
5. ç”Ÿæˆè¯¦ç»†çš„å®¡è®¡æŠ¥å‘Š

ä½œè€…ï¼šQilin Quant Team
åˆ›å»ºï¼š2025-10-30
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import sys
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from data_layer.premium_data_provider import PremiumDataProvider


class DataQualityAuditor:
    """æ•°æ®è´¨é‡å®¡è®¡å™¨"""
    
    def __init__(self, start_date: str = "2023-01-01", end_date: str = None):
        """
        åˆå§‹åŒ–å®¡è®¡å™¨
        
        Args:
            start_date: å®¡è®¡å¼€å§‹æ—¥æœŸ
            end_date: å®¡è®¡ç»“æŸæ—¥æœŸï¼ˆé»˜è®¤ä¸ºä»Šå¤©ï¼‰
        """
        self.start_date = start_date
        self.end_date = end_date or datetime.now().strftime('%Y-%m-%d')
        
        # å®¡è®¡ç»“æœ
        self.audit_results = {}
        self.report_sections = []
        
        print(f"ğŸ“Š æ•°æ®è´¨é‡å®¡è®¡åˆå§‹åŒ–")
        print(f"   å®¡è®¡åŒºé—´: {self.start_date} ~ {self.end_date}")
        print("=" * 70)
    
    def audit_data_sources_coverage(self) -> Dict:
        """å®¡è®¡å„æ•°æ®æºçš„è¦†ç›–ç‡"""
        print("\nğŸ” 1. å®¡è®¡æ•°æ®æºè¦†ç›–ç‡...")
        
        coverage_stats = {
            'qlib': {'available': False, 'coverage': 0, 'status': 'æœªæ£€æµ‹'},
            'akshare': {'available': False, 'coverage': 0, 'status': 'æœªæ£€æµ‹'},
            'tushare': {'available': False, 'coverage': 0, 'status': 'æœªæ£€æµ‹'}
        }
        
        # 1. æ£€æµ‹Qlib
        try:
            import qlib
            from qlib.data import D
            
            # å°è¯•è·å–æ•°æ®
            test_symbols = ['SH600000', 'SZ000001']
            data_count = 0
            for symbol in test_symbols:
                try:
                    df = D.features([symbol], ['$close', '$volume'], 
                                   start_time=self.start_date, end_time=self.end_date)
                    if df is not None and not df.empty:
                        data_count += len(df)
                except:
                    pass
            
            coverage_stats['qlib']['available'] = data_count > 0
            coverage_stats['qlib']['coverage'] = data_count
            coverage_stats['qlib']['status'] = 'âœ… å¯ç”¨' if data_count > 0 else 'âŒ æ— æ•°æ®'
            
        except ImportError:
            coverage_stats['qlib']['status'] = 'âŒ æœªå®‰è£…'
        except Exception as e:
            coverage_stats['qlib']['status'] = f'âš ï¸ å¼‚å¸¸: {str(e)[:50]}'
        
        # 2. æ£€æµ‹AKShare
        try:
            import akshare as ak
            
            # æµ‹è¯•è·å–ä»Šæ—¥æ¶¨åœæ•°æ®
            today = datetime.now().strftime('%Y%m%d')
            df = ak.stock_zt_pool_em(date=today)
            
            coverage_stats['akshare']['available'] = not df.empty
            coverage_stats['akshare']['coverage'] = len(df) if not df.empty else 0
            coverage_stats['akshare']['status'] = 'âœ… å¯ç”¨'
            
        except ImportError:
            coverage_stats['akshare']['status'] = 'âŒ æœªå®‰è£…'
        except Exception as e:
            coverage_stats['akshare']['status'] = f'âš ï¸ å¼‚å¸¸: {str(e)[:50]}'
        
        # 3. æ£€æµ‹Tushare
        try:
            import tushare as ts
            
            # æ£€æŸ¥æ˜¯å¦æœ‰tokené…ç½®
            token_file = project_root / 'config' / 'tushare_token.txt'
            if token_file.exists():
                with open(token_file, 'r') as f:
                    token = f.read().strip()
                ts.set_token(token)
                
                pro = ts.pro_api()
                df = pro.daily(trade_date='20240101', limit=10)
                
                coverage_stats['tushare']['available'] = not df.empty
                coverage_stats['tushare']['coverage'] = len(df)
                coverage_stats['tushare']['status'] = 'âœ… å¯ç”¨'
            else:
                coverage_stats['tushare']['status'] = 'âš ï¸ æœªé…ç½®Token'
                
        except ImportError:
            coverage_stats['tushare']['status'] = 'âŒ æœªå®‰è£…'
        except Exception as e:
            coverage_stats['tushare']['status'] = f'âš ï¸ å¼‚å¸¸: {str(e)[:50]}'
        
        # æ‰“å°ç»“æœ
        print("\nğŸ“ˆ æ•°æ®æºè¦†ç›–ç‡ç»Ÿè®¡ï¼š")
        for source, stats in coverage_stats.items():
            print(f"   {source.upper():10s}: {stats['status']:20s} | æ•°æ®é‡: {stats['coverage']}")
        
        self.audit_results['coverage'] = coverage_stats
        return coverage_stats
    
    def audit_missing_values(self, sample_size: int = 100) -> Dict:
        """å®¡è®¡ç¼ºå¤±å€¼æƒ…å†µ"""
        print(f"\nğŸ” 2. å®¡è®¡ç¼ºå¤±å€¼ï¼ˆé‡‡æ · {sample_size} æ¡è®°å½•ï¼‰...")
        
        missing_stats = {}
        
        try:
            # ä½¿ç”¨AKShareä½œä¸ºä¸»è¦æ•°æ®æºè¿›è¡Œå®¡è®¡
            import akshare as ak
            
            # è·å–æœ€è¿‘çš„æ¶¨åœæ•°æ®
            recent_date = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            df = ak.stock_zt_pool_em(date=recent_date)
            
            if df.empty:
                print("   âš ï¸ æ— æ³•è·å–æ ·æœ¬æ•°æ®")
                return {}
            
            # é™åˆ¶æ ·æœ¬å¤§å°
            df_sample = df.head(sample_size)
            
            # ç»Ÿè®¡æ¯åˆ—çš„ç¼ºå¤±å€¼
            total_rows = len(df_sample)
            for col in df_sample.columns:
                missing_count = df_sample[col].isna().sum()
                missing_rate = missing_count / total_rows * 100
                
                missing_stats[col] = {
                    'missing_count': int(missing_count),
                    'missing_rate': f"{missing_rate:.2f}%",
                    'status': 'âœ… æ­£å¸¸' if missing_rate < 5 else 'âš ï¸ é«˜ç¼ºå¤±' if missing_rate < 20 else 'âŒ ä¸¥é‡ç¼ºå¤±'
                }
            
            # æ‰“å°é«˜ç¼ºå¤±ç‡å­—æ®µ
            print("\n   é«˜ç¼ºå¤±ç‡å­—æ®µï¼ˆ>5%ï¼‰ï¼š")
            high_missing = {k: v for k, v in missing_stats.items() if float(v['missing_rate'].rstrip('%')) > 5}
            if high_missing:
                for col, stats in high_missing.items():
                    print(f"   - {col:20s}: {stats['missing_rate']:8s} {stats['status']}")
            else:
                print("   âœ… æœªå‘ç°é«˜ç¼ºå¤±ç‡å­—æ®µ")
                
        except Exception as e:
            print(f"   âŒ å®¡è®¡å¤±è´¥: {e}")
        
        self.audit_results['missing_values'] = missing_stats
        return missing_stats
    
    def audit_outliers(self, sample_size: int = 100) -> Dict:
        """å®¡è®¡å¼‚å¸¸å€¼æƒ…å†µ"""
        print(f"\nğŸ” 3. å®¡è®¡å¼‚å¸¸å€¼ï¼ˆé‡‡æ · {sample_size} æ¡è®°å½•ï¼‰...")
        
        outlier_stats = {}
        
        try:
            import akshare as ak
            
            recent_date = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            df = ak.stock_zt_pool_em(date=recent_date)
            
            if df.empty:
                print("   âš ï¸ æ— æ³•è·å–æ ·æœ¬æ•°æ®")
                return {}
            
            df_sample = df.head(sample_size)
            
            # æ£€æµ‹æ•°å€¼å‹åˆ—çš„å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
            numeric_cols = df_sample.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                try:
                    Q1 = df_sample[col].quantile(0.25)
                    Q3 = df_sample[col].quantile(0.75)
                    IQR = Q3 - Q1
                    
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    outliers = df_sample[(df_sample[col] < lower_bound) | (df_sample[col] > upper_bound)]
                    outlier_count = len(outliers)
                    outlier_rate = outlier_count / len(df_sample) * 100
                    
                    outlier_stats[col] = {
                        'outlier_count': int(outlier_count),
                        'outlier_rate': f"{outlier_rate:.2f}%",
                        'lower_bound': float(lower_bound),
                        'upper_bound': float(upper_bound),
                        'status': 'âœ… æ­£å¸¸' if outlier_rate < 5 else 'âš ï¸ æœ‰å¼‚å¸¸'
                    }
                except:
                    pass
            
            # æ‰“å°å¼‚å¸¸å­—æ®µ
            print("\n   å¼‚å¸¸å€¼æ£€æµ‹ç»“æœï¼š")
            high_outlier = {k: v for k, v in outlier_stats.items() if float(v['outlier_rate'].rstrip('%')) > 5}
            if high_outlier:
                for col, stats in high_outlier.items():
                    print(f"   - {col:20s}: {stats['outlier_rate']:8s} {stats['status']}")
            else:
                print("   âœ… æœªå‘ç°é«˜å¼‚å¸¸ç‡å­—æ®µ")
                
        except Exception as e:
            print(f"   âŒ å®¡è®¡å¤±è´¥: {e}")
        
        self.audit_results['outliers'] = outlier_stats
        return outlier_stats
    
    def audit_high_freq_features(self) -> Dict:
        """å®¡è®¡é«˜é¢‘ç‰¹å¾çš„æ•°æ®ç²’åº¦"""
        print("\nğŸ” 4. å®¡è®¡é«˜é¢‘ç‰¹å¾æ•°æ®ç²’åº¦...")
        
        high_freq_features = {
            'å°å•ç¨³å®šæ€§': {'data_source': 'æœªçŸ¥', 'granularity': 'æœªçŸ¥', 'reliability': 0},
            'å¤§å•æµå…¥èŠ‚å¥': {'data_source': 'æœªçŸ¥', 'granularity': 'æœªçŸ¥', 'reliability': 0},
            'æˆäº¤èç¼©åº¦': {'data_source': 'æœªçŸ¥', 'granularity': 'æœªçŸ¥', 'reliability': 0},
            'åˆ†æ—¶å½¢æ€': {'data_source': 'æœªçŸ¥', 'granularity': 'æœªçŸ¥', 'reliability': 0},
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰L2æ•°æ®
        l2_available = False
        
        # æ£€æŸ¥åˆ†é’Ÿæ•°æ®å¯ç”¨æ€§
        minute_data_available = False
        try:
            import akshare as ak
            # å°è¯•è·å–åˆ†é’Ÿæ•°æ®
            df_minute = ak.stock_zh_a_hist_min_em(symbol="000001", period='1', adjust='')
            minute_data_available = not df_minute.empty
        except:
            pass
        
        # è¯„ä¼°ç‰¹å¾å¯é æ€§
        print("\n   é«˜é¢‘ç‰¹å¾æ•°æ®æºè¯„ä¼°ï¼š")
        
        if l2_available:
            for feature in high_freq_features:
                high_freq_features[feature]['data_source'] = 'Level-2é€ç¬”'
                high_freq_features[feature]['granularity'] = 'é€ç¬”/å¿«ç…§'
                high_freq_features[feature]['reliability'] = 95
                print(f"   âœ… {feature:15s}: Level-2æ•°æ®ï¼Œå¯é æ€§ 95%")
        elif minute_data_available:
            for feature in high_freq_features:
                high_freq_features[feature]['data_source'] = 'åˆ†é’Ÿçº¿æ•°æ®'
                high_freq_features[feature]['granularity'] = '1åˆ†é’Ÿ'
                high_freq_features[feature]['reliability'] = 60
                print(f"   âš ï¸ {feature:15s}: åˆ†é’Ÿæ•°æ®æ¨¡æ‹Ÿï¼Œå¯é æ€§ 60%")
        else:
            for feature in high_freq_features:
                high_freq_features[feature]['data_source'] = 'æ—¥çº¿æ•°æ®'
                high_freq_features[feature]['granularity'] = 'æ—¥çº¿'
                high_freq_features[feature]['reliability'] = 30
                print(f"   âŒ {feature:15s}: æ—¥çº¿æ•°æ®æ¨¡æ‹Ÿï¼Œå¯é æ€§ 30% âš ï¸ å»ºè®®ç¦ç”¨")
        
        print("\n   ğŸ’¡ å»ºè®®ï¼š")
        avg_reliability = np.mean([v['reliability'] for v in high_freq_features.values()])
        if avg_reliability < 50:
            print("   âš ï¸ é«˜é¢‘ç‰¹å¾å¹³å‡å¯é æ€§ <50%ï¼Œå¼ºçƒˆå»ºè®®æš‚æ—¶ç¦ç”¨è¿™äº›ç‰¹å¾ï¼")
            print("   ğŸ“Œ åœ¨è·å¾—çœŸå®L2æ•°æ®å‰ï¼Œåº”ä½¿ç”¨æ—¥çº¿å¯é ç‰¹å¾æ„å»ºåŸºå‡†æ¨¡å‹")
        elif avg_reliability < 70:
            print("   âš ï¸ é«˜é¢‘ç‰¹å¾å¯é æ€§ä¸­ç­‰ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨å¹¶å¯†åˆ‡ç›‘æ§æ•ˆæœ")
        else:
            print("   âœ… é«˜é¢‘ç‰¹å¾å¯é æ€§è¾ƒé«˜ï¼Œå¯ä»¥ä½¿ç”¨")
        
        self.audit_results['high_freq_features'] = high_freq_features
        return high_freq_features
    
    def audit_data_consistency(self, test_symbols: List[str] = None) -> Dict:
        """å®¡è®¡ä¸åŒæ•°æ®æºçš„ä¸€è‡´æ€§"""
        print("\nğŸ” 5. å®¡è®¡æ•°æ®æºä¸€è‡´æ€§...")
        
        if test_symbols is None:
            test_symbols = ['000001', '600000']  # é»˜è®¤æµ‹è¯•ä¸¤åªè‚¡ç¥¨
        
        consistency_results = {}
        
        print(f"\n   æµ‹è¯•è‚¡ç¥¨: {', '.join(test_symbols)}")
        
        for symbol in test_symbols:
            print(f"\n   æ£€æµ‹ {symbol}...")
            symbol_results = {}
            
            # å°è¯•ä»ä¸åŒæ•°æ®æºè·å–ç›¸åŒæ—¥æœŸçš„æ”¶ç›˜ä»·
            test_date = '20240101'
            
            # AKShare
            try:
                import akshare as ak
                symbol_with_prefix = f"sz{symbol}" if symbol.startswith('0') or symbol.startswith('3') else f"sh{symbol}"
                df_ak = ak.stock_zh_a_hist(symbol=symbol, period="daily", adjust="")
                if not df_ak.empty:
                    df_ak['æ—¥æœŸ'] = pd.to_datetime(df_ak['æ—¥æœŸ'])
                    close_ak = df_ak[df_ak['æ—¥æœŸ'] == pd.to_datetime(test_date)]['æ”¶ç›˜'].values
                    symbol_results['akshare'] = float(close_ak[0]) if len(close_ak) > 0 else None
            except Exception as e:
                symbol_results['akshare'] = None
                print(f"      AKShareè·å–å¤±è´¥: {str(e)[:50]}")
            
            # å¯¹æ¯”ç»“æœ
            if symbol_results:
                consistency_results[symbol] = symbol_results
                print(f"      æ•°æ®ç‚¹æ•°: {len([v for v in symbol_results.values() if v is not None])}")
        
        if consistency_results:
            print("\n   âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ")
        else:
            print("\n   âš ï¸ æ— æ³•è·å–è¶³å¤Ÿæ•°æ®è¿›è¡Œä¸€è‡´æ€§å¯¹æ¯”")
        
        self.audit_results['consistency'] = consistency_results
        return consistency_results
    
    def generate_report(self, output_path: str = None) -> str:
        """ç”Ÿæˆå®¡è®¡æŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆå®¡è®¡æŠ¥å‘Š...")
        
        if output_path is None:
            output_path = project_root / 'reports' / 'data_quality_audit_report.md'
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        report = []
        report.append("# æ•°æ®è´¨é‡å®¡è®¡æŠ¥å‘Š\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append(f"**å®¡è®¡åŒºé—´**: {self.start_date} ~ {self.end_date}\n")
        report.append(f"**ä»»åŠ¡æ¥æº**: docs/IMPROVEMENT_ROADMAP.md - é˜¶æ®µä¸€ä»»åŠ¡1.1\n")
        report.append("\n---\n\n")
        
        # 1. æ•°æ®æºè¦†ç›–ç‡
        report.append("## 1. æ•°æ®æºè¦†ç›–ç‡\n\n")
        if 'coverage' in self.audit_results:
            report.append("| æ•°æ®æº | çŠ¶æ€ | æ•°æ®é‡ |\n")
            report.append("|--------|------|--------|\n")
            for source, stats in self.audit_results['coverage'].items():
                report.append(f"| {source.upper()} | {stats['status']} | {stats['coverage']} |\n")
        report.append("\n")
        
        # 2. ç¼ºå¤±å€¼ç»Ÿè®¡
        report.append("## 2. ç¼ºå¤±å€¼ç»Ÿè®¡\n\n")
        if 'missing_values' in self.audit_results:
            high_missing = {k: v for k, v in self.audit_results['missing_values'].items() 
                          if float(v['missing_rate'].rstrip('%')) > 5}
            if high_missing:
                report.append("**é«˜ç¼ºå¤±ç‡å­—æ®µï¼ˆ>5%ï¼‰**:\n\n")
                report.append("| å­—æ®µ | ç¼ºå¤±ç‡ | çŠ¶æ€ |\n")
                report.append("|------|--------|------|\n")
                for col, stats in high_missing.items():
                    report.append(f"| {col} | {stats['missing_rate']} | {stats['status']} |\n")
            else:
                report.append("âœ… **æœªå‘ç°é«˜ç¼ºå¤±ç‡å­—æ®µ**\n")
        report.append("\n")
        
        # 3. å¼‚å¸¸å€¼ç»Ÿè®¡
        report.append("## 3. å¼‚å¸¸å€¼ç»Ÿè®¡\n\n")
        if 'outliers' in self.audit_results:
            high_outlier = {k: v for k, v in self.audit_results['outliers'].items() 
                          if float(v['outlier_rate'].rstrip('%')) > 5}
            if high_outlier:
                report.append("**é«˜å¼‚å¸¸ç‡å­—æ®µï¼ˆ>5%ï¼‰**:\n\n")
                report.append("| å­—æ®µ | å¼‚å¸¸ç‡ | çŠ¶æ€ |\n")
                report.append("|------|--------|------|\n")
                for col, stats in high_outlier.items():
                    report.append(f"| {col} | {stats['outlier_rate']} | {stats['status']} |\n")
            else:
                report.append("âœ… **æœªå‘ç°é«˜å¼‚å¸¸ç‡å­—æ®µ**\n")
        report.append("\n")
        
        # 4. é«˜é¢‘ç‰¹å¾è¯„ä¼°
        report.append("## 4. é«˜é¢‘ç‰¹å¾æ•°æ®ç²’åº¦è¯„ä¼°\n\n")
        if 'high_freq_features' in self.audit_results:
            report.append("| ç‰¹å¾ | æ•°æ®æº | ç²’åº¦ | å¯é æ€§ |\n")
            report.append("|------|--------|------|--------|\n")
            for feature, stats in self.audit_results['high_freq_features'].items():
                reliability_emoji = "âœ…" if stats['reliability'] > 70 else "âš ï¸" if stats['reliability'] > 50 else "âŒ"
                report.append(f"| {feature} | {stats['data_source']} | {stats['granularity']} | {reliability_emoji} {stats['reliability']}% |\n")
            
            avg_reliability = np.mean([v['reliability'] for v in self.audit_results['high_freq_features'].values()])
            report.append(f"\n**å¹³å‡å¯é æ€§**: {avg_reliability:.1f}%\n\n")
            
            if avg_reliability < 50:
                report.append("### âš ï¸ å…³é”®å»ºè®®\n\n")
                report.append("é«˜é¢‘ç‰¹å¾å¹³å‡å¯é æ€§ <50%ï¼Œ**å¼ºçƒˆå»ºè®®æš‚æ—¶ç¦ç”¨è¿™äº›ç‰¹å¾**ï¼\n\n")
                report.append("åœ¨è·å¾—çœŸå®L2æ•°æ®å‰ï¼Œåº”ä½¿ç”¨æ—¥çº¿å¯é ç‰¹å¾æ„å»ºåŸºå‡†æ¨¡å‹ã€‚\n\n")
        
        # 5. å…³é”®å‘ç°ä¸å»ºè®®
        report.append("## 5. å…³é”®å‘ç°ä¸å»ºè®®\n\n")
        report.append("### ğŸ” å…³é”®å‘ç°\n\n")
        
        # æ ¹æ®å®¡è®¡ç»“æœæ€»ç»“
        if 'high_freq_features' in self.audit_results:
            avg_rel = np.mean([v['reliability'] for v in self.audit_results['high_freq_features'].values()])
            if avg_rel < 50:
                report.append("1. âŒ **é«˜é¢‘ç‰¹å¾ä¸å¯é **: å½“å‰é«˜é¢‘ç‰¹å¾åŸºäºä½ç²’åº¦æ•°æ®ï¼ˆæ—¥çº¿æˆ–åˆ†é’Ÿçº¿ï¼‰ï¼Œå¯é æ€§ä¸¥é‡ä¸è¶³\n")
            elif avg_rel < 70:
                report.append("1. âš ï¸ **é«˜é¢‘ç‰¹å¾å¯é æ€§ä¸­ç­‰**: åŸºäºåˆ†é’Ÿæ•°æ®æ¨¡æ‹Ÿï¼Œéœ€è°¨æ…ä½¿ç”¨\n")
            else:
                report.append("1. âœ… **é«˜é¢‘ç‰¹å¾å¯ç”¨**: æ•°æ®ç²’åº¦æ»¡è¶³è¦æ±‚\n")
        
        if 'coverage' in self.audit_results:
            available_sources = [k for k, v in self.audit_results['coverage'].items() if v['available']]
            report.append(f"2. ğŸ“Š **å¯ç”¨æ•°æ®æº**: {', '.join([s.upper() for s in available_sources])}\n")
        
        report.append("\n### ğŸ’¡ ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®\n\n")
        report.append("æ ¹æ® `docs/IMPROVEMENT_ROADMAP.md` é˜¶æ®µä¸€è®¡åˆ’ï¼š\n\n")
        report.append("1. âœ… **å®Œæˆ**: æ•°æ®è´¨é‡å®¡è®¡ï¼ˆå½“å‰ä»»åŠ¡ï¼‰\n")
        report.append("2. â­ï¸ **ä¸‹ä¸€æ­¥**: æ‰§è¡Œé«˜é¢‘ç‰¹å¾å¯é æ€§æµ‹è¯• (`scripts/test_high_freq_features.py`)\n")
        report.append("3. ğŸ“Œ **åç»­**: ç‰¹å¾é™ç»´ï¼Œç¦ç”¨ä¸å¯é ç‰¹å¾ï¼Œç”Ÿæˆæ ¸å¿ƒç‰¹å¾é›†\n")
        
        report.append("\n---\n\n")
        report.append("*æœ¬æŠ¥å‘Šç”± Qilin Stack æ•°æ®è´¨é‡å®¡è®¡ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\n")
        
        # å†™å…¥æ–‡ä»¶
        report_text = ''.join(report)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(f"\nâœ… å®¡è®¡æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return report_text
    
    def run_full_audit(self) -> Dict:
        """è¿è¡Œå®Œæ•´å®¡è®¡æµç¨‹"""
        print("\n" + "="*70)
        print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®è´¨é‡å®¡è®¡")
        print("="*70)
        
        # 1. æ•°æ®æºè¦†ç›–ç‡
        self.audit_data_sources_coverage()
        
        # 2. ç¼ºå¤±å€¼
        self.audit_missing_values()
        
        # 3. å¼‚å¸¸å€¼
        self.audit_outliers()
        
        # 4. é«˜é¢‘ç‰¹å¾
        self.audit_high_freq_features()
        
        # 5. æ•°æ®ä¸€è‡´æ€§
        self.audit_data_consistency()
        
        # 6. ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        print("\n" + "="*70)
        print("âœ… æ•°æ®è´¨é‡å®¡è®¡å®Œæˆï¼")
        print("="*70)
        
        return self.audit_results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®è´¨é‡å®¡è®¡å·¥å…·')
    parser.add_argument('--start-date', type=str, default='2023-01-01',
                      help='å®¡è®¡å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str, default=None,
                      help='å®¡è®¡ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©')
    parser.add_argument('--output', type=str, default=None,
                      help='å®¡è®¡æŠ¥å‘Šè¾“å‡ºè·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®¡è®¡å™¨
    auditor = DataQualityAuditor(
        start_date=args.start_date,
        end_date=args.end_date
    )
    
    # è¿è¡Œå®Œæ•´å®¡è®¡
    results = auditor.run_full_audit()
    
    # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œç”ŸæˆæŠ¥å‘Š
    if args.output:
        auditor.generate_report(output_path=args.output)
    
    return results


if __name__ == '__main__':
    main()
