"""
é¢˜ææ‰©æ•£ä¸é¾™å¤´å› å­ç³»ç»Ÿ

æ ¹æ® docs/IMPROVEMENT_ROADMAP.md é˜¶æ®µä¸€ä»»åŠ¡1.8
ç›®æ ‡ï¼šæ•æ‰çƒ­ç‚¹é¢˜æå’Œé¾™å¤´æˆ˜æ³•ï¼Œè¯„ä¼°é¢˜ææ‰©æ•£åº¦å’Œé¾™å¤´å¼ºåº¦

æ ¸å¿ƒç»´åº¦ï¼š
1. é¢˜æè¯†åˆ«ï¼šçƒ­é—¨é¢˜æã€é¢˜ææ¶¨åœæ•°ã€é¢˜æå¸‚å€¼
2. é¢˜ææ‰©æ•£ï¼šé¢˜æé›†ä¸­åº¦ã€è½®åŠ¨é€Ÿåº¦ã€æ‰©æ•£å¹¿åº¦
3. é¾™å¤´è¯†åˆ«ï¼šé¾™å¤´è‚¡ã€é¾™å¤´æº¢ä»·ã€é¾™å¤´ç¨³å®šæ€§
4. é¢˜æç”Ÿå‘½å‘¨æœŸï¼šæ–°é¢˜æã€æˆç†Ÿé¢˜æã€è¡°é€€é¢˜æ
5. æ¿å—è”åŠ¨ï¼šè¡Œä¸šè”åŠ¨åº¦ã€æ¿å—å…±æŒ¯
6. é¢˜æè”åŠ¨æ€§ï¼šé¢˜æé—´ç›¸å…³æ€§ã€å…±æŒ¯å¼ºåº¦
7. è·¨æ¿å—æ‰©æ•£ï¼šæ‰©æ•£è·¯å¾„ã€å½±å“èŒƒå›´ã€æ‰©æ•£é€Ÿåº¦
8. é¾™å¤´æ¥åŠ›ï¼šé¾™å¤´åˆ‡æ¢ã€æ¥åŠ›è¿ç»­æ€§ã€æ¥åŠ›å¼ºåº¦

ä½œè€…ï¼šQilin Quant Team
åˆ›å»ºï¼š2025-10-30
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Set
from datetime import datetime, timedelta
from pathlib import Path
from collections import Counter, defaultdict
import sys
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class ThemeDiffusionFactors:
    """é¢˜ææ‰©æ•£ä¸é¾™å¤´å› å­è®¡ç®—å™¨"""
    
    # é¢„å®šä¹‰å¸¸è§é¢˜æå…³é”®è¯
    THEME_KEYWORDS = {
        'AIäººå·¥æ™ºèƒ½': ['äººå·¥æ™ºèƒ½', 'AI', 'chatgpt', 'å¤§æ¨¡å‹', 'ç®—åŠ›', 'GPU'],
        'æ–°èƒ½æº': ['æ–°èƒ½æº', 'é”‚ç”µ', 'å…‰ä¼', 'é£ç”µ', 'å‚¨èƒ½', 'æ°¢èƒ½'],
        'åŠå¯¼ä½“': ['åŠå¯¼ä½“', 'èŠ¯ç‰‡', 'é›†æˆç”µè·¯', 'æ™¶åœ†', 'å°æµ‹'],
        'å†›å·¥': ['å†›å·¥', 'èˆªå¤©', 'èˆªç©º', 'èˆ¹èˆ¶', 'å…µå™¨'],
        'åŒ»è¯': ['åŒ»è¯', 'ç”Ÿç‰©', 'ç–«è‹—', 'åˆ›æ–°è¯', 'CXO'],
        'æ¶ˆè´¹': ['æ¶ˆè´¹', 'ç™½é…’', 'é£Ÿå“', 'é›¶å”®', 'é¤é¥®'],
        'é‡‘è': ['é“¶è¡Œ', 'ä¿é™©', 'åˆ¸å•†', 'ä¿¡æ‰˜'],
        'åœ°äº§': ['æˆ¿åœ°äº§', 'å»ºç­‘', 'è£…ä¿®', 'å®¶å±…'],
        '5Gé€šä¿¡': ['5G', 'é€šä¿¡', 'ç‰©è”ç½‘', 'åŸºç«™'],
        'å…ƒå®‡å®™': ['å…ƒå®‡å®™', 'VR', 'AR', 'è™šæ‹Ÿç°å®'],
        'æ•°å­—ç»æµ': ['æ•°å­—ç»æµ', 'å¤§æ•°æ®', 'äº‘è®¡ç®—', 'åŒºå—é“¾'],
        'ç¢³ä¸­å’Œ': ['ç¢³ä¸­å’Œ', 'ç¯ä¿', 'èŠ‚èƒ½', 'æ¸…æ´èƒ½æº'],
        'å›½ä¼æ”¹é©': ['å›½ä¼æ”¹é©', 'å¤®ä¼', 'æ··æ”¹'],
        'ä¸€å¸¦ä¸€è·¯': ['ä¸€å¸¦ä¸€è·¯', 'åŸºå»º', 'å‡ºå£'],
        'ä¹¡æ‘æŒ¯å…´': ['ä¹¡æ‘æŒ¯å…´', 'å†œä¸š', 'ç§ä¸š']
    }
    
    def __init__(self):
        """åˆå§‹åŒ–é¢˜ææ‰©æ•£å› å­è®¡ç®—å™¨"""
        self.theme_cache = {}
        self.leader_cache = {}
        self.theme_history = {}  # å†å²é¢˜ææ•°æ®
        self.leader_history = {}  # å†å²é¾™å¤´æ•°æ®
        print("ğŸ¯ é¢˜ææ‰©æ•£ä¸é¾™å¤´å› å­è®¡ç®—å™¨åˆå§‹åŒ–")
    
    def calculate_all_factors(self, date: str, market_data: pd.DataFrame = None) -> Dict:
        """
        è®¡ç®—æ‰€æœ‰é¢˜ææ‰©æ•£å’Œé¾™å¤´å› å­
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            market_data: å¸‚åœºæ•°æ®ï¼ˆå¿…é¡»åŒ…å«stock_name, conceptç­‰å­—æ®µï¼‰
        
        Returns:
            Dict: åŒ…å«æ‰€æœ‰é¢˜æå’Œé¾™å¤´å› å­çš„å­—å…¸
        """
        print(f"\nè®¡ç®— {date} é¢˜ææ‰©æ•£ä¸é¾™å¤´å› å­...")
        
        factors = {}
        
        # 1. é¢˜æè¯†åˆ«ä¸åˆ†ç±»
        theme_analysis = self.analyze_themes(date, market_data)
        factors.update(theme_analysis)
        
        # 2. é¢˜ææ‰©æ•£åº¦åˆ†æ
        diffusion_analysis = self.calculate_theme_diffusion(date, theme_analysis)
        factors.update(diffusion_analysis)
        
        # 3. é¾™å¤´è¯†åˆ«ä¸åˆ†æ
        leader_analysis = self.identify_and_analyze_leaders(date, market_data, theme_analysis)
        factors.update(leader_analysis)
        
        # 4. é¢˜æç”Ÿå‘½å‘¨æœŸ
        lifecycle_analysis = self.analyze_theme_lifecycle(date, theme_analysis)
        factors.update(lifecycle_analysis)
        
        # 5. æ¿å—è”åŠ¨åˆ†æ
        sector_analysis = self.analyze_sector_linkage(date, market_data)
        factors.update(sector_analysis)
        
        # 6. é¢˜æè”åŠ¨æ€§åˆ†æ
        theme_linkage = self.analyze_theme_linkage(date, theme_analysis)
        factors.update(theme_linkage)
        
        # 7. è·¨æ¿å—æ‰©æ•£åˆ†æ
        cross_sector_diffusion = self.analyze_cross_sector_diffusion(date, market_data, theme_analysis)
        factors.update(cross_sector_diffusion)
        
        # 8. é¾™å¤´æ¥åŠ›å…³ç³»åˆ†æ
        leader_relay = self.analyze_leader_relay(date, leader_analysis)
        factors.update(leader_relay)
        
        # ç¼“å­˜å†å²æ•°æ®
        self.theme_history[date] = theme_analysis
        self.leader_history[date] = leader_analysis
        
        print(f"âœ… å…±è®¡ç®— {len(factors)} ä¸ªé¢˜æä¸é¾™å¤´å› å­")
        
        return factors
    
    def analyze_themes(self, date: str, market_data: pd.DataFrame = None) -> Dict:
        """
        é¢˜æè¯†åˆ«ä¸åˆ†ç±»
        
        è¯†åˆ«å½“æ—¥çƒ­é—¨é¢˜æï¼Œç»Ÿè®¡æ¯ä¸ªé¢˜æçš„æ¶¨åœæ•°ã€å¸‚å€¼ç­‰
        """
        print("  åˆ†æçƒ­é—¨é¢˜æ...")
        
        factors = {}
        
        try:
            # è·å–æ¶¨åœè‚¡ç¥¨æ•°æ®
            limitup_stocks = self._get_limitup_stocks(date, market_data)
            
            if limitup_stocks is not None and not limitup_stocks.empty:
                # æå–é¢˜æä¿¡æ¯
                theme_stats = self._extract_theme_statistics(limitup_stocks)
                
                # 1. çƒ­é—¨é¢˜æTop 5
                top_themes = sorted(theme_stats.items(), key=lambda x: x[1]['limitup_count'], reverse=True)[:5]
                
                for i, (theme_name, stats) in enumerate(top_themes, 1):
                    factors[f'top_{i}_theme_name'] = theme_name
                    factors[f'top_{i}_theme_limitup_count'] = stats['limitup_count']
                    factors[f'top_{i}_theme_avg_seal_strength'] = stats['avg_seal_strength']
                    factors[f'top_{i}_theme_total_market_cap'] = stats['total_market_cap']
                
                # å¡«å……å‰©ä½™ä½ç½®
                for i in range(len(top_themes) + 1, 6):
                    factors[f'top_{i}_theme_name'] = 'æ— '
                    factors[f'top_{i}_theme_limitup_count'] = 0
                    factors[f'top_{i}_theme_avg_seal_strength'] = 0
                    factors[f'top_{i}_theme_total_market_cap'] = 0
                
                # 2. é¢˜ææ€»æ•°
                factors['total_active_themes'] = len(theme_stats)
                
                # 3. æœ€å¼ºé¢˜æï¼ˆæ¶¨åœæ•°æœ€å¤šï¼‰
                if top_themes:
                    strongest_theme = top_themes[0]
                    factors['strongest_theme_name'] = strongest_theme[0]
                    factors['strongest_theme_dominance'] = strongest_theme[1]['limitup_count'] / len(limitup_stocks)
                else:
                    factors['strongest_theme_name'] = 'æ— '
                    factors['strongest_theme_dominance'] = 0
                
                # 4. é¢˜ææ¶¨åœè‚¡å æ¯”
                total_limitup = len(limitup_stocks)
                themed_limitup = sum(stats['limitup_count'] for stats in theme_stats.values())
                factors['themed_limitup_ratio'] = themed_limitup / total_limitup if total_limitup > 0 else 0
                
                # ç¼“å­˜é¢˜ææ•°æ®ä¾›åç»­ä½¿ç”¨
                self.theme_cache[date] = theme_stats
                
            else:
                # æ— æ•°æ®æ—¶å¡«å……é»˜è®¤å€¼
                for i in range(1, 6):
                    factors[f'top_{i}_theme_name'] = 'æ— '
                    factors[f'top_{i}_theme_limitup_count'] = 0
                    factors[f'top_{i}_theme_avg_seal_strength'] = 0
                    factors[f'top_{i}_theme_total_market_cap'] = 0
                
                factors.update({
                    'total_active_themes': 0,
                    'strongest_theme_name': 'æ— ',
                    'strongest_theme_dominance': 0,
                    'themed_limitup_ratio': 0
                })
        
        except Exception as e:
            print(f"    âš ï¸ é¢˜æåˆ†æå¤±è´¥: {e}")
            for i in range(1, 6):
                factors[f'top_{i}_theme_name'] = 'æ— '
                factors[f'top_{i}_theme_limitup_count'] = 0
                factors[f'top_{i}_theme_avg_seal_strength'] = 0
                factors[f'top_{i}_theme_total_market_cap'] = 0
            
            factors.update({
                'total_active_themes': 0,
                'strongest_theme_name': 'æ— ',
                'strongest_theme_dominance': 0,
                'themed_limitup_ratio': 0
            })
        
        return factors
    
    def calculate_theme_diffusion(self, date: str, theme_analysis: Dict) -> Dict:
        """
        è®¡ç®—é¢˜ææ‰©æ•£åº¦
        
        è¯„ä¼°é¢˜æçš„é›†ä¸­åº¦ã€æ‰©æ•£å¹¿åº¦ã€è½®åŠ¨é€Ÿåº¦
        """
        print("  è®¡ç®—é¢˜ææ‰©æ•£åº¦...")
        
        factors = {}
        
        try:
            theme_stats = self.theme_cache.get(date, {})
            
            if theme_stats:
                # 1. é¢˜æé›†ä¸­åº¦ï¼ˆHHIæŒ‡æ•°ï¼‰
                # HHI = Î£(å¸‚åœºä»½é¢^2)ï¼Œè¶Šé«˜è¶Šé›†ä¸­
                total_limitup = sum(stats['limitup_count'] for stats in theme_stats.values())
                
                if total_limitup > 0:
                    hhi = sum((stats['limitup_count'] / total_limitup) ** 2 for stats in theme_stats.values())
                    factors['theme_concentration_hhi'] = hhi
                    
                    # HHIè§£é‡Šï¼š
                    # >0.25: é«˜åº¦é›†ä¸­ï¼ˆä¸€ä¸ªé¢˜æç‹¬å¤§ï¼‰
                    # 0.15-0.25: ä¸­åº¦é›†ä¸­
                    # <0.15: åˆ†æ•£ï¼ˆå¤šé¢˜æå…±å­˜ï¼‰
                    if hhi > 0.25:
                        factors['theme_concentration_level'] = 'é«˜åº¦é›†ä¸­'
                    elif hhi > 0.15:
                        factors['theme_concentration_level'] = 'ä¸­åº¦é›†ä¸­'
                    else:
                        factors['theme_concentration_level'] = 'åˆ†æ•£'
                else:
                    factors['theme_concentration_hhi'] = 0
                    factors['theme_concentration_level'] = 'æ— '
                
                # 2. é¢˜ææ‰©æ•£å¹¿åº¦ï¼ˆæœ‰æ¶¨åœè‚¡çš„é¢˜ææ•°/æ€»é¢˜ææ•°ï¼‰
                factors['theme_diffusion_breadth'] = len(theme_stats)
                
                # 3. é¢˜æå¹³å‡æ¶¨åœæ•°
                if theme_stats:
                    factors['avg_limitup_per_theme'] = total_limitup / len(theme_stats)
                else:
                    factors['avg_limitup_per_theme'] = 0
                
                # 4. é¾™å¤´é¢˜æé›†ä¸­åº¦ï¼ˆTop3é¢˜æå æ¯”ï¼‰
                sorted_themes = sorted(theme_stats.items(), key=lambda x: x[1]['limitup_count'], reverse=True)
                top3_limitup = sum(stats['limitup_count'] for _, stats in sorted_themes[:3])
                factors['top3_theme_concentration'] = top3_limitup / total_limitup if total_limitup > 0 else 0
                
                # 5. é¢˜æè½®åŠ¨é€Ÿåº¦ï¼ˆä¸å‰ä¸€å¤©å¯¹æ¯”ï¼‰
                rotation_speed = self._calculate_theme_rotation_speed(date, theme_stats)
                factors['theme_rotation_speed'] = rotation_speed
                
            else:
                factors.update({
                    'theme_concentration_hhi': 0,
                    'theme_concentration_level': 'æ— ',
                    'theme_diffusion_breadth': 0,
                    'avg_limitup_per_theme': 0,
                    'top3_theme_concentration': 0,
                    'theme_rotation_speed': 0
                })
        
        except Exception as e:
            print(f"    âš ï¸ é¢˜ææ‰©æ•£åº¦è®¡ç®—å¤±è´¥: {e}")
            factors.update({
                'theme_concentration_hhi': 0,
                'theme_concentration_level': 'æ— ',
                'theme_diffusion_breadth': 0,
                'avg_limitup_per_theme': 0,
                'top3_theme_concentration': 0,
                'theme_rotation_speed': 0
            })
        
        return factors
    
    def identify_and_analyze_leaders(self, date: str, market_data: pd.DataFrame = None, 
                                    theme_analysis: Dict = None) -> Dict:
        """
        è¯†åˆ«å¹¶åˆ†æé¾™å¤´è‚¡
        
        é¾™å¤´è¯†åˆ«æ ‡å‡†ï¼š
        1. è¿æ¿é«˜åº¦é«˜
        2. å°å•å¼ºåº¦å¤§
        3. å¸‚å€¼é€‚ä¸­ï¼ˆ100-500äº¿ï¼‰
        4. æˆäº¤æ´»è·ƒ
        5. é¢˜æçº¯æ­£
        """
        print("  è¯†åˆ«å’Œåˆ†æé¾™å¤´è‚¡...")
        
        factors = {}
        
        try:
            limitup_stocks = self._get_limitup_stocks(date, market_data)
            
            if limitup_stocks is not None and not limitup_stocks.empty:
                # é¾™å¤´å€™é€‰ï¼šè¿æ¿æ•°>=2çš„è‚¡ç¥¨
                if 'consecutive_days' in limitup_stocks.columns:
                    leader_candidates = limitup_stocks[limitup_stocks['consecutive_days'] >= 2].copy()
                else:
                    leader_candidates = limitup_stocks.copy()
                
                if not leader_candidates.empty:
                    # è®¡ç®—é¾™å¤´è¯„åˆ†
                    leader_scores = self._calculate_leader_scores(leader_candidates)
                    leader_candidates['leader_score'] = leader_scores
                    
                    # æŒ‰è¯„åˆ†æ’åºï¼Œå–Top 5
                    top_leaders = leader_candidates.nlargest(5, 'leader_score')
                    
                    # 1. Top 5é¾™å¤´ä¿¡æ¯
                    for i, (idx, row) in enumerate(top_leaders.iterrows(), 1):
                        factors[f'leader_{i}_name'] = row.get('name', f'è‚¡ç¥¨{i}')
                        factors[f'leader_{i}_consecutive_days'] = int(row.get('consecutive_days', 1))
                        factors[f'leader_{i}_seal_strength'] = float(row.get('seal_strength', 0))
                        factors[f'leader_{i}_score'] = float(row.get('leader_score', 0))
                    
                    # å¡«å……å‰©ä½™ä½ç½®
                    for i in range(len(top_leaders) + 1, 6):
                        factors[f'leader_{i}_name'] = 'æ— '
                        factors[f'leader_{i}_consecutive_days'] = 0
                        factors[f'leader_{i}_seal_strength'] = 0
                        factors[f'leader_{i}_score'] = 0
                    
                    # 2. é¾™å¤´æ•°é‡
                    factors['total_leader_count'] = len(leader_candidates)
                    
                    # 3. æœ€å¼ºé¾™å¤´é«˜åº¦
                    max_consecutive = leader_candidates['consecutive_days'].max() if 'consecutive_days' in leader_candidates.columns else 1
                    factors['max_leader_height'] = int(max_consecutive)
                    
                    # 4. é¾™å¤´å¹³å‡å°å•å¼ºåº¦
                    if 'seal_strength' in leader_candidates.columns:
                        factors['leader_avg_seal_strength'] = float(leader_candidates['seal_strength'].mean())
                    else:
                        factors['leader_avg_seal_strength'] = 0
                    
                    # 5. é¾™å¤´æº¢ä»·ï¼ˆé¾™å¤´å°å•å¼ºåº¦ / å¸‚åœºå¹³å‡å°å•å¼ºåº¦ï¼‰
                    if 'seal_strength' in limitup_stocks.columns:
                        market_avg_seal = limitup_stocks['seal_strength'].mean()
                        leader_avg_seal = leader_candidates['seal_strength'].mean()
                        factors['leader_premium'] = leader_avg_seal / market_avg_seal if market_avg_seal > 0 else 1.0
                    else:
                        factors['leader_premium'] = 1.0
                    
                    # 6. é¾™å¤´ç¨³å®šæ€§ï¼ˆè¿æ¿>=3çš„é¾™å¤´æ•°é‡ï¼‰
                    if 'consecutive_days' in leader_candidates.columns:
                        stable_leader_count = (leader_candidates['consecutive_days'] >= 3).sum()
                        factors['stable_leader_count'] = int(stable_leader_count)
                        factors['stable_leader_ratio'] = stable_leader_count / len(leader_candidates)
                    else:
                        factors['stable_leader_count'] = 0
                        factors['stable_leader_ratio'] = 0
                    
                    # ç¼“å­˜é¾™å¤´æ•°æ®
                    self.leader_cache[date] = top_leaders
                    
                else:
                    # æ— é¾™å¤´å€™é€‰
                    self._fill_no_leader_factors(factors)
            else:
                self._fill_no_leader_factors(factors)
        
        except Exception as e:
            print(f"    âš ï¸ é¾™å¤´åˆ†æå¤±è´¥: {e}")
            self._fill_no_leader_factors(factors)
        
        return factors
    
    def analyze_theme_lifecycle(self, date: str, theme_analysis: Dict) -> Dict:
        """
        åˆ†æé¢˜æç”Ÿå‘½å‘¨æœŸ
        
        åˆ¤æ–­é¢˜æå¤„äºï¼šæ–°ç”ŸæœŸã€æˆé•¿æœŸã€æˆç†ŸæœŸã€è¡°é€€æœŸ
        """
        print("  åˆ†æé¢˜æç”Ÿå‘½å‘¨æœŸ...")
        
        factors = {}
        
        try:
            theme_stats = self.theme_cache.get(date, {})
            
            if theme_stats:
                # ä¸å†å²å¯¹æ¯”ï¼Œåˆ¤æ–­é¢˜æç”Ÿå‘½å‘¨æœŸ
                lifecycle_analysis = {}
                
                for theme_name, stats in theme_stats.items():
                    # ç®€åŒ–å®ç°ï¼šæ ¹æ®æ¶¨åœæ•°å’Œå°å•å¼ºåº¦åˆ¤æ–­
                    limitup_count = stats['limitup_count']
                    avg_seal = stats['avg_seal_strength']
                    
                    if limitup_count >= 10 and avg_seal > 5:
                        lifecycle = 'æˆç†ŸæœŸ'  # é«˜æ¶¨åœæ•°+é«˜å°å•å¼ºåº¦
                    elif limitup_count >= 5 and avg_seal > 3:
                        lifecycle = 'æˆé•¿æœŸ'  # ä¸­ç­‰æ¶¨åœæ•°+ä¸­ç­‰å°å•å¼ºåº¦
                    elif limitup_count >= 3:
                        lifecycle = 'æ–°ç”ŸæœŸ'  # åˆšèµ·æ­¥
                    else:
                        lifecycle = 'è¡°é€€æœŸ'  # ä½æ¶¨åœæ•°
                    
                    lifecycle_analysis[theme_name] = lifecycle
                
                # ç»Ÿè®¡å„é˜¶æ®µé¢˜ææ•°
                lifecycle_counter = Counter(lifecycle_analysis.values())
                factors['emerging_theme_count'] = lifecycle_counter.get('æ–°ç”ŸæœŸ', 0)
                factors['growing_theme_count'] = lifecycle_counter.get('æˆé•¿æœŸ', 0)
                factors['mature_theme_count'] = lifecycle_counter.get('æˆç†ŸæœŸ', 0)
                factors['declining_theme_count'] = lifecycle_counter.get('è¡°é€€æœŸ', 0)
                
                # ä¸»æµé¢˜æç”Ÿå‘½å‘¨æœŸ
                top_theme_name = theme_analysis.get('strongest_theme_name', 'æ— ')
                factors['main_theme_lifecycle'] = lifecycle_analysis.get(top_theme_name, 'æ— ')
                
            else:
                factors.update({
                    'emerging_theme_count': 0,
                    'growing_theme_count': 0,
                    'mature_theme_count': 0,
                    'declining_theme_count': 0,
                    'main_theme_lifecycle': 'æ— '
                })
        
        except Exception as e:
            print(f"    âš ï¸ ç”Ÿå‘½å‘¨æœŸåˆ†æå¤±è´¥: {e}")
            factors.update({
                'emerging_theme_count': 0,
                'growing_theme_count': 0,
                'mature_theme_count': 0,
                'declining_theme_count': 0,
                'main_theme_lifecycle': 'æ— '
            })
        
        return factors
    
    def analyze_sector_linkage(self, date: str, market_data: pd.DataFrame = None) -> Dict:
        """
        åˆ†ææ¿å—è”åŠ¨
        
        è¯„ä¼°ä¸åŒæ¿å—/è¡Œä¸šä¹‹é—´çš„è”åŠ¨æ•ˆåº”
        """
        print("  åˆ†ææ¿å—è”åŠ¨...")
        
        factors = {}
        
        try:
            if market_data is not None and 'sector' in market_data.columns:
                # ç»Ÿè®¡å„æ¿å—æ¶¨åœæ•°
                limitup_by_sector = market_data[market_data.get('is_limit_up', 0) == 1].groupby('sector').size()
                
                if not limitup_by_sector.empty:
                    # 1. æ¶¨åœæ¿å—æ•°
                    factors['limitup_sector_count'] = len(limitup_by_sector)
                    
                    # 2. æœ€å¼ºæ¿å—
                    top_sector = limitup_by_sector.idxmax()
                    factors['strongest_sector'] = top_sector
                    factors['strongest_sector_limitup_count'] = int(limitup_by_sector.max())
                    
                    # 3. æ¿å—é›†ä¸­åº¦
                    total_sector_limitup = limitup_by_sector.sum()
                    sector_hhi = sum((count / total_sector_limitup) ** 2 for count in limitup_by_sector.values)
                    factors['sector_concentration_hhi'] = sector_hhi
                    
                    # 4. æ¿å—è½®åŠ¨ï¼ˆTop3æ¿å—å æ¯”ï¼‰
                    top3_sector_limitup = limitup_by_sector.nlargest(3).sum()
                    factors['top3_sector_ratio'] = top3_sector_limitup / total_sector_limitup if total_sector_limitup > 0 else 0
                    
                    # 5. æ¿å—å¹³å‡æ¶¨åœæ•°
                    factors['avg_limitup_per_sector'] = float(limitup_by_sector.mean())
                    
                else:
                    self._fill_no_sector_factors(factors)
            else:
                self._fill_no_sector_factors(factors)
        
        except Exception as e:
            print(f"    âš ï¸ æ¿å—è”åŠ¨åˆ†æå¤±è´¥: {e}")
            self._fill_no_sector_factors(factors)
        
        return factors
    
    def analyze_theme_linkage(self, date: str, theme_analysis: Dict) -> Dict:
        """
        åˆ†æé¢˜æé—´çš„è”åŠ¨æ€§
        
        è¯„ä¼°ä¸åŒé¢˜æä¹‹é—´çš„ç›¸å…³æ€§å’Œå…±æŒ¯æ•ˆåº”
        """
        print("  åˆ†æé¢˜æè”åŠ¨æ€§...")
        
        factors = {}
        
        try:
            theme_stats = self.theme_cache.get(date, {})
            
            if len(theme_stats) >= 2:
                # 1. è®¡ç®—é¢˜æè‚¡ç¥¨é‡å åº¦
                # æ£€æŸ¥ä¸åŒé¢˜æä¹‹é—´æœ‰å¤šå°‘è‚¡ç¥¨æ˜¯å…±åŒçš„ï¼ˆä¸€è‚¡å¤šé¢˜æï¼‰
                theme_stocks = {theme: set(stats['stocks']) for theme, stats in theme_stats.items()}
                
                # Top 5 é¢˜æé—´çš„é‡å åº¦çŸ©é˜µ
                top_themes = sorted(theme_stats.items(), key=lambda x: x[1]['limitup_count'], reverse=True)[:5]
                overlap_scores = []
                
                for i in range(len(top_themes)):
                    for j in range(i + 1, len(top_themes)):
                        theme1, theme2 = top_themes[i][0], top_themes[j][0]
                        stocks1 = theme_stocks.get(theme1, set())
                        stocks2 = theme_stocks.get(theme2, set())
                        
                        if stocks1 and stocks2:
                            # Jaccardç›¸ä¼¼åº¦
                            intersection = len(stocks1 & stocks2)
                            union = len(stocks1 | stocks2)
                            overlap = intersection / union if union > 0 else 0
                            overlap_scores.append(overlap)
                
                # 2. å¹³å‡é¢˜æè”åŠ¨å¼ºåº¦
                if overlap_scores:
                    factors['theme_linkage_strength'] = np.mean(overlap_scores)
                    factors['theme_max_linkage'] = np.max(overlap_scores)
                    
                    # è”åŠ¨çº§åˆ«åˆ†ç±»
                    avg_linkage = factors['theme_linkage_strength']
                    if avg_linkage > 0.4:
                        factors['theme_linkage_level'] = 'å¼ºè”åŠ¨'
                    elif avg_linkage > 0.2:
                        factors['theme_linkage_level'] = 'ä¸­ç­‰è”åŠ¨'
                    else:
                        factors['theme_linkage_level'] = 'å¼±è”åŠ¨'
                else:
                    factors['theme_linkage_strength'] = 0
                    factors['theme_max_linkage'] = 0
                    factors['theme_linkage_level'] = 'æ— è”åŠ¨'
                
                # 3. å…±æŒ¯é¢˜æå¯¹æ•°é‡ï¼ˆé‡å åº¦>0.3çš„é¢˜æå¯¹ï¼‰
                resonance_pairs = sum(1 for score in overlap_scores if score > 0.3)
                factors['theme_resonance_pairs'] = resonance_pairs
                
                # 4. é¢˜æå…±æŒ¯å¼ºåº¦ï¼ˆæœ‰å¤šå°‘é¢˜æåœ¨å…±åŒå‘åŠ›ï¼‰
                # å¦‚æœå¤šä¸ªé¢˜ææ¶¨åœæ•°éƒ½å¾ˆé«˜ï¼Œè¯´æ˜å…±æŒ¯å¼º
                strong_themes = [t for t, s in theme_stats.items() if s['limitup_count'] >= 5]
                factors['strong_theme_count'] = len(strong_themes)
                
                # 5. é¢˜æå…±æŒ¯æ¯”ä¾‹
                factors['theme_resonance_ratio'] = len(strong_themes) / len(theme_stats) if theme_stats else 0
                
            else:
                # é¢˜ææ•°é‡ä¸è¶³ï¼Œæ— æ³•è®¡ç®—è”åŠ¨
                factors.update({
                    'theme_linkage_strength': 0,
                    'theme_max_linkage': 0,
                    'theme_linkage_level': 'æ— è”åŠ¨',
                    'theme_resonance_pairs': 0,
                    'strong_theme_count': 0,
                    'theme_resonance_ratio': 0
                })
        
        except Exception as e:
            print(f"    âš ï¸ é¢˜æè”åŠ¨æ€§åˆ†æå¤±è´¥: {e}")
            factors.update({
                'theme_linkage_strength': 0,
                'theme_max_linkage': 0,
                'theme_linkage_level': 'æ— è”åŠ¨',
                'theme_resonance_pairs': 0,
                'strong_theme_count': 0,
                'theme_resonance_ratio': 0
            })
        
        return factors
    
    def analyze_cross_sector_diffusion(self, date: str, market_data: pd.DataFrame = None,
                                       theme_analysis: Dict = None) -> Dict:
        """
        åˆ†æè·¨æ¿å—æ‰©æ•£è·¯å¾„
        
        è¯„ä¼°é¢˜æä»æŸä¸ªæ¿å—å‘å…¶ä»–æ¿å—æ‰©æ•£çš„æƒ…å†µ
        """
        print("  åˆ†æè·¨æ¿å—æ‰©æ•£...")
        
        factors = {}
        
        try:
            limitup_stocks = self._get_limitup_stocks(date, market_data)
            theme_stats = self.theme_cache.get(date, {})
            
            if limitup_stocks is not None and not limitup_stocks.empty and 'sector' in limitup_stocks.columns:
                # 1. ç»Ÿè®¡æ¯ä¸ªé¢˜ææ¶‰åŠçš„æ¿å—æ•°
                theme_sector_spread = {}
                
                for theme, stats in theme_stats.items():
                    theme_stock_names = set(stats['stocks'])
                    # æ‰¾åˆ°è¿™äº›è‚¡ç¥¨æ‰€å±çš„æ¿å—
                    theme_limitup = limitup_stocks[limitup_stocks.get('name', limitup_stocks.index).isin(theme_stock_names)]
                    
                    if not theme_limitup.empty and 'sector' in theme_limitup.columns:
                        sectors = theme_limitup['sector'].nunique()
                        theme_sector_spread[theme] = sectors
                
                # 2. æœ€å¹¿æ‰©æ•£é¢˜æï¼ˆæ¶‰åŠæ¿å—æœ€å¤šï¼‰
                if theme_sector_spread:
                    most_spread_theme = max(theme_sector_spread, key=theme_sector_spread.get)
                    factors['most_spread_theme'] = most_spread_theme
                    factors['most_spread_sector_count'] = theme_sector_spread[most_spread_theme]
                else:
                    factors['most_spread_theme'] = 'æ— '
                    factors['most_spread_sector_count'] = 0
                
                # 3. å¹³å‡æ¿å—æ‰©æ•£åº¦
                if theme_sector_spread:
                    factors['avg_sector_spread'] = np.mean(list(theme_sector_spread.values()))
                else:
                    factors['avg_sector_spread'] = 0
                
                # 4. è·¨æ¿å—æ‰©æ•£å¼ºåº¦ï¼ˆæ¶‰åŠ3+æ¿å—çš„é¢˜æå æ¯”ï¼‰
                if theme_sector_spread:
                    cross_sector_themes = sum(1 for count in theme_sector_spread.values() if count >= 3)
                    factors['cross_sector_theme_count'] = cross_sector_themes
                    factors['cross_sector_theme_ratio'] = cross_sector_themes / len(theme_sector_spread)
                else:
                    factors['cross_sector_theme_count'] = 0
                    factors['cross_sector_theme_ratio'] = 0
                
                # 5. æ‰©æ•£è·¯å¾„åˆ†æï¼ˆä¸»å¯¼æ¿å— -> è·Ÿéšæ¿å—ï¼‰
                # æ‰¾åˆ°æ¶¨åœæ•°æœ€å¤šçš„æ¿å—ï¼Œåˆ¤æ–­å…¶ä»–æ¿å—æ˜¯å¦è·Ÿéš
                sector_limitup_count = limitup_stocks.groupby('sector').size()
                
                if not sector_limitup_count.empty:
                    dominant_sector = sector_limitup_count.idxmax()
                    factors['dominant_diffusion_sector'] = dominant_sector
                    
                    # è®¡ç®—è·Ÿéšæ¿å—æ•°ï¼ˆæ¶¨åœæ•°>=3çš„å…¶ä»–æ¿å—ï¼‰
                    following_sectors = (sector_limitup_count >= 3).sum() - 1  # å‡å»ä¸»å¯¼æ¿å—
                    factors['following_sector_count'] = max(0, following_sectors)
                    
                    # æ‰©æ•£æ•ˆç‡ï¼ˆè·Ÿéšæ¿å—å æ¯”ï¼‰
                    total_sectors = len(sector_limitup_count)
                    factors['diffusion_efficiency'] = following_sectors / (total_sectors - 1) if total_sectors > 1 else 0
                else:
                    factors['dominant_diffusion_sector'] = 'æ— '
                    factors['following_sector_count'] = 0
                    factors['diffusion_efficiency'] = 0
                
                # 6. æ‰©æ•£é€Ÿåº¦ï¼ˆæ–°å¢æ¿å—æ•° vs æ˜¨æ—¥ï¼‰
                # ç®€åŒ–å®ç°ï¼šè¿”å›å½“å‰æ¶‰åŠæ¿å—æ€»æ•°ä½œä¸ºä»£ç†æŒ‡æ ‡
                factors['current_diffusion_breadth'] = limitup_stocks['sector'].nunique() if 'sector' in limitup_stocks.columns else 0
                
            else:
                self._fill_no_diffusion_factors(factors)
        
        except Exception as e:
            print(f"    âš ï¸ è·¨æ¿å—æ‰©æ•£åˆ†æå¤±è´¥: {e}")
            self._fill_no_diffusion_factors(factors)
        
        return factors
    
    def analyze_leader_relay(self, date: str, leader_analysis: Dict) -> Dict:
        """
        åˆ†æé¾™å¤´æ¥åŠ›å…³ç³»
        
        è¯„ä¼°é¾™å¤´è‚¡çš„åˆ‡æ¢ã€æ¥åŠ›è¿ç»­æ€§å’Œå¼ºåº¦
        """
        print("  åˆ†æé¾™å¤´æ¥åŠ›å…³ç³»...")
        
        factors = {}
        
        try:
            current_leaders = self.leader_cache.get(date, pd.DataFrame())
            
            if not current_leaders.empty:
                # 1. é¾™å¤´æ¥åŠ›è¿ç»­æ€§
                # æ£€æŸ¥æ˜¯å¦æœ‰é¾™å¤´è¿ç»­å¤šæ—¥ä¿æŒé¾™å¤´åœ°ä½
                if 'consecutive_days' in current_leaders.columns:
                    max_consecutive = current_leaders['consecutive_days'].max()
                    
                    # è¶…é«˜è¿æ¿ï¼ˆ>=5ï¼‰
                    super_leader_count = (current_leaders['consecutive_days'] >= 5).sum()
                    factors['super_leader_count'] = int(super_leader_count)
                    
                    # é¾™å¤´æŒç»­æ€§æŒ‡æ ‡
                    factors['leader_continuity_score'] = float(current_leaders['consecutive_days'].mean())
                    
                    # è¿ç»­æ€§çº§åˆ«
                    if max_consecutive >= 7:
                        factors['leader_continuity_level'] = 'è¶…å¼ºæŒç»­'
                    elif max_consecutive >= 5:
                        factors['leader_continuity_level'] = 'å¼ºæŒç»­'
                    elif max_consecutive >= 3:
                        factors['leader_continuity_level'] = 'ä¸­ç­‰æŒç»­'
                    else:
                        factors['leader_continuity_level'] = 'å¼±æŒç»­'
                else:
                    factors['super_leader_count'] = 0
                    factors['leader_continuity_score'] = 1.0
                    factors['leader_continuity_level'] = 'æœªçŸ¥'
                
                # 2. é¾™å¤´æ¥åŠ›å¼ºåº¦
                # å¦‚æœæœ‰å¤šä¸ªé¾™å¤´åŒæ—¶åœ¨é«˜ä½ï¼ˆè¿æ¿>=3ï¼‰ï¼Œè¯´æ˜æ¥åŠ›å¼º
                if 'consecutive_days' in current_leaders.columns:
                    high_leaders = (current_leaders['consecutive_days'] >= 3).sum()
                    total_leaders = len(current_leaders)
                    
                    factors['high_level_leader_count'] = int(high_leaders)
                    factors['leader_relay_strength'] = high_leaders / total_leaders if total_leaders > 0 else 0
                    
                    # æ¥åŠ›å¼ºåº¦çº§åˆ«
                    relay_strength = factors['leader_relay_strength']
                    if relay_strength > 0.6:
                        factors['leader_relay_level'] = 'å¼ºæ¥åŠ›'
                    elif relay_strength > 0.3:
                        factors['leader_relay_level'] = 'ä¸­ç­‰æ¥åŠ›'
                    else:
                        factors['leader_relay_level'] = 'å¼±æ¥åŠ›'
                else:
                    factors['high_level_leader_count'] = 0
                    factors['leader_relay_strength'] = 0
                    factors['leader_relay_level'] = 'æ— æ¥åŠ›'
                
                # 3. é¾™å¤´æ¢¯é˜Ÿå®Œæ•´æ€§
                # ç†æƒ³æƒ…å†µï¼šæ—¢æœ‰é«˜ä½é¾™å¤´ï¼ˆ5+æ¿ï¼‰ï¼Œä¹Ÿæœ‰ä¸­ä½é¾™å¤´ï¼ˆ3-4æ¿ï¼‰ï¼Œè¿˜æœ‰ä½ä½é¾™å¤´ï¼ˆ2æ¿ï¼‰
                if 'consecutive_days' in current_leaders.columns:
                    high_tier = (current_leaders['consecutive_days'] >= 5).sum()
                    mid_tier = ((current_leaders['consecutive_days'] >= 3) & (current_leaders['consecutive_days'] < 5)).sum()
                    low_tier = (current_leaders['consecutive_days'] == 2).sum()
                    
                    factors['leader_high_tier_count'] = int(high_tier)
                    factors['leader_mid_tier_count'] = int(mid_tier)
                    factors['leader_low_tier_count'] = int(low_tier)
                    
                    # æ¢¯é˜Ÿå®Œæ•´æ€§ï¼šä¸‰ä¸ªæ¢¯é˜Ÿéƒ½æœ‰åˆ™å®Œæ•´
                    tier_completeness = (high_tier > 0) + (mid_tier > 0) + (low_tier > 0)
                    factors['leader_tier_completeness'] = tier_completeness / 3.0
                    
                    if tier_completeness == 3:
                        factors['leader_tier_structure'] = 'å®Œæ•´æ¢¯é˜Ÿ'
                    elif tier_completeness == 2:
                        factors['leader_tier_structure'] = 'éƒ¨åˆ†æ¢¯é˜Ÿ'
                    else:
                        factors['leader_tier_structure'] = 'å•ä¸€æ¢¯é˜Ÿ'
                else:
                    factors['leader_high_tier_count'] = 0
                    factors['leader_mid_tier_count'] = 0
                    factors['leader_low_tier_count'] = 0
                    factors['leader_tier_completeness'] = 0
                    factors['leader_tier_structure'] = 'æ— æ¢¯é˜Ÿ'
                
                # 4. é¾™å¤´åˆ‡æ¢åˆ†æ
                # å¯¹æ¯”å‰ä¸€æ—¥é¾™å¤´ï¼Œçœ‹æ˜¯å¦æœ‰æ–°é¾™å¤´å‡ºç°
                prev_date = self._get_previous_trade_date(date)
                prev_leaders = self.leader_cache.get(prev_date, pd.DataFrame())
                
                if not prev_leaders.empty and 'name' in current_leaders.columns and 'name' in prev_leaders.columns:
                    current_names = set(current_leaders['name'].values)
                    prev_names = set(prev_leaders['name'].values)
                    
                    # æ–°å¢é¾™å¤´
                    new_leaders = current_names - prev_names
                    factors['new_leader_count'] = len(new_leaders)
                    
                    # æŒç»­é¾™å¤´ï¼ˆä¸¤å¤©éƒ½åœ¨ï¼‰
                    continuing_leaders = current_names & prev_names
                    factors['continuing_leader_count'] = len(continuing_leaders)
                    
                    # é¾™å¤´ç¨³å®šæ€§ï¼ˆæŒç»­é¾™å¤´å æ¯”ï¼‰
                    factors['leader_stability'] = len(continuing_leaders) / len(current_names) if current_names else 0
                    
                    # é¾™å¤´åˆ‡æ¢ç‡
                    factors['leader_turnover_rate'] = len(new_leaders) / len(current_names) if current_names else 0
                    
                    # åˆ‡æ¢æ¨¡å¼
                    if factors['leader_turnover_rate'] > 0.7:
                        factors['leader_switch_mode'] = 'å¿«é€Ÿåˆ‡æ¢'
                    elif factors['leader_turnover_rate'] > 0.4:
                        factors['leader_switch_mode'] = 'æ­£å¸¸è½®åŠ¨'
                    else:
                        factors['leader_switch_mode'] = 'ç¨³å®šæŒç»­'
                else:
                    factors['new_leader_count'] = 0
                    factors['continuing_leader_count'] = 0
                    factors['leader_stability'] = 0
                    factors['leader_turnover_rate'] = 0
                    factors['leader_switch_mode'] = 'æœªçŸ¥'
                
            else:
                self._fill_no_relay_factors(factors)
        
        except Exception as e:
            print(f"    âš ï¸ é¾™å¤´æ¥åŠ›åˆ†æå¤±è´¥: {e}")
            self._fill_no_relay_factors(factors)
        
        return factors
    
    # ==================== è¾…åŠ©æ–¹æ³• ====================
    
    def _get_limitup_stocks(self, date: str, market_data: pd.DataFrame = None) -> Optional[pd.DataFrame]:
        """è·å–æ¶¨åœè‚¡ç¥¨æ•°æ®"""
        if market_data is not None:
            # ç­›é€‰æ¶¨åœè‚¡ç¥¨
            if 'is_limit_up' in market_data.columns:
                return market_data[market_data['is_limit_up'] == 1].copy()
            else:
                return market_data.copy()
        
        # å°è¯•ä»å¤–éƒ¨è·å–
        try:
            import akshare as ak
            date_str = date.replace('-', '')
            df = ak.stock_zt_pool_em(date=date_str)
            
            if not df.empty:
                df['is_limit_up'] = 1
                return df
        except:
            pass
        
        return None
    
    def _extract_theme_statistics(self, limitup_stocks: pd.DataFrame) -> Dict:
        """ä»æ¶¨åœè‚¡ç¥¨ä¸­æå–é¢˜æç»Ÿè®¡"""
        theme_stats = defaultdict(lambda: {
            'limitup_count': 0,
            'total_market_cap': 0,
            'seal_strengths': [],
            'stocks': []
        })
        
        for idx, row in limitup_stocks.iterrows():
            # å°è¯•ä»æ¦‚å¿µ/åç§°ä¸­è¯†åˆ«é¢˜æ
            themes = self._identify_themes_from_stock(row)
            
            for theme in themes:
                theme_stats[theme]['limitup_count'] += 1
                theme_stats[theme]['total_market_cap'] += row.get('market_cap', 0)
                theme_stats[theme]['seal_strengths'].append(row.get('seal_strength', 0))
                theme_stats[theme]['stocks'].append(row.get('name', ''))
        
        # è®¡ç®—å¹³å‡å°å•å¼ºåº¦
        for theme, stats in theme_stats.items():
            if stats['seal_strengths']:
                stats['avg_seal_strength'] = np.mean(stats['seal_strengths'])
            else:
                stats['avg_seal_strength'] = 0
            # æ¸…ç†ä¸´æ—¶æ•°æ®
            del stats['seal_strengths']
        
        return dict(theme_stats)
    
    def _identify_themes_from_stock(self, stock_row: pd.Series) -> List[str]:
        """ä»è‚¡ç¥¨ä¿¡æ¯ä¸­è¯†åˆ«é¢˜æ"""
        themes = []
        
        # ä»åç§°è¯†åˆ«
        stock_name = str(stock_row.get('name', '')).lower()
        
        # ä»æ¦‚å¿µè¯†åˆ«
        concept = str(stock_row.get('concept', '')).lower()
        
        # åˆå¹¶æ–‡æœ¬
        text = stock_name + ' ' + concept
        
        # åŒ¹é…é¢„å®šä¹‰é¢˜æ
        for theme_name, keywords in self.THEME_KEYWORDS.items():
            for keyword in keywords:
                if keyword.lower() in text:
                    themes.append(theme_name)
                    break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›"å…¶ä»–"
        if not themes:
            themes.append('å…¶ä»–')
        
        return themes
    
    def _calculate_theme_rotation_speed(self, date: str, current_theme_stats: Dict) -> float:
        """è®¡ç®—é¢˜æè½®åŠ¨é€Ÿåº¦"""
        # ç®€åŒ–å®ç°ï¼šè¿”å›é»˜è®¤å€¼
        # å®é™…åº”è¯¥å¯¹æ¯”å‰ä¸€å¤©çš„é¢˜ææ’åå˜åŒ–
        return 0.5  # 0-1ä¹‹é—´ï¼Œè¶Šé«˜è½®åŠ¨è¶Šå¿«
    
    def _calculate_leader_scores(self, candidates: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—é¾™å¤´è¯„åˆ†
        
        è¯„åˆ†ç»´åº¦ï¼š
        1. è¿æ¿é«˜åº¦ï¼ˆ40%ï¼‰
        2. å°å•å¼ºåº¦ï¼ˆ30%ï¼‰
        3. å¸‚å€¼é€‚ä¸­æ€§ï¼ˆ15%ï¼‰
        4. æ¢æ‰‹ç‡ï¼ˆ15%ï¼‰
        """
        scores = pd.Series(index=candidates.index, dtype=float)
        
        # 1. è¿æ¿é«˜åº¦å¾—åˆ†ï¼ˆå½’ä¸€åŒ–ï¼‰
        if 'consecutive_days' in candidates.columns:
            consecutive_norm = (candidates['consecutive_days'] - candidates['consecutive_days'].min()) / \
                              (candidates['consecutive_days'].max() - candidates['consecutive_days'].min() + 1e-6)
            score_consecutive = consecutive_norm * 40
        else:
            score_consecutive = 20  # é»˜è®¤ä¸­ç­‰åˆ†
        
        # 2. å°å•å¼ºåº¦å¾—åˆ†
        if 'seal_strength' in candidates.columns:
            seal_norm = candidates['seal_strength'] / (candidates['seal_strength'].max() + 1e-6)
            score_seal = seal_norm * 30
        else:
            score_seal = 15
        
        # 3. å¸‚å€¼é€‚ä¸­æ€§å¾—åˆ†ï¼ˆ100-500äº¿æœ€ä½³ï¼‰
        if 'market_cap' in candidates.columns:
            market_cap_billion = candidates['market_cap'] / 1e8
            # ä½¿ç”¨é«˜æ–¯å‡½æ•°ï¼Œå³°å€¼åœ¨300äº¿
            score_market_cap = 15 * np.exp(-((market_cap_billion - 300) / 200) ** 2)
        else:
            score_market_cap = 7.5
        
        # 4. æ¢æ‰‹ç‡å¾—åˆ†ï¼ˆ5-15%æœ€ä½³ï¼‰
        if 'turnover_rate' in candidates.columns:
            turnover_opt = 10  # æœ€ä½³æ¢æ‰‹ç‡
            score_turnover = 15 * np.exp(-((candidates['turnover_rate'] - turnover_opt) / 10) ** 2)
        else:
            score_turnover = 7.5
        
        scores = score_consecutive + score_seal + score_market_cap + score_turnover
        
        return scores
    
    def _fill_no_leader_factors(self, factors: Dict):
        """å¡«å……æ— é¾™å¤´æ—¶çš„é»˜è®¤å€¼"""
        for i in range(1, 6):
            factors[f'leader_{i}_name'] = 'æ— '
            factors[f'leader_{i}_consecutive_days'] = 0
            factors[f'leader_{i}_seal_strength'] = 0
            factors[f'leader_{i}_score'] = 0
        
        factors.update({
            'total_leader_count': 0,
            'max_leader_height': 0,
            'leader_avg_seal_strength': 0,
            'leader_premium': 1.0,
            'stable_leader_count': 0,
            'stable_leader_ratio': 0
        })
    
    def _fill_no_sector_factors(self, factors: Dict):
        """å¡«å……æ— æ¿å—æ•°æ®æ—¶çš„é»˜è®¤å€¼"""
        factors.update({
            'limitup_sector_count': 0,
            'strongest_sector': 'æ— ',
            'strongest_sector_limitup_count': 0,
            'sector_concentration_hhi': 0,
            'top3_sector_ratio': 0,
            'avg_limitup_per_sector': 0
        })
    
    def _fill_no_diffusion_factors(self, factors: Dict):
        """å¡«å……æ— æ‰©æ•£æ•°æ®æ—¶çš„é»˜è®¤å€¼"""
        factors.update({
            'most_spread_theme': 'æ— ',
            'most_spread_sector_count': 0,
            'avg_sector_spread': 0,
            'cross_sector_theme_count': 0,
            'cross_sector_theme_ratio': 0,
            'dominant_diffusion_sector': 'æ— ',
            'following_sector_count': 0,
            'diffusion_efficiency': 0,
            'current_diffusion_breadth': 0
        })
    
    def _fill_no_relay_factors(self, factors: Dict):
        """å¡«å……æ— æ¥åŠ›æ•°æ®æ—¶çš„é»˜è®¤å€¼"""
        factors.update({
            'super_leader_count': 0,
            'leader_continuity_score': 0,
            'leader_continuity_level': 'æ— ',
            'high_level_leader_count': 0,
            'leader_relay_strength': 0,
            'leader_relay_level': 'æ— æ¥åŠ›',
            'leader_high_tier_count': 0,
            'leader_mid_tier_count': 0,
            'leader_low_tier_count': 0,
            'leader_tier_completeness': 0,
            'leader_tier_structure': 'æ— æ¢¯é˜Ÿ',
            'new_leader_count': 0,
            'continuing_leader_count': 0,
            'leader_stability': 0,
            'leader_turnover_rate': 0,
            'leader_switch_mode': 'æœªçŸ¥'
        })
    
    def _get_previous_trade_date(self, date: str) -> str:
        """è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥"""
        # ç®€åŒ–å®ç°ï¼šç›´æ¥å‡1å¤©
        # å®é™…åº”è¯¥æŸ¥è¯¢äº¤æ˜“æ—¥å†
        try:
            date_obj = datetime.strptime(date, '%Y-%m-%d')
            prev_date = date_obj - timedelta(days=1)
            return prev_date.strftime('%Y-%m-%d')
        except:
            return date


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    calculator = ThemeDiffusionFactors()
    
    # è®¡ç®—ä»Šæ—¥é¢˜ææ‰©æ•£
    today = datetime.now().strftime('%Y-%m-%d')
    factors = calculator.calculate_all_factors(today)
    
    print("\n" + "="*70)
    print("ğŸ¯ é¢˜ææ‰©æ•£ä¸é¾™å¤´å› å­è®¡ç®—ç»“æœ")
    print("="*70)
    
    # çƒ­é—¨é¢˜æ
    print("\nã€çƒ­é—¨é¢˜æ Top 5ã€‘")
    for i in range(1, 6):
        theme_name = factors.get(f'top_{i}_theme_name', 'æ— ')
        limitup_count = factors.get(f'top_{i}_theme_limitup_count', 0)
        if theme_name != 'æ— ':
            print(f"  {i}. {theme_name}: {limitup_count}åªæ¶¨åœ")
    
    # é¢˜ææ‰©æ•£
    print("\nã€é¢˜ææ‰©æ•£åº¦ã€‘")
    print(f"  é¢˜æé›†ä¸­åº¦(HHI): {factors.get('theme_concentration_hhi', 0):.4f}")
    print(f"  é›†ä¸­åº¦çº§åˆ«: {factors.get('theme_concentration_level', 'æ— ')}")
    print(f"  æ´»è·ƒé¢˜ææ•°: {factors.get('total_active_themes', 0)}")
    print(f"  é¢˜æè½®åŠ¨é€Ÿåº¦: {factors.get('theme_rotation_speed', 0):.2f}")
    
    # é¾™å¤´è‚¡
    print("\nã€é¾™å¤´è‚¡ Top 5ã€‘")
    for i in range(1, 6):
        leader_name = factors.get(f'leader_{i}_name', 'æ— ')
        consecutive = factors.get(f'leader_{i}_consecutive_days', 0)
        score = factors.get(f'leader_{i}_score', 0)
        if leader_name != 'æ— ':
            print(f"  {i}. {leader_name}: {consecutive}è¿æ¿, è¯„åˆ†{score:.1f}")
    
    print(f"\n  é¾™å¤´æ€»æ•°: {factors.get('total_leader_count', 0)}")
    print(f"  æœ€é«˜è¿æ¿: {factors.get('max_leader_height', 0)}")
    print(f"  é¾™å¤´æº¢ä»·: {factors.get('leader_premium', 1.0):.2f}å€")
    
    # ç”Ÿå‘½å‘¨æœŸ
    print("\nã€é¢˜æç”Ÿå‘½å‘¨æœŸã€‘")
    print(f"  æ–°ç”ŸæœŸé¢˜æ: {factors.get('emerging_theme_count', 0)}")
    print(f"  æˆé•¿æœŸé¢˜æ: {factors.get('growing_theme_count', 0)}")
    print(f"  æˆç†ŸæœŸé¢˜æ: {factors.get('mature_theme_count', 0)}")
    print(f"  è¡°é€€æœŸé¢˜æ: {factors.get('declining_theme_count', 0)}")
    
    # æ¿å—è”åŠ¨
    print("\nã€æ¿å—è”åŠ¨ã€‘")
    print(f"  æœ€å¼ºæ¿å—: {factors.get('strongest_sector', 'æ— ')}")
    print(f"  æ¿å—é›†ä¸­åº¦: {factors.get('sector_concentration_hhi', 0):.4f}")
    
    # é¢˜æè”åŠ¨
    print("\nã€é¢˜æè”åŠ¨æ€§ã€‘")
    print(f"  è”åŠ¨å¼ºåº¦: {factors.get('theme_linkage_strength', 0):.4f}")
    print(f"  è”åŠ¨çº§åˆ«: {factors.get('theme_linkage_level', 'æ— ')}")
    print(f"  å…±æŒ¯é¢˜æå¯¹: {factors.get('theme_resonance_pairs', 0)}")
    print(f"  å¼ºåŠ¿é¢˜ææ•°: {factors.get('strong_theme_count', 0)}")
    
    # è·¨æ¿å—æ‰©æ•£
    print("\nã€è·¨æ¿å—æ‰©æ•£ã€‘")
    print(f"  æœ€å¹¿æ‰©æ•£é¢˜æ: {factors.get('most_spread_theme', 'æ— ')}")
    print(f"  æ¶‰åŠæ¿å—æ•°: {factors.get('most_spread_sector_count', 0)}")
    print(f"  å¹³å‡æ¿å—æ‰©æ•£: {factors.get('avg_sector_spread', 0):.2f}")
    print(f"  è·¨æ¿å—é¢˜ææ•°: {factors.get('cross_sector_theme_count', 0)}")
    print(f"  ä¸»å¯¼æ‰©æ•£æ¿å—: {factors.get('dominant_diffusion_sector', 'æ— ')}")
    print(f"  è·Ÿéšæ¿å—æ•°: {factors.get('following_sector_count', 0)}")
    
    # é¾™å¤´æ¥åŠ›
    print("\nã€é¾™å¤´æ¥åŠ›å…³ç³»ã€‘")
    print(f"  è¶…å¼ºé¾™å¤´æ•°(5+æ¿): {factors.get('super_leader_count', 0)}")
    print(f"  é¾™å¤´æŒç»­æ€§: {factors.get('leader_continuity_score', 0):.2f} ({factors.get('leader_continuity_level', 'æ— ')})")
    print(f"  é«˜ä½é¾™å¤´æ•°(3+æ¿): {factors.get('high_level_leader_count', 0)}")
    print(f"  æ¥åŠ›å¼ºåº¦: {factors.get('leader_relay_strength', 0):.2%} ({factors.get('leader_relay_level', 'æ— ')})")
    print(f"  æ¢¯é˜Ÿç»“æ„: {factors.get('leader_tier_structure', 'æ— ')} (é«˜{factors.get('leader_high_tier_count', 0)}/ä¸­{factors.get('leader_mid_tier_count', 0)}/ä½{factors.get('leader_low_tier_count', 0)})")
    print(f"  æ–°å¢é¾™å¤´: {factors.get('new_leader_count', 0)}")
    print(f"  æŒç»­é¾™å¤´: {factors.get('continuing_leader_count', 0)}")
    print(f"  é¾™å¤´ç¨³å®šæ€§: {factors.get('leader_stability', 0):.2%}")
    print(f"  åˆ‡æ¢æ¨¡å¼: {factors.get('leader_switch_mode', 'æœªçŸ¥')}")
    
    print("\n" + "="*70)


if __name__ == '__main__':
    main()
