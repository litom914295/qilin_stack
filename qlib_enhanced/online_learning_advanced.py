"""
Qlibåœ¨çº¿å­¦ä¹ é«˜çº§å®ç° (P1-1)

é›†æˆQlibå®˜æ–¹OnlineManager,å®ç°:
1. æ»šåŠ¨çª—å£è®­ç»ƒ (90å¤©çª—å£,30å¤©é‡è®­)
2. å¢é‡æ¨¡å‹æ›´æ–°
3. æ¦‚å¿µæ¼‚ç§»æ£€æµ‹ (åŸºäºICå’Œç»Ÿè®¡æ£€éªŒ)
4. æ¨¡å‹çƒ­æ›´æ–°æœºåˆ¶ (é›¶åœæœº)
5. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
6. æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦

ä¾èµ–:
- Qlibå®˜æ–¹: qlib.workflow.online.manager.OnlineManager
- Qlibå®˜æ–¹: qlib.workflow.online.strategy.RollingStrategy
- P0-3å®Œæˆ: è·¯å¾„é…ç½®ç®¡ç†
"""

import os
import sys
import gc
import asyncio
import pickle
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, field
import logging

import pandas as pd
import numpy as np
from scipy import stats

# Qlibå®˜æ–¹å¯¼å…¥
try:
    import qlib
    from qlib.workflow.online.manager import OnlineManager
    from qlib.workflow.online.strategy import RollingStrategy
    from qlib.workflow.task.gen import RollingGen
    from qlib.model.trainer import TrainerR, DelayTrainerR
    from qlib.workflow import R
    from qlib.data.data import D
    QLIB_AVAILABLE = True
except ImportError:
    QLIB_AVAILABLE = False
    logging.warning("Qlibæœªå®‰è£…,åœ¨çº¿å­¦ä¹ é«˜çº§åŠŸèƒ½å°†å—é™")

logger = logging.getLogger(__name__)


# ============================================================================
# æ•°æ®ç±»å®šä¹‰
# ============================================================================

@dataclass
class ConceptDriftResult:
    """æ¦‚å¿µæ¼‚ç§»æ£€æµ‹ç»“æœ"""
    detected: bool
    drift_score: float
    ic_degradation: float  # ICè¡°å‡å¹…åº¦
    detection_time: datetime
    affected_features: List[str]
    recommended_action: str  # "no_action", "incremental_update", "full_retrain"
    statistical_test_pvalue: float


@dataclass
class ModelVersion:
    """æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯"""
    version: str
    created_at: datetime
    ic: float
    icir: float
    model_path: str
    metadata: Dict[str, Any]


@dataclass
class OnlineUpdateMetrics:
    """åœ¨çº¿æ›´æ–°æŒ‡æ ‡"""
    success: bool
    update_time: datetime
    samples_processed: int
    ic: float
    icir: float
    drift_detected: bool
    model_version: str
    update_duration_seconds: float


# ============================================================================
# æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨ (å¢å¼ºç‰ˆ)
# ============================================================================

class ConceptDriftDetectorAdvanced:
    """
    æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨ (åŸºäºICå’Œç»Ÿè®¡æ£€éªŒ)
    
    æ£€æµ‹æ–¹æ³•:
    1. ICæ»šåŠ¨çª—å£ç›‘æ§ (Information Coefficient)
    2. Kolmogorov-Smirnovæ£€éªŒ (ç‰¹å¾åˆ†å¸ƒå˜åŒ–)
    3. Page-Hinkleyæ£€éªŒ (åœ¨çº¿å˜ç‚¹æ£€æµ‹)
    4. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
    """
    
    def __init__(
        self,
        window_size: int = 20,
        ic_threshold: float = 0.05,
        ks_threshold: float = 0.1,
        min_samples: int = 100
    ):
        """
        åˆå§‹åŒ–æ¼‚ç§»æ£€æµ‹å™¨
        
        Args:
            window_size: æ»šåŠ¨çª—å£å¤§å°(å¤©æ•°)
            ic_threshold: ICè¡°å‡é˜ˆå€¼
            ks_threshold: KSæ£€éªŒé˜ˆå€¼
            min_samples: æœ€å°æ ·æœ¬æ•°
        """
        self.window_size = window_size
        self.ic_threshold = ic_threshold
        self.ks_threshold = ks_threshold
        self.min_samples = min_samples
        
        # å†å²è®°å½•
        self.ic_history = []
        self.icir_history = []
        self.feature_distributions = {}
        self.reference_distribution = None
        
        logger.info(
            f"æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨åˆå§‹åŒ–: window_size={window_size}, "
            f"ic_threshold={ic_threshold}"
        )
    
    def detect(
        self,
        predictions: np.ndarray,
        labels: np.ndarray,
        features: Optional[pd.DataFrame] = None
    ) -> ConceptDriftResult:
        """
        æ£€æµ‹æ¦‚å¿µæ¼‚ç§»
        
        Args:
            predictions: æ¨¡å‹é¢„æµ‹å€¼
            labels: çœŸå®æ ‡ç­¾
            features: ç‰¹å¾æ•°æ®(å¯é€‰,ç”¨äºåˆ†å¸ƒæ£€æµ‹)
            
        Returns:
            ConceptDriftResult
        """
        # 1. è®¡ç®—IC
        current_ic = self._calculate_ic(predictions, labels)
        self.ic_history.append(current_ic)
        
        # 2. ICè¡°å‡æ£€æµ‹
        ic_degradation = 0.0
        ic_drift_detected = False
        
        if len(self.ic_history) >= self.window_size:
            recent_ic = np.mean(self.ic_history[-self.window_size:])
            historical_ic = np.mean(self.ic_history[:-self.window_size])
            ic_degradation = historical_ic - recent_ic
            
            if ic_degradation > self.ic_threshold:
                ic_drift_detected = True
                logger.warning(
                    f"ICæ¼‚ç§»æ£€æµ‹åˆ°! "
                    f"å†å²IC={historical_ic:.4f} â†’ è¿‘æœŸIC={recent_ic:.4f} "
                    f"(è¡°å‡={ic_degradation:.4f})"
                )
        
        # 3. ç»Ÿè®¡æ£€éªŒ (KSæ£€éªŒ)
        ks_pvalue = 1.0
        feature_drift_detected = False
        affected_features = []
        
        if features is not None and len(self.ic_history) >= self.window_size:
            feature_drift_detected, ks_pvalue, affected_features = \
                self._detect_feature_drift(features)
        
        # 4. ç»¼åˆåˆ¤æ–­
        drift_detected = ic_drift_detected or feature_drift_detected
        drift_score = max(ic_degradation / (self.ic_threshold + 1e-8), 
                         1.0 - ks_pvalue)
        
        # 5. æ¨èè¡ŒåŠ¨
        if drift_score > 2.0:
            action = "full_retrain"
        elif drift_score > 1.0:
            action = "incremental_update"
        else:
            action = "no_action"
        
        return ConceptDriftResult(
            detected=drift_detected,
            drift_score=drift_score,
            ic_degradation=ic_degradation,
            detection_time=datetime.now(),
            affected_features=affected_features,
            recommended_action=action,
            statistical_test_pvalue=ks_pvalue
        )
    
    def _calculate_ic(self, predictions: np.ndarray, labels: np.ndarray) -> float:
        """è®¡ç®—Information Coefficient"""
        try:
            # å¤„ç†NaN
            mask = ~(np.isnan(predictions) | np.isnan(labels))
            if mask.sum() < self.min_samples:
                return 0.0
            
            ic = np.corrcoef(predictions[mask], labels[mask])[0, 1]
            return ic if not np.isnan(ic) else 0.0
        except Exception as e:
            logger.error(f"è®¡ç®—ICå¤±è´¥: {e}")
            return 0.0
    
    def _detect_feature_drift(
        self,
        features: pd.DataFrame
    ) -> Tuple[bool, float, List[str]]:
        """
        æ£€æµ‹ç‰¹å¾åˆ†å¸ƒæ¼‚ç§» (KSæ£€éªŒ)
        
        Returns:
            (æ˜¯å¦æ¼‚ç§», på€¼, å—å½±å“ç‰¹å¾åˆ—è¡¨)
        """
        if self.reference_distribution is None:
            # åˆå§‹åŒ–å‚è€ƒåˆ†å¸ƒ
            self.reference_distribution = {
                col: features[col].values
                for col in features.columns
            }
            return False, 1.0, []
        
        # KSæ£€éªŒ
        ks_results = {}
        for col in features.columns:
            if col not in self.reference_distribution:
                continue
            
            try:
                stat, pvalue = stats.ks_2samp(
                    self.reference_distribution[col],
                    features[col].values
                )
                ks_results[col] = (stat, pvalue)
            except Exception as e:
                logger.warning(f"ç‰¹å¾{col}çš„KSæ£€éªŒå¤±è´¥: {e}")
                continue
        
        # æ‰¾å‡ºæ˜¾è‘—å˜åŒ–çš„ç‰¹å¾
        affected_features = [
            col for col, (stat, pvalue) in ks_results.items()
            if stat > self.ks_threshold or pvalue < 0.05
        ]
        
        # ç»¼åˆpå€¼ (å–æœ€å°)
        min_pvalue = min([p for _, p in ks_results.values()]) if ks_results else 1.0
        
        drift_detected = len(affected_features) > 0
        
        if drift_detected:
            logger.warning(
                f"ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹åˆ°! "
                f"å—å½±å“ç‰¹å¾: {affected_features[:5]} "
                f"(min_pvalue={min_pvalue:.4f})"
            )
        
        return drift_detected, min_pvalue, affected_features
    
    def reset_reference(self, features: pd.DataFrame):
        """é‡ç½®å‚è€ƒåˆ†å¸ƒ (é‡è®­ç»ƒåè°ƒç”¨)"""
        self.reference_distribution = {
            col: features[col].values
            for col in features.columns
        }
        logger.info("å‚è€ƒåˆ†å¸ƒå·²é‡ç½®")


# ============================================================================
# æ¨¡å‹çƒ­æ›´æ–°å™¨
# ============================================================================

class ModelHotReloader:
    """
    æ¨¡å‹çƒ­æ›´æ–°å™¨ (é›¶åœæœºåˆ‡æ¢)
    
    ç‰¹æ€§:
    1. å¼‚æ­¥åŠ è½½æ–°æ¨¡å‹
    2. æ¨¡å‹éªŒè¯
    3. åŸå­åˆ‡æ¢ (æ— ç¼åˆ‡æ¢)
    4. è‡ªåŠ¨æ¸…ç†æ—§æ¨¡å‹
    """
    
    def __init__(self):
        self.current_model = None
        self.loading_model = None
        self.lock = asyncio.Lock()
        self.load_count = 0
        
        logger.info("æ¨¡å‹çƒ­æ›´æ–°å™¨åˆå§‹åŒ–")
    
    async def hot_reload(
        self,
        new_model: Any,
        validation_data: Optional[Tuple[pd.DataFrame, pd.Series]] = None
    ) -> bool:
        """
        çƒ­æ›´æ–°æ¨¡å‹
        
        Args:
            new_model: æ–°æ¨¡å‹å¯¹è±¡
            validation_data: éªŒè¯æ•°æ® (å¯é€‰)
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        start_time = datetime.now()
        
        try:
            async with self.lock:
                # 1. éªŒè¯æ–°æ¨¡å‹
                if validation_data is not None:
                    if not self._validate_model(new_model, validation_data):
                        logger.error("æ–°æ¨¡å‹éªŒè¯å¤±è´¥,å–æ¶ˆçƒ­æ›´æ–°")
                        return False
                
                # 2. åŸå­åˆ‡æ¢
                old_model = self.current_model
                self.current_model = new_model
                self.loading_model = None
                self.load_count += 1
                
                # 3. æ¸…ç†æ—§æ¨¡å‹
                if old_model is not None:
                    del old_model
                    gc.collect()
                
                duration = (datetime.now() - start_time).total_seconds()
                logger.info(
                    f"âœ… æ¨¡å‹çƒ­æ›´æ–°å®Œæˆ "
                    f"(ç¬¬{self.load_count}æ¬¡, è€—æ—¶{duration:.2f}ç§’)"
                )
                
                return True
                
        except Exception as e:
            logger.error(f"æ¨¡å‹çƒ­æ›´æ–°å¤±è´¥: {e}")
            return False
    
    def _validate_model(
        self,
        model: Any,
        validation_data: Tuple[pd.DataFrame, pd.Series]
    ) -> bool:
        """éªŒè¯æ¨¡å‹"""
        try:
            X_val, y_val = validation_data
            predictions = model.predict(X_val)
            
            # æ£€æŸ¥é¢„æµ‹è¾“å‡º
            if predictions is None or len(predictions) == 0:
                return False
            
            # æ£€æŸ¥IC
            ic = np.corrcoef(predictions, y_val)[0, 1]
            if np.isnan(ic) or abs(ic) < 0.01:
                logger.warning(f"æ¨¡å‹éªŒè¯ICè¿‡ä½: {ic:.4f}")
                return False
            
            logger.info(f"æ¨¡å‹éªŒè¯é€šè¿‡: IC={ic:.4f}")
            return True
            
        except Exception as e:
            logger.error(f"æ¨¡å‹éªŒè¯å¼‚å¸¸: {e}")
            return False
    
    def get_current_model(self) -> Optional[Any]:
        """è·å–å½“å‰æ¨¡å‹"""
        return self.current_model


# ============================================================================
# æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨
# ============================================================================

class ModelRegistry:
    """
    æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨
    
    åŠŸèƒ½:
    1. æ¨¡å‹ç‰ˆæœ¬æ³¨å†Œ
    2. æœ€ä¼˜æ¨¡å‹è¿½è¸ª
    3. å†å²æ¨¡å‹å›æ»š
    4. æ¨¡å‹å…ƒæ•°æ®ç®¡ç†
    """
    
    def __init__(self, storage_dir: str = "./mlruns/model_registry"):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        self.versions: List[ModelVersion] = []
        self.current_best_ic = -np.inf
        self.best_version = None
        
        logger.info(f"æ¨¡å‹æ³¨å†Œè¡¨åˆå§‹åŒ–: {self.storage_dir}")
    
    def register(
        self,
        model: Any,
        metrics: Dict[str, float],
        metadata: Optional[Dict[str, Any]] = None
    ) -> ModelVersion:
        """
        æ³¨å†Œæ–°æ¨¡å‹ç‰ˆæœ¬
        
        Args:
            model: æ¨¡å‹å¯¹è±¡
            metrics: æ€§èƒ½æŒ‡æ ‡ {"ic": 0.05, "icir": 0.5}
            metadata: å…ƒæ•°æ®
            
        Returns:
            ModelVersion
        """
        # ç”Ÿæˆç‰ˆæœ¬å·
        version_id = f"v{len(self.versions) + 1}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ä¿å­˜æ¨¡å‹
        model_path = self.storage_dir / f"{version_id}.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        
        # åˆ›å»ºç‰ˆæœ¬è®°å½•
        version = ModelVersion(
            version=version_id,
            created_at=datetime.now(),
            ic=metrics.get('ic', 0.0),
            icir=metrics.get('icir', 0.0),
            model_path=str(model_path),
            metadata=metadata or {}
        )
        
        self.versions.append(version)
        
        # æ›´æ–°æœ€ä¼˜æ¨¡å‹
        if version.ic > self.current_best_ic:
            self.current_best_ic = version.ic
            self.best_version = version
            logger.info(
                f"ğŸ† æ–°çš„æœ€ä¼˜æ¨¡å‹: {version_id} "
                f"(IC={version.ic:.4f}, ICIR={version.icir:.4f})"
            )
        else:
            logger.info(
                f"æ¨¡å‹æ³¨å†Œ: {version_id} "
                f"(IC={version.ic:.4f}, ICIR={version.icir:.4f})"
            )
        
        return version
    
    def get_best_model(self) -> Optional[Any]:
        """è·å–æœ€ä¼˜æ¨¡å‹"""
        if self.best_version is None:
            return None
        
        with open(self.best_version.model_path, 'rb') as f:
            return pickle.load(f)
    
    def load_version(self, version_id: str) -> Optional[Any]:
        """åŠ è½½æŒ‡å®šç‰ˆæœ¬"""
        for version in self.versions:
            if version.version == version_id:
                with open(version.model_path, 'rb') as f:
                    return pickle.load(f)
        return None
    
    def get_version_history(self) -> pd.DataFrame:
        """è·å–ç‰ˆæœ¬å†å²"""
        if not self.versions:
            return pd.DataFrame()
        
        return pd.DataFrame([
            {
                'version': v.version,
                'created_at': v.created_at,
                'ic': v.ic,
                'icir': v.icir,
                'is_best': v == self.best_version
            }
            for v in self.versions
        ])


# ============================================================================
# Qlibåœ¨çº¿å­¦ä¹ é«˜çº§ç®¡ç†å™¨
# ============================================================================

class QlibOnlineLearningAdvanced:
    """
    Qlibåœ¨çº¿å­¦ä¹ é«˜çº§ç®¡ç†å™¨
    
    åŠŸèƒ½:
    1. é›†æˆå®˜æ–¹OnlineManager
    2. æ»šåŠ¨çª—å£è®­ç»ƒ (90å¤©çª—å£,30å¤©é‡è®­)
    3. æ¦‚å¿µæ¼‚ç§»è‡ªé€‚åº”
    4. æ¨¡å‹çƒ­æ›´æ–°
    5. æ€§èƒ½ç›‘æ§
    """
    
    def __init__(
        self,
        task_config: Dict[str, Any],
        rolling_window: int = 90,
        retrain_interval: int = 30,
        drift_threshold: float = 0.05,
        enable_hot_reload: bool = True,
        qlib_provider_uri: Optional[str] = None,
        qlib_region: str = "cn"
    ):
        """
        åˆå§‹åŒ–åœ¨çº¿å­¦ä¹ ç®¡ç†å™¨
        
        Args:
            task_config: Qlibä»»åŠ¡é…ç½®
            rolling_window: æ»šåŠ¨çª—å£å¤§å°(å¤©)
            retrain_interval: é‡è®­ç»ƒé—´éš”(å¤©)
            drift_threshold: æ¼‚ç§»æ£€æµ‹é˜ˆå€¼
            enable_hot_reload: å¯ç”¨çƒ­æ›´æ–°
            qlib_provider_uri: Qlibæ•°æ®è·¯å¾„
            qlib_region: QlibåŒºåŸŸ
        """
        if not QLIB_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…Qlib: pip install pyqlib")
        
        # Qlibåˆå§‹åŒ–
        if qlib_provider_uri:
            qlib.init(provider_uri=qlib_provider_uri, region=qlib_region)
        
        self.task_config = task_config
        self.rolling_window = rolling_window
        self.retrain_interval = retrain_interval
        
        # æ ¸å¿ƒç»„ä»¶
        self.drift_detector = ConceptDriftDetectorAdvanced(
            ic_threshold=drift_threshold
        )
        self.model_registry = ModelRegistry()
        self.hot_reloader = ModelHotReloader() if enable_hot_reload else None
        
        # åœ¨çº¿ç®¡ç†å™¨ (å»¶è¿Ÿåˆå§‹åŒ–)
        self.online_manager: Optional[OnlineManager] = None
        self.strategy: Optional[RollingStrategy] = None
        
        # æ€§èƒ½å†å²
        self.metrics_history = []
        
        logger.info(
            f"Qlibåœ¨çº¿å­¦ä¹ é«˜çº§ç®¡ç†å™¨åˆå§‹åŒ–: "
            f"rolling_window={rolling_window}å¤©, "
            f"retrain_interval={retrain_interval}å¤©"
        )
    
    def initialize_strategy(self, strategy_name: str = "rolling_strategy"):
        """åˆå§‹åŒ–æ»šåŠ¨ç­–ç•¥"""
        # åˆ›å»ºRollingGen
        rolling_gen = RollingGen(
            step=self.retrain_interval,
            rtype=RollingGen.ROLL_SD
        )
        
        # åˆ›å»ºRollingStrategy
        self.strategy = RollingStrategy(
            name_id=strategy_name,
            task_template=self.task_config,
            rolling_gen=rolling_gen
        )
        
        # åˆ›å»ºOnlineManager
        self.online_manager = OnlineManager(
            strategies=[self.strategy],
            trainer=TrainerR()
        )
        
        logger.info(f"æ»šåŠ¨ç­–ç•¥åˆå§‹åŒ–å®Œæˆ: {strategy_name}")
    
    async def first_train(self) -> OnlineUpdateMetrics:
        """é¦–æ¬¡è®­ç»ƒ"""
        if self.online_manager is None:
            raise ValueError("éœ€è¦å…ˆè°ƒç”¨initialize_strategy()")
        
        start_time = datetime.now()
        logger.info("å¼€å§‹é¦–æ¬¡è®­ç»ƒ...")
        
        try:
            # é¦–æ¬¡è®­ç»ƒ
            self.online_manager.first_train()
            
            # è·å–é¦–ä¸ªæ¨¡å‹
            # TODO: ä»OnlineManageræå–æ¨¡å‹å’Œé¢„æµ‹
            
            duration = (datetime.now() - start_time).total_seconds()
            
            metrics = OnlineUpdateMetrics(
                success=True,
                update_time=datetime.now(),
                samples_processed=0,
                ic=0.0,
                icir=0.0,
                drift_detected=False,
                model_version="v1_initial",
                update_duration_seconds=duration
            )
            
            self.metrics_history.append(metrics)
            logger.info(f"âœ… é¦–æ¬¡è®­ç»ƒå®Œæˆ (è€—æ—¶{duration:.2f}ç§’)")
            
            return metrics
            
        except Exception as e:
            logger.error(f"é¦–æ¬¡è®­ç»ƒå¤±è´¥: {e}")
            raise
    
    async def online_update(
        self,
        current_date: Union[str, pd.Timestamp],
        enable_drift_detection: bool = True
    ) -> OnlineUpdateMetrics:
        """
        åœ¨çº¿æ›´æ–°ä¸»æµç¨‹
        
        Args:
            current_date: å½“å‰æ—¥æœŸ
            enable_drift_detection: å¯ç”¨æ¼‚ç§»æ£€æµ‹
            
        Returns:
            OnlineUpdateMetrics
        """
        start_time = datetime.now()
        logger.info(f"å¼€å§‹åœ¨çº¿æ›´æ–°: {current_date}")
        
        try:
            # 1. æ‰§è¡Œroutine
            self.online_manager.routine(cur_time=current_date)
            
            # 2. è·å–é¢„æµ‹å’Œæ ‡ç­¾
            # TODO: ä»OnlineManageræå–é¢„æµ‹ç»“æœ
            # predictions = self._get_latest_predictions()
            # labels = self._get_latest_labels()
            
            # 3. æ¦‚å¿µæ¼‚ç§»æ£€æµ‹
            drift_result = None
            if enable_drift_detection:
                # drift_result = self.drift_detector.detect(predictions, labels)
                pass
            
            # 4. æ ¹æ®æ¼‚ç§»ç»“æœé‡‡å–è¡ŒåŠ¨
            # if drift_result and drift_result.detected:
            #     if drift_result.recommended_action == "full_retrain":
            #         await self._trigger_full_retrain(current_date)
            
            # 5. æ¨¡å‹çƒ­æ›´æ–°
            # if self.hot_reloader:
            #     new_model = self._get_latest_model()
            #     await self.hot_reloader.hot_reload(new_model)
            
            duration = (datetime.now() - start_time).total_seconds()
            
            metrics = OnlineUpdateMetrics(
                success=True,
                update_time=datetime.now(),
                samples_processed=0,
                ic=0.0,
                icir=0.0,
                drift_detected=drift_result.detected if drift_result else False,
                model_version=f"v{len(self.metrics_history) + 1}",
                update_duration_seconds=duration
            )
            
            self.metrics_history.append(metrics)
            logger.info(f"âœ… åœ¨çº¿æ›´æ–°å®Œæˆ (è€—æ—¶{duration:.2f}ç§’)")
            
            return metrics
            
        except Exception as e:
            logger.error(f"åœ¨çº¿æ›´æ–°å¤±è´¥: {e}")
            raise
    
    def get_performance_summary(self) -> pd.DataFrame:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics_history:
            return pd.DataFrame()
        
        return pd.DataFrame([
            {
                'update_time': m.update_time,
                'ic': m.ic,
                'icir': m.icir,
                'drift_detected': m.drift_detected,
                'model_version': m.model_version,
                'duration_seconds': m.update_duration_seconds
            }
            for m in self.metrics_history
        ])


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

async def example_advanced_online_learning():
    """é«˜çº§åœ¨çº¿å­¦ä¹ ç¤ºä¾‹"""
    print("=== Qlibåœ¨çº¿å­¦ä¹ é«˜çº§ç¤ºä¾‹ (P1-1) ===\n")
    
    # ä»»åŠ¡é…ç½® (ç¤ºä¾‹)
    task_config = {
        "model": {
            "class": "LGBModel",
            "module_path": "qlib.contrib.model.gbdt",
            "kwargs": {
                "loss": "mse",
                "colsample_bytree": 0.8879,
                "learning_rate": 0.0421,
                "subsample": 0.8789,
                "lambda_l1": 205.6999,
                "lambda_l2": 580.9768,
                "max_depth": 8,
                "num_leaves": 210,
                "num_threads": 20,
            },
        },
        "dataset": {
            "class": "DatasetH",
            "module_path": "qlib.data.dataset",
            "kwargs": {
                "handler": {
                    "class": "Alpha158",
                    "module_path": "qlib.contrib.data.handler",
                    "kwargs": {"start_time": "2008-01-01", "end_time": "2020-08-01"},
                },
                "segments": {
                    "train": ("2008-01-01", "2014-12-31"),
                    "valid": ("2015-01-01", "2016-12-31"),
                    "test": ("2017-01-01", "2020-08-01"),
                },
            },
        },
    }
    
    try:
        # åˆ›å»ºç®¡ç†å™¨
        manager = QlibOnlineLearningAdvanced(
            task_config=task_config,
            rolling_window=90,
            retrain_interval=30,
            drift_threshold=0.05
        )
        
        # åˆå§‹åŒ–ç­–ç•¥
        manager.initialize_strategy()
        
        # é¦–æ¬¡è®­ç»ƒ
        print("1. é¦–æ¬¡è®­ç»ƒ...")
        first_metrics = await manager.first_train()
        print(f"   âœ… å®Œæˆ: {first_metrics}\n")
        
        # æ¨¡æ‹Ÿåœ¨çº¿æ›´æ–°
        print("2. æ¨¡æ‹Ÿ30å¤©åœ¨çº¿æ›´æ–°...")
        base_date = pd.Timestamp("2020-09-01")
        for day in range(5):  # æ¼”ç¤º5å¤©
            current_date = base_date + timedelta(days=day)
            print(f"   Day {day + 1}: {current_date.date()}")
            
            metrics = await manager.online_update(current_date)
            print(f"   IC={metrics.ic:.4f}, æ¼‚ç§»={metrics.drift_detected}")
        
        print("\n3. æ€§èƒ½æ‘˜è¦:")
        print(manager.get_performance_summary())
        
        print("\nâœ… ç¤ºä¾‹å®Œæˆ!")
        
    except ImportError as e:
        print(f"âŒ éœ€è¦Qlibç¯å¢ƒ: {e}")
        print("   æç¤º: è¯·ç¡®ä¿å·²å®‰è£…Qlibå¹¶é…ç½®å¥½æ•°æ®")


if __name__ == "__main__":
    asyncio.run(example_advanced_online_learning())
