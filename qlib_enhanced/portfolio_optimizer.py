"""
æŠ•èµ„ç»„åˆä¼˜åŒ–å™¨æ¨¡å—
å®ç°å¤šç§èµ„äº§é…ç½®ä¼˜åŒ–ç®—æ³•ï¼šå‡å€¼æ–¹å·®ã€Black-Littermanã€é£é™©å¹³ä»·ç­‰
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import logging
from scipy.optimize import minimize
from dataclasses import dataclass

logger = logging.getLogger(__name__)


# ============================================================================
# æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    weights: np.ndarray
    expected_return: float
    expected_risk: float
    sharpe_ratio: float
    method: str
    constraints: Dict
    metadata: Dict


# ============================================================================
# å‡å€¼æ–¹å·®ä¼˜åŒ–å™¨ (Markowitz)
# ============================================================================

class MeanVarianceOptimizer:
    """
    å‡å€¼æ–¹å·®ä¼˜åŒ–å™¨ (Markowitzæ¨¡å‹)
    æœ€å¤§åŒ–å¤æ™®æ¯”ç‡æˆ–æœ€å°åŒ–é£é™©
    """
    
    def __init__(self, returns: pd.DataFrame, risk_free_rate: float = 0.03):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Args:
            returns: èµ„äº§æ”¶ç›Šç‡æ•°æ® (N x M: Nä¸ªæ—¶é—´ç‚¹, Mä¸ªèµ„äº§)
            risk_free_rate: æ— é£é™©åˆ©ç‡
        """
        self.returns = returns
        self.risk_free_rate = risk_free_rate
        self.n_assets = returns.shape[1]
        
        # è®¡ç®—æœŸæœ›æ”¶ç›Šå’Œåæ–¹å·®çŸ©é˜µ
        self.expected_returns = returns.mean() * 252  # å¹´åŒ–
        self.cov_matrix = returns.cov() * 252  # å¹´åŒ–
        
        logger.info(f"å‡å€¼æ–¹å·®ä¼˜åŒ–å™¨åˆå§‹åŒ–: {self.n_assets}ä¸ªèµ„äº§")
    
    def optimize_sharpe(self,
                       target_return: Optional[float] = None,
                       allow_short: bool = False) -> OptimizationResult:
        """
        æœ€å¤§åŒ–å¤æ™®æ¯”ç‡
        
        Args:
            target_return: ç›®æ ‡æ”¶ç›Šç‡ (å¯é€‰)
            allow_short: æ˜¯å¦å…è®¸åšç©º
        
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        logger.info("ä¼˜åŒ–ç›®æ ‡: æœ€å¤§åŒ–å¤æ™®æ¯”ç‡")
        
        # ç›®æ ‡å‡½æ•°: è´Ÿå¤æ™®æ¯”ç‡
        def neg_sharpe(weights):
            portfolio_return = np.dot(weights, self.expected_returns)
            portfolio_std = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
            sharpe = (portfolio_return - self.risk_free_rate) / portfolio_std
            return -sharpe
        
        # çº¦æŸæ¡ä»¶
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]  # æƒé‡å’Œä¸º1
        
        if target_return is not None:
            constraints.append({
                'type': 'eq',
                'fun': lambda w: np.dot(w, self.expected_returns) - target_return
            })
        
        # è¾¹ç•Œ
        if allow_short:
            bounds = [(-1, 1) for _ in range(self.n_assets)]
        else:
            bounds = [(0, 1) for _ in range(self.n_assets)]
        
        # åˆå§‹æƒé‡ (ç­‰æƒ)
        init_weights = np.array([1.0 / self.n_assets] * self.n_assets)
        
        # ä¼˜åŒ–
        result = minimize(
            neg_sharpe,
            init_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints
        )
        
        if not result.success:
            logger.warning(f"ä¼˜åŒ–æœªæ”¶æ•›: {result.message}")
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        weights = result.x
        expected_return = np.dot(weights, self.expected_returns)
        expected_risk = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
        sharpe_ratio = (expected_return - self.risk_free_rate) / expected_risk
        
        return OptimizationResult(
            weights=weights,
            expected_return=expected_return,
            expected_risk=expected_risk,
            sharpe_ratio=sharpe_ratio,
            method='max_sharpe',
            constraints={'target_return': target_return, 'allow_short': allow_short},
            metadata={'success': result.success, 'message': result.message}
        )
    
    def optimize_min_volatility(self, allow_short: bool = False) -> OptimizationResult:
        """
        æœ€å°åŒ–æ³¢åŠ¨ç‡
        
        Args:
            allow_short: æ˜¯å¦å…è®¸åšç©º
        
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        logger.info("ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–æ³¢åŠ¨ç‡")
        
        # ç›®æ ‡å‡½æ•°: æ³¢åŠ¨ç‡
        def portfolio_volatility(weights):
            return np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
        
        # çº¦æŸæ¡ä»¶
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
        
        # è¾¹ç•Œ
        if allow_short:
            bounds = [(-1, 1) for _ in range(self.n_assets)]
        else:
            bounds = [(0, 1) for _ in range(self.n_assets)]
        
        # åˆå§‹æƒé‡
        init_weights = np.array([1.0 / self.n_assets] * self.n_assets)
        
        # ä¼˜åŒ–
        result = minimize(
            portfolio_volatility,
            init_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints
        )
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        weights = result.x
        expected_return = np.dot(weights, self.expected_returns)
        expected_risk = portfolio_volatility(weights)
        sharpe_ratio = (expected_return - self.risk_free_rate) / expected_risk
        
        return OptimizationResult(
            weights=weights,
            expected_return=expected_return,
            expected_risk=expected_risk,
            sharpe_ratio=sharpe_ratio,
            method='min_volatility',
            constraints={'allow_short': allow_short},
            metadata={'success': result.success}
        )
    
    def efficient_frontier(self, n_points: int = 50) -> List[OptimizationResult]:
        """
        è®¡ç®—æœ‰æ•ˆå‰æ²¿
        
        Args:
            n_points: å‰æ²¿ç‚¹æ•°
        
        Returns:
            æœ‰æ•ˆå‰æ²¿ä¸Šçš„ä¼˜åŒ–ç»“æœåˆ—è¡¨
        """
        logger.info(f"è®¡ç®—æœ‰æ•ˆå‰æ²¿: {n_points}ä¸ªç‚¹")
        
        # æ‰¾åˆ°æœ€å°å’Œæœ€å¤§æ”¶ç›Š
        min_vol_result = self.optimize_min_volatility()
        max_return = self.expected_returns.max()
        
        target_returns = np.linspace(
            min_vol_result.expected_return,
            max_return * 0.95,
            n_points
        )
        
        frontier = []
        for target_return in target_returns:
            try:
                result = self.optimize_sharpe(target_return=target_return)
                frontier.append(result)
            except Exception as e:
                logger.warning(f"è®¡ç®—å‰æ²¿ç‚¹å¤±è´¥ (target={target_return:.4f}): {e}")
        
        return frontier


# ============================================================================
# Black-Littermanæ¨¡å‹
# ============================================================================

class BlackLittermanOptimizer:
    """
    Black-Littermanèµ„äº§é…ç½®æ¨¡å‹
    ç»“åˆå¸‚åœºå‡è¡¡å’ŒæŠ•èµ„è€…è§‚ç‚¹
    """
    
    def __init__(self,
                 returns: pd.DataFrame,
                 market_caps: Optional[np.ndarray] = None,
                 risk_free_rate: float = 0.03,
                 tau: float = 0.05):
        """
        åˆå§‹åŒ–Black-Littermanä¼˜åŒ–å™¨
        
        Args:
            returns: èµ„äº§æ”¶ç›Šç‡æ•°æ®
            market_caps: å¸‚åœºå¸‚å€¼ (ç”¨äºè®¡ç®—å¸‚åœºæƒé‡)
            risk_free_rate: æ— é£é™©åˆ©ç‡
            tau: å…ˆéªŒä¸ç¡®å®šæ€§å‚æ•°
        """
        self.returns = returns
        self.n_assets = returns.shape[1]
        self.risk_free_rate = risk_free_rate
        self.tau = tau
        
        # åæ–¹å·®çŸ©é˜µ
        self.cov_matrix = returns.cov() * 252
        
        # å¸‚åœºæƒé‡ (å¦‚æœæ²¡æœ‰æä¾›å¸‚å€¼ï¼Œä½¿ç”¨ç­‰æƒ)
        if market_caps is not None:
            self.market_weights = market_caps / market_caps.sum()
        else:
            self.market_weights = np.ones(self.n_assets) / self.n_assets
        
        # è®¡ç®—éšå«æ”¶ç›Š (å¸‚åœºå‡è¡¡æ”¶ç›Š)
        self.implied_returns = self._calculate_implied_returns()
        
        logger.info(f"Black-Littermanä¼˜åŒ–å™¨åˆå§‹åŒ–: {self.n_assets}ä¸ªèµ„äº§")
    
    def _calculate_implied_returns(self, delta: float = 2.5) -> np.ndarray:
        """
        è®¡ç®—éšå«æ”¶ç›Šç‡
        
        Args:
            delta: é£é™©åŒæ¶ç³»æ•°
        
        Returns:
            éšå«æ”¶ç›Šç‡å‘é‡
        """
        return delta * np.dot(self.cov_matrix, self.market_weights)
    
    def optimize_with_views(self,
                           views: Dict[int, float],
                           view_confidence: float = 0.5) -> OptimizationResult:
        """
        åŸºäºæŠ•èµ„è€…è§‚ç‚¹è¿›è¡Œä¼˜åŒ–
        
        Args:
            views: æŠ•èµ„è€…è§‚ç‚¹ {èµ„äº§ç´¢å¼•: é¢„æœŸæ”¶ç›Šç‡}
            view_confidence: è§‚ç‚¹ç½®ä¿¡åº¦ (0-1)
        
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        logger.info(f"åŸºäºè§‚ç‚¹ä¼˜åŒ–: {len(views)}ä¸ªè§‚ç‚¹")
        
        # æ„å»ºè§‚ç‚¹çŸ©é˜µPå’Œè§‚ç‚¹å‘é‡Q
        n_views = len(views)
        P = np.zeros((n_views, self.n_assets))
        Q = np.zeros(n_views)
        
        for i, (asset_idx, expected_return) in enumerate(views.items()):
            P[i, asset_idx] = 1
            Q[i] = expected_return
        
        # è§‚ç‚¹ä¸ç¡®å®šæ€§çŸ©é˜µÎ©
        omega = np.diag(np.diag(np.dot(P, np.dot(self.tau * self.cov_matrix, P.T)))) / view_confidence
        
        # Black-Littermanå…¬å¼
        # åéªŒåæ–¹å·®
        M_inverse = np.linalg.inv(np.linalg.inv(self.tau * self.cov_matrix) + 
                                  np.dot(P.T, np.dot(np.linalg.inv(omega), P)))
        
        # åéªŒæœŸæœ›æ”¶ç›Š
        posterior_returns = np.dot(M_inverse,
                                  np.dot(np.linalg.inv(self.tau * self.cov_matrix), 
                                        self.implied_returns) +
                                  np.dot(P.T, np.dot(np.linalg.inv(omega), Q)))
        
        # ä½¿ç”¨åéªŒæ”¶ç›Šä¼˜åŒ–æƒé‡
        def neg_utility(weights):
            return -(np.dot(weights, posterior_returns) - 
                    0.5 * np.dot(weights.T, np.dot(self.cov_matrix, weights)))
        
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
        bounds = [(0, 1) for _ in range(self.n_assets)]
        init_weights = self.market_weights
        
        result = minimize(neg_utility, init_weights, method='SLSQP',
                        bounds=bounds, constraints=constraints)
        
        weights = result.x
        expected_return = np.dot(weights, posterior_returns)
        expected_risk = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
        sharpe_ratio = (expected_return - self.risk_free_rate) / expected_risk
        
        return OptimizationResult(
            weights=weights,
            expected_return=expected_return,
            expected_risk=expected_risk,
            sharpe_ratio=sharpe_ratio,
            method='black_litterman',
            constraints={'views': views, 'confidence': view_confidence},
            metadata={'posterior_returns': posterior_returns}
        )


# ============================================================================
# é£é™©å¹³ä»· (Risk Parity)
# ============================================================================

class RiskParityOptimizer:
    """
    é£é™©å¹³ä»·ä¼˜åŒ–å™¨
    ä½¿æ¯ä¸ªèµ„äº§å¯¹ç»„åˆé£é™©çš„è´¡çŒ®ç›¸ç­‰
    """
    
    def __init__(self, returns: pd.DataFrame):
        """
        åˆå§‹åŒ–é£é™©å¹³ä»·ä¼˜åŒ–å™¨
        
        Args:
            returns: èµ„äº§æ”¶ç›Šç‡æ•°æ®
        """
        self.returns = returns
        self.n_assets = returns.shape[1]
        self.cov_matrix = returns.cov() * 252
        
        logger.info(f"é£é™©å¹³ä»·ä¼˜åŒ–å™¨åˆå§‹åŒ–: {self.n_assets}ä¸ªèµ„äº§")
    
    def optimize(self) -> OptimizationResult:
        """
        é£é™©å¹³ä»·ä¼˜åŒ–
        
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        logger.info("æ‰§è¡Œé£é™©å¹³ä»·ä¼˜åŒ–")
        
        def risk_parity_objective(weights):
            """ç›®æ ‡å‡½æ•°: æœ€å°åŒ–é£é™©è´¡çŒ®çš„æ–¹å·®"""
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
            
            # æ¯ä¸ªèµ„äº§çš„è¾¹é™…é£é™©è´¡çŒ®
            marginal_contrib = np.dot(self.cov_matrix, weights) / portfolio_vol
            
            # é£é™©è´¡çŒ®
            risk_contrib = weights * marginal_contrib
            
            # ç›®æ ‡æ”¶ç›Šè´¡çŒ®å‡ç­‰
            target_risk = portfolio_vol / self.n_assets
            
            # æœ€å°åŒ–ä¸ç›®æ ‡çš„åå·®
            return np.sum((risk_contrib - target_risk) ** 2)
        
        # çº¦æŸå’Œè¾¹ç•Œ
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
        bounds = [(0, 1) for _ in range(self.n_assets)]
        
        # åˆå§‹æƒé‡
        init_weights = np.ones(self.n_assets) / self.n_assets
        
        # ä¼˜åŒ–
        result = minimize(
            risk_parity_objective,
            init_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints
        )
        
        weights = result.x
        expected_return = np.dot(weights, self.returns.mean() * 252)
        expected_risk = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
        sharpe_ratio = expected_return / expected_risk
        
        return OptimizationResult(
            weights=weights,
            expected_return=expected_return,
            expected_risk=expected_risk,
            sharpe_ratio=sharpe_ratio,
            method='risk_parity',
            constraints={},
            metadata={'success': result.success}
        )


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def create_sample_returns(n_assets: int = 5, n_days: int = 252) -> pd.DataFrame:
    """åˆ›å»ºæ¨¡æ‹Ÿæ”¶ç›Šç‡æ•°æ®"""
    np.random.seed(42)
    dates = pd.date_range(start='2023-01-01', periods=n_days, freq='D')
    
    # ç”Ÿæˆç›¸å…³çš„æ”¶ç›Šç‡
    mean_returns = np.random.uniform(0.0001, 0.001, n_assets)
    volatilities = np.random.uniform(0.01, 0.03, n_assets)
    
    # ç›¸å…³ç³»æ•°çŸ©é˜µ
    corr_matrix = np.random.uniform(0.3, 0.7, (n_assets, n_assets))
    np.fill_diagonal(corr_matrix, 1.0)
    corr_matrix = (corr_matrix + corr_matrix.T) / 2  # å¯¹ç§°åŒ–
    
    # åæ–¹å·®çŸ©é˜µ
    cov_matrix = np.outer(volatilities, volatilities) * corr_matrix
    
    # ç”Ÿæˆæ”¶ç›Šç‡
    returns = np.random.multivariate_normal(mean_returns, cov_matrix, n_days)
    
    columns = [f'Asset_{i+1}' for i in range(n_assets)]
    return pd.DataFrame(returns, index=dates, columns=columns)


def main():
    """ç¤ºä¾‹ï¼šæŠ•èµ„ç»„åˆä¼˜åŒ–"""
    print("=" * 80)
    print("æŠ•èµ„ç»„åˆä¼˜åŒ– - ç¤ºä¾‹")
    print("=" * 80)
    
    # 1. åˆ›å»ºæ•°æ®
    print("\nğŸ“Š ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    returns = create_sample_returns(n_assets=5, n_days=252)
    print(f"æ•°æ®ç»´åº¦: {returns.shape}")
    
    # 2. å‡å€¼æ–¹å·®ä¼˜åŒ–
    print("\nğŸ¯ å‡å€¼æ–¹å·®ä¼˜åŒ– (æœ€å¤§åŒ–å¤æ™®æ¯”ç‡)...")
    mv_optimizer = MeanVarianceOptimizer(returns, risk_free_rate=0.03)
    result_sharpe = mv_optimizer.optimize_sharpe()
    
    print(f"æƒé‡: {result_sharpe.weights}")
    print(f"é¢„æœŸæ”¶ç›Š: {result_sharpe.expected_return:.2%}")
    print(f"é¢„æœŸé£é™©: {result_sharpe.expected_risk:.2%}")
    print(f"å¤æ™®æ¯”ç‡: {result_sharpe.sharpe_ratio:.2f}")
    
    # 3. æœ€å°æ³¢åŠ¨ç‡
    print("\nğŸ“‰ æœ€å°æ³¢åŠ¨ç‡ä¼˜åŒ–...")
    result_minvol = mv_optimizer.optimize_min_volatility()
    
    print(f"æƒé‡: {result_minvol.weights}")
    print(f"é¢„æœŸæ”¶ç›Š: {result_minvol.expected_return:.2%}")
    print(f"é¢„æœŸé£é™©: {result_minvol.expected_risk:.2%}")
    
    # 4. Black-Litterman
    print("\nğŸ”® Black-Littermanä¼˜åŒ–...")
    bl_optimizer = BlackLittermanOptimizer(returns)
    
    # æŠ•èµ„è€…è§‚ç‚¹: Asset_1é¢„æœŸæ”¶ç›Š15%, Asset_3é¢„æœŸæ”¶ç›Š10%
    views = {0: 0.15, 2: 0.10}
    result_bl = bl_optimizer.optimize_with_views(views, view_confidence=0.7)
    
    print(f"æƒé‡: {result_bl.weights}")
    print(f"é¢„æœŸæ”¶ç›Š: {result_bl.expected_return:.2%}")
    print(f"é¢„æœŸé£é™©: {result_bl.expected_risk:.2%}")
    print(f"å¤æ™®æ¯”ç‡: {result_bl.sharpe_ratio:.2f}")
    
    # 5. é£é™©å¹³ä»·
    print("\nâš–ï¸  é£é™©å¹³ä»·ä¼˜åŒ–...")
    rp_optimizer = RiskParityOptimizer(returns)
    result_rp = rp_optimizer.optimize()
    
    print(f"æƒé‡: {result_rp.weights}")
    print(f"é¢„æœŸæ”¶ç›Š: {result_rp.expected_return:.2%}")
    print(f"é¢„æœŸé£é™©: {result_rp.expected_risk:.2%}")
    
    # 6. æœ‰æ•ˆå‰æ²¿
    print("\nğŸ“ˆ è®¡ç®—æœ‰æ•ˆå‰æ²¿...")
    frontier = mv_optimizer.efficient_frontier(n_points=20)
    print(f"æœ‰æ•ˆå‰æ²¿ç‚¹æ•°: {len(frontier)}")
    
    print("\n" + "=" * 80)
    print("âœ… å®Œæˆï¼")
    print("=" * 80)


if __name__ == '__main__':
    main()
