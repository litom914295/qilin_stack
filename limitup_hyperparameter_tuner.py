"""
æ¶¨åœæ¿é¢„æµ‹ç³»ç»Ÿ - Optunaè¶…å‚æ•°è°ƒä¼˜æ¨¡å—
æ”¯æŒå¤šæ¨¡å‹è‡ªåŠ¨è°ƒå‚å’Œç»“æœæŒä¹…åŒ–
"""

import optuna
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
from pathlib import Path
import json
from datetime import datetime
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score
from sklearn.model_selection import TimeSeriesSplit

class LimitUpHyperparameterTuner:
    """æ¶¨åœæ¿é¢„æµ‹è¶…å‚æ•°è°ƒä¼˜å™¨"""
    
    def __init__(
        self,
        model_type: str = 'lightgbm',
        n_trials: int = 100,
        timeout: int = 3600,
        save_dir: str = './tuning_results'
    ):
        """
        åˆå§‹åŒ–è°ƒä¼˜å™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('lightgbm', 'xgboost', 'catboost')
            n_trials: ä¼˜åŒ–è¯•éªŒæ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            save_dir: ç»“æœä¿å­˜ç›®å½•
        """
        self.model_type = model_type
        self.n_trials = n_trials
        self.timeout = timeout
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        self.best_params = None
        self.best_score = None
        self.study = None
        
    def suggest_params(self, trial: optuna.Trial) -> Dict[str, Any]:
        """æ ¹æ®æ¨¡å‹ç±»å‹å»ºè®®è¶…å‚æ•°"""
        
        if self.model_type == 'lightgbm':
            return {
                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                'max_depth': trial.suggest_int('max_depth', 3, 12),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
                'subsample': trial.suggest_float('subsample', 0.5, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
            }
        
        elif self.model_type == 'xgboost':
            return {
                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                'max_depth': trial.suggest_int('max_depth', 3, 12),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
                'subsample': trial.suggest_float('subsample', 0.5, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
                'gamma': trial.suggest_float('gamma', 1e-8, 10.0, log=True),
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
            }
        
        elif self.model_type == 'catboost':
            return {
                'iterations': trial.suggest_int('iterations', 100, 1000),
                'depth': trial.suggest_int('depth', 4, 10),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),
                'border_count': trial.suggest_int('border_count', 32, 255),
                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),
            }
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def create_model(self, params: Dict[str, Any]):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        
        if self.model_type == 'lightgbm':
            return LGBMClassifier(**params, random_state=42, verbose=-1)
        
        elif self.model_type == 'xgboost':
            return XGBClassifier(**params, random_state=42, use_label_encoder=False, eval_metric='logloss')
        
        elif self.model_type == 'catboost':
            return CatBoostClassifier(**params, random_state=42, verbose=0)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def objective(self, trial: optuna.Trial, X: pd.DataFrame, y: pd.Series) -> float:
        """ä¼˜åŒ–ç›®æ ‡å‡½æ•° - ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯"""
        
        # å»ºè®®è¶…å‚æ•°
        params = self.suggest_params(trial)
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_model(params)
        
        # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []
        
        for train_idx, val_idx in tscv.split(X):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            y_pred = model.predict(X_val)
            
            # è®¡ç®—F1åˆ†æ•°ï¼ˆé’ˆå¯¹æ¶¨åœæ¿é¢„æµ‹ä¼˜åŒ–ï¼‰
            score = f1_score(y_val, y_pred, average='weighted')
            scores.append(score)
        
        # è¿”å›å¹³å‡å¾—åˆ†
        mean_score = np.mean(scores)
        return mean_score
    
    def optimize(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        direction: str = 'maximize'
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
        
        Args:
            X: ç‰¹å¾æ•°æ®
            y: ç›®æ ‡å˜é‡
            direction: ä¼˜åŒ–æ–¹å‘ ('maximize' or 'minimize')
            
        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸
        """
        
        print(f"\nğŸš€ å¼€å§‹{self.model_type}æ¨¡å‹è¶…å‚æ•°ä¼˜åŒ–...")
        print(f"è¯•éªŒæ¬¡æ•°: {self.n_trials}, è¶…æ—¶: {self.timeout}ç§’")
        
        # åˆ›å»ºOptuna study
        self.study = optuna.create_study(
            direction=direction,
            sampler=optuna.samplers.TPESampler(seed=42),
            pruner=optuna.pruners.MedianPruner()
        )
        
        # æ‰§è¡Œä¼˜åŒ–
        self.study.optimize(
            lambda trial: self.objective(trial, X, y),
            n_trials=self.n_trials,
            timeout=self.timeout,
            show_progress_bar=True
        )
        
        # ä¿å­˜æœ€ä¼˜å‚æ•°
        self.best_params = self.study.best_params
        self.best_score = self.study.best_value
        
        print(f"\nâœ… ä¼˜åŒ–å®Œæˆ!")
        print(f"æœ€ä¼˜å¾—åˆ†: {self.best_score:.4f}")
        print(f"æœ€ä¼˜å‚æ•°: {json.dumps(self.best_params, indent=2, ensure_ascii=False)}")
        
        # ä¿å­˜ç»“æœ
        self._save_results()
        
        return self.best_params
    
    def _save_results(self):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜æœ€ä¼˜å‚æ•°
        params_file = self.save_dir / f'{self.model_type}_best_params_{timestamp}.json'
        with open(params_file, 'w', encoding='utf-8') as f:
            json.dump({
                'model_type': self.model_type,
                'best_score': float(self.best_score),
                'best_params': self.best_params,
                'n_trials': self.n_trials,
                'timestamp': timestamp
            }, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å‚æ•°å·²ä¿å­˜: {params_file}")
        
        # ä¿å­˜ä¼˜åŒ–å†å²
        df_trials = self.study.trials_dataframe()
        history_file = self.save_dir / f'{self.model_type}_history_{timestamp}.csv'
        df_trials.to_csv(history_file, index=False, encoding='utf-8-sig')
        
        print(f"ğŸ“Š å†å²å·²ä¿å­˜: {history_file}")
        
        # ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
        self._generate_visualization()
    
    def _generate_visualization(self):
        """ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š"""
        
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            plt.rcParams['font.sans-serif'] = ['SimHei']
            plt.rcParams['axes.unicode_minus'] = False
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # 1. ä¼˜åŒ–å†å²
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot([t.number for t in self.study.trials], 
                   [t.value for t in self.study.trials])
            ax.set_xlabel('è¯•éªŒæ¬¡æ•°')
            ax.set_ylabel('F1åˆ†æ•°')
            ax.set_title(f'{self.model_type} ä¼˜åŒ–å†å²')
            ax.grid(True, alpha=0.3)
            
            history_plot = self.save_dir / f'{self.model_type}_history_{timestamp}.png'
            plt.savefig(history_plot, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ å¯è§†åŒ–å·²ä¿å­˜: {history_plot}")
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
    
    def load_best_params(self, params_file: str) -> Dict[str, Any]:
        """åŠ è½½ä¿å­˜çš„æœ€ä¼˜å‚æ•°"""
        
        with open(params_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.best_params = data['best_params']
        self.best_score = data['best_score']
        
        print(f"âœ… å·²åŠ è½½æœ€ä¼˜å‚æ•° (å¾—åˆ†: {self.best_score:.4f})")
        return self.best_params


class MultiModelTuner:
    """å¤šæ¨¡å‹æ‰¹é‡è°ƒä¼˜å™¨"""
    
    def __init__(
        self,
        models: List[str] = ['lightgbm', 'xgboost', 'catboost'],
        n_trials: int = 100,
        timeout: int = 3600,
        save_dir: str = './tuning_results'
    ):
        """
        åˆå§‹åŒ–å¤šæ¨¡å‹è°ƒä¼˜å™¨
        
        Args:
            models: æ¨¡å‹åˆ—è¡¨
            n_trials: æ¯ä¸ªæ¨¡å‹çš„è¯•éªŒæ¬¡æ•°
            timeout: æ¯ä¸ªæ¨¡å‹çš„è¶…æ—¶æ—¶é—´
            save_dir: ç»“æœä¿å­˜ç›®å½•
        """
        self.models = models
        self.n_trials = n_trials
        self.timeout = timeout
        self.save_dir = save_dir
        
        self.tuners = {}
        self.results = {}
    
    def optimize_all(
        self,
        X: pd.DataFrame,
        y: pd.Series
    ) -> Dict[str, Dict[str, Any]]:
        """
        ä¼˜åŒ–æ‰€æœ‰æ¨¡å‹
        
        Returns:
            æ‰€æœ‰æ¨¡å‹çš„æœ€ä¼˜å‚æ•°å­—å…¸
        """
        
        print(f"\n{'='*60}")
        print(f"ğŸ¯ å¼€å§‹æ‰¹é‡è¶…å‚æ•°ä¼˜åŒ– - {len(self.models)}ä¸ªæ¨¡å‹")
        print(f"{'='*60}\n")
        
        for model_type in self.models:
            print(f"\n{'='*60}")
            print(f"æ¨¡å‹: {model_type.upper()}")
            print(f"{'='*60}")
            
            # åˆ›å»ºè°ƒä¼˜å™¨
            tuner = LimitUpHyperparameterTuner(
                model_type=model_type,
                n_trials=self.n_trials,
                timeout=self.timeout,
                save_dir=self.save_dir
            )
            
            # æ‰§è¡Œä¼˜åŒ–
            best_params = tuner.optimize(X, y)
            
            # ä¿å­˜ç»“æœ
            self.tuners[model_type] = tuner
            self.results[model_type] = {
                'best_params': best_params,
                'best_score': tuner.best_score
            }
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_summary_report()
        
        return self.results
    
    def _generate_summary_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        
        print(f"\n{'='*60}")
        print("ğŸ“Š ä¼˜åŒ–ç»“æœæ±‡æ€»")
        print(f"{'='*60}\n")
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        summary_data = []
        for model_type, result in self.results.items():
            summary_data.append({
                'æ¨¡å‹': model_type,
                'æœ€ä¼˜å¾—åˆ†': f"{result['best_score']:.4f}",
                'å‚æ•°æ•°é‡': len(result['best_params'])
            })
        
        df_summary = pd.DataFrame(summary_data)
        print(df_summary.to_string(index=False))
        
        # ä¿å­˜æ±‡æ€»
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        summary_file = Path(self.save_dir) / f'tuning_summary_{timestamp}.csv'
        df_summary.to_csv(summary_file, index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ’¾ æ±‡æ€»å·²ä¿å­˜: {summary_file}")


if __name__ == '__main__':
    # æµ‹è¯•ç¤ºä¾‹
    print("="*60)
    print("æ¶¨åœæ¿é¢„æµ‹ç³»ç»Ÿ - Optunaè¶…å‚æ•°è°ƒä¼˜æ¨¡å—")
    print("="*60)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 1000
    n_features = 50
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    
    # æ¨¡æ‹Ÿæ¶¨åœæ¿æ ‡ç­¾ï¼ˆ0=ä¸æ¶¨åœï¼Œ1=æ¶¨åœï¼‰
    y = pd.Series(np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3]))
    
    print(f"\næ•°æ®é›†å¤§å°: {X.shape}")
    print(f"æ¶¨åœæ¿æ ·æœ¬å æ¯”: {y.mean():.2%}")
    
    # å•æ¨¡å‹è°ƒä¼˜
    print("\n" + "="*60)
    print("1ï¸âƒ£ å•æ¨¡å‹è°ƒä¼˜ç¤ºä¾‹")
    print("="*60)
    
    tuner = LimitUpHyperparameterTuner(
        model_type='lightgbm',
        n_trials=20,
        timeout=300
    )
    
    best_params = tuner.optimize(X, y)
    
    # å¤šæ¨¡å‹æ‰¹é‡è°ƒä¼˜
    print("\n" + "="*60)
    print("2ï¸âƒ£ å¤šæ¨¡å‹æ‰¹é‡è°ƒä¼˜ç¤ºä¾‹")
    print("="*60)
    
    multi_tuner = MultiModelTuner(
        models=['lightgbm', 'xgboost'],
        n_trials=20,
        timeout=300
    )
    
    results = multi_tuner.optimize_all(X, y)
    
    print("\nâœ… æ‰€æœ‰è°ƒä¼˜ä»»åŠ¡å®Œæˆ!")
